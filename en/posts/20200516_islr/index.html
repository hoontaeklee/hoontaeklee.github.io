<!DOCTYPE html>
<html lang="en" dir="ltr">

<head prefix="og: http://ogp.me/ns#">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>ISLR Note – bloght</title>
    


<script src="/js/enquire.min.aa37bdcb743826eecdae5c5d177fc7d6552340f1b4378ffaa9c82b2c6111400b.js"></script>

<script defer src="/js/lazysizes.min.5e11d056075a05065b9c0bfec44084a113fc2976c2952ec804dedb61c7662db9.js"></script>

<script defer src="/js/fuse.min.c4bee9a8d44273d6154fe86006923d4131eb2e8069d8897687137c6f37f553e3.js"></script>

<script defer src="/js/helper/getParents.min.1618c696be7c98933f9a92677f518b512a74e55bdbb976b09936b4182e93181b.js"></script>

<script defer src="/js/helper/fadeinout.min.93a331f96194789a542f33690bbe4f0c102c7e78ffc018217f5a1c33010bad91.js"></script>

<script defer src="/js/helper/closest.min.js"></script>
  
<script>
  "use strict";

  
  
  if (window.NodeList && !NodeList.prototype.forEach) {
    NodeList.prototype.forEach = Array.prototype.forEach;
  }

  
  if (!String.prototype.includes) {
    String.prototype.includes = function (search, start) {
      'use strict';

      if (search instanceof RegExp) {
        throw TypeError('first argument must not be a RegExp');
      }
      if (start === undefined) { start = 0; }
      return this.indexOf(search, start) !== -1;
    };
  }

  
  Document.prototype.append = Element.prototype.append = function append() {
    this.appendChild(_mutation(arguments));
  };
  function _mutation(nodes) {
    if (!nodes.length) {
      throw new Error('DOM Exception 8');
    } else if (nodes.length === 1) {
      return typeof nodes[0] === 'string' ? document.createTextNode(nodes[0]) : nodes[0];
    } else {
      var
      fragment = document.createDocumentFragment(),
      length = nodes.length,
      index = -1,
      node;

      while (++index < length) {
        node = nodes[index];

        fragment.appendChild(typeof node === 'string' ? document.createTextNode(node) : node);
      }

      return fragment;
    }
  }

  
  if (!String.prototype.startsWith) {
    String.prototype.startsWith = function (searchString, position) {
      position = position || 0;
      return this.indexOf(searchString, position) === position;
    };
  }
  


  document.addEventListener('DOMContentLoaded', function () {
    
    var navCollapseBtn = document.querySelector('.navbar__burger');
    navCollapseBtn ? navCollapseBtn.addEventListener('click', function (e) {
      var navCollapse = document.querySelector('.navbarm__collapse');

      if (navCollapse) {
        var dataOpen = navCollapse.getAttribute('data-open');

        if (dataOpen === 'true') {
          navCollapse.setAttribute('data-open', 'false');
          navCollapse.style.maxHeight = 0;
          navCollapseBtn.classList.remove('is-active');
        } else {
          navCollapse.setAttribute('data-open', 'true');
          navCollapse.style.maxHeight = navCollapse.scrollHeight + "px";
          navCollapseBtn.classList.add('is-active');
        }
      }
    }) : null;
    


    
    var summaryContainer = document.querySelector('.summary__container');
    var searchResult = document.querySelector('.search-result');
    var searchResultCloseBtn = document.querySelector('.search-result__close');
    searchResultCloseBtn ? searchResultCloseBtn.addEventListener('click', function (e) {
      searchResult.setAttribute('data-display', 'none');
      summaryContainer.setAttribute('data-display', 'block');
    }) : null;
    


    
    document.querySelectorAll('.tab') ? 
    document.querySelectorAll('.tab').forEach(function(elem, idx) {
      var containerId = elem.getAttribute('id');
      var containerElem = elem;
      var tabLinks = elem.querySelectorAll('.tab__link');
      var tabContents = elem.querySelectorAll('.tab__content');
      var ids = [];

      tabLinks && tabLinks.length > 0 ?
      tabLinks.forEach(function(link, index, self) {
        link.onclick = function(e) {
          for (var i = 0; i < self.length; i++) {
            if (index === parseInt(i, 10)) {
              if (!self[i].classList.contains('active')) {
                self[i].classList.add('active');
                tabContents[i].style.display = 'block';
              }
            } else {
              self[i].classList.remove('active');
              tabContents[i].style.display = 'none';
            }
          }
        }
      }) : null;
    }) : null;
    


    
    document.querySelectorAll('.codetab') ? 
    document.querySelectorAll('.codetab').forEach(function(elem, idx) {
      var containerId = elem.getAttribute('id');
      var containerElem = elem;
      var codetabLinks = elem.querySelectorAll('.codetab__link');
      var codetabContents = elem.querySelectorAll('.codetab__content');
      var ids = [];

      codetabLinks && codetabLinks.length > 0 ?
      codetabLinks.forEach(function(link, index, self) {
        link.onclick = function(e) {
          for (var i = 0; i < self.length; i++) {
            if (index === parseInt(i, 10)) {
              if (!self[i].classList.contains('active')) {
                self[i].classList.add('active');
                codetabContents[i].style.display = 'block';
              }
            } else {
              self[i].classList.remove('active');
              codetabContents[i].style.display = 'none';
            }
          }
        }
      }) : null;
    }) : null;
    


    
    var gttBtn = document.getElementById("gtt");
    gttBtn.style.display = "none";
    gttBtn.addEventListener('click', function () {
      if (window.document.documentMode) {
        document.documentElement.scrollTop = 0;
      } else {
        scrollToTop(250);
      }
    });

    function scrollToTop(scrollDuration) {
      var scrollStep = -window.scrollY / (scrollDuration / 15);
      var scrollInterval = setInterval(function () {
        if (window.scrollY != 0) {
          window.scrollBy(0, scrollStep);
        }
        else clearInterval(scrollInterval);
      }, 15);
    }

    var scrollFunction = function () {
      if (document.body.scrollTop > 250 || document.documentElement.scrollTop > 250) {
        gttBtn.style.display = "block";
      } else {
        gttBtn.style.display = "none";
      }
    }
    


    
    var expandBtn = document.querySelectorAll('.expand__button');

    for (let i = 0; i < expandBtn.length; i++) {
      expandBtn[i].addEventListener("click", function () {
        var content = this.nextElementSibling;
        if (content.style.maxHeight) {
          content.style.maxHeight = null;
          this.querySelector('svg').classList.add('expand-icon__right');
          this.querySelector('svg').classList.remove('expand-icon__down');
        } else {
          content.style.maxHeight = content.scrollHeight + "px";
          this.querySelector('svg').classList.remove('expand-icon__right');
          this.querySelector('svg').classList.add('expand-icon__down');
        }
      });
    }
    


    
    var lastScrollTop = window.pageYOffset || document.documentElement.scrollTop;
    var tocElem = document.querySelector('.toc');
    var tableOfContentsElem = tocElem ? tocElem.querySelector('#TableOfContents') : null;
    var toggleTocElem = document.getElementById('toggle-toc');
    var singleContentsElem = document.querySelector('.single__contents');
    var navbar = document.querySelector('.navbar');
    var tocFlexbox = document.querySelector('.toc__flexbox');
    var tocFlexboxOuter = document.querySelector('.toc__flexbox--outer');
    var expandContents = document.querySelectorAll('.expand__content');
    var boxContents = document.querySelectorAll('.box');
    var notAllowedTitleIds = null;

    
    var tocFolding = JSON.parse("true");
    
    var tocLevels = JSON.parse("[\"h2\",\"h3\",\"h4\"]");
    
    if (tocLevels) {
      tocLevels = tocLevels.toString();
    } else {
      tocLevels = "h1, h2, h3, h4, h5, h6";
    }

    
    singleContentsElem && singleContentsElem.querySelectorAll(".tab") ?
    singleContentsElem.querySelectorAll(".tab").forEach(function (elem) {
      elem.querySelectorAll(tocLevels).forEach(function (element) {
        notAllowedTitleIds = Array.isArray(notAllowedTitleIds) ?
          notAllowedTitleIds.concat(element.getAttribute('id')) :
          [element.getAttribute('id')];
      });
    }) : null;

    
    expandContents ? expandContents.forEach(function(elem) {
      elem.querySelectorAll(tocLevels).forEach(function (element) {
        notAllowedTitleIds = Array.isArray(notAllowedTitleIds) ?
          notAllowedTitleIds.concat(element.getAttribute('id')) :
          [element.getAttribute('id')];
      });
    }) : null;

    
    boxContents ? boxContents.forEach(function(elem) {
      elem.querySelectorAll(tocLevels).forEach(function (element) {
        notAllowedTitleIds = Array.isArray(notAllowedTitleIds) ?
          notAllowedTitleIds.concat(element.getAttribute('id')) :
          [element.getAttribute('id')];
      });
    }) : null;

    
    window.onscroll = function () {
      scrollFunction();
      
      var st = window.pageYOffset || document.documentElement.scrollTop;
      if (st > lastScrollTop) { 
        if (st < 250) {
          gttBtn.style.display = "none";
        } else {
          gttBtn.style.display = "block";
        }

        if (st < 45) {
          return null;
        }
        
        if (!navbar.classList.contains('navbar--hide')) {
          navbar.classList.add('navbar--hide');
        } else if (navbar.classList.contains('navbar--show')) {
          navbar.classList.remove('navbar--show');
        }

        if (singleContentsElem) {
          if (singleContentsElem.querySelectorAll(tocLevels).length > 0) {
            singleContentsElem.querySelectorAll(tocLevels).forEach(function (elem) {
              if (toggleTocElem && !toggleTocElem.checked) {
                return null;
              }

              if (notAllowedTitleIds && notAllowedTitleIds.includes(elem.getAttribute('id'))) {
                return null;
              }
              
              if (document.documentElement.scrollTop >= elem.offsetTop) {
                if (tableOfContentsElem) {
                  var id = elem.getAttribute('id');
                  tocElem.querySelectorAll('a').forEach(function (elem) {
                    elem.classList.remove('active');
                  });
                  tocElem.querySelector('a[href="#' + id + '"]') ?
                    tocElem.querySelector('a[href="#' + id + '"]').classList.add('active') : null;

                  if (false === tocFolding) {
                    
                  } else {
                    tableOfContentsElem.querySelectorAll('ul') ?
                      tableOfContentsElem.querySelectorAll('ul').forEach(function (rootUl) {
                        rootUl.querySelectorAll('li').forEach(function (liElem) {
                          liElem.querySelectorAll('ul').forEach(function (ulElem) {
                            ulElem.style.display = 'none';
                          });
                        });
                      }) : null;
                  }

                  var curElem = tableOfContentsElem.querySelector("[href='#" + id + "']");
                  if (curElem && curElem.nextElementSibling) {
                    curElem.nextElementSibling.style.display = 'block';
                  }
                  getParents(curElem, 'ul') ?
                    getParents(curElem, 'ul').forEach(function (elem) {
                      elem.style.display = 'block';
                    }) : null;
                }
              }
            });
          } else {
            if (tocFlexbox) {
              tocFlexbox.setAttribute('data-position', '');
              if (!tocFlexbox.classList.contains('hide')) {
                tocFlexbox.classList.add('hide');
              }
            }
            if (tocFlexboxOuter) {
              tocFlexboxOuter.setAttribute('data-position', '');
              if (!tocFlexboxOuter.classList.contains('hide')) {
                tocFlexboxOuter.classList.add('hide');
              }
            }
          }
        }
      } else { 
        if (st < 250) {
          gttBtn.style.display = "none";
        }

        if (navbar.classList.contains('navbar--hide')) {
          navbar.classList.remove('navbar--hide');
        } else if (!navbar.classList.contains('navbar--show')) {
          navbar.classList.add('navbar--show');
        }

        if (singleContentsElem) {
          if (singleContentsElem.querySelectorAll(tocLevels).length > 0) {
            singleContentsElem.querySelectorAll(tocLevels).forEach(function (elem) {
              if (toggleTocElem && !toggleTocElem.checked) {
                return null;
              }
              
              if (notAllowedTitleIds && notAllowedTitleIds.includes(elem.getAttribute('id'))) {
                return null;
              }

              if (document.documentElement.scrollTop >= elem.offsetTop) {
                if (tableOfContentsElem) {
                  var id = elem.getAttribute('id');
                  tocElem.querySelectorAll('a').forEach(function (elem) {
                    elem.classList.remove('active');
                  });
                  tocElem.querySelector('a[href="#' + id + '"]') ?
                    tocElem.querySelector('a[href="#' + id + '"]').classList.add('active') : null;

                  if (false === tocFolding) {
                    
                  } else {
                    tableOfContentsElem.querySelectorAll('ul') ?
                      tableOfContentsElem.querySelectorAll('ul').forEach(function (rootUl) {
                        rootUl.querySelectorAll('li').forEach(function (liElem) {
                          liElem.querySelectorAll('ul').forEach(function (ulElem) {
                            ulElem.style.display = 'none';
                          });
                        });
                      }) : null;
                  }

                  var curElem = tableOfContentsElem.querySelector("[href='#" + id + "']");
                  if (curElem && curElem.nextElementSibling) {
                    curElem.nextElementSibling.style.display = 'block';
                  }
                  getParents(curElem, 'ul') ?
                    getParents(curElem, 'ul').forEach(function (elem) {
                      elem.style.display = 'block';
                    }) : null;
                }
              }
            });
          } else {
            if (tocFlexbox && !tocFlexbox.classList.contains('hide')) {
              tocFlexbox.classList.add('hide');
            }
            if (tocFlexboxOuter && !tocFlexboxOuter.classList.contains('hide')) {
              tocFlexboxOuter.classList.add('hide');
            }
          }
          
        }

        if (tableOfContentsElem && document.documentElement.scrollTop < 250) {
          if (false === tocFolding) {

          } else {
            tableOfContentsElem.querySelector('ul') ?
              tableOfContentsElem.querySelector('ul').querySelectorAll('li').forEach(function (liElem) {
                liElem.querySelectorAll('ul').forEach(function (ulElem) {
                  ulElem.style.display = 'none';
                });
              }) : null;
          }
        }
      }
      lastScrollTop = st <= 0 ? 0 : st;
    };
  


  
    var localTheme = localStorage.getItem('theme');
    var rootEleme = document.getElementById('root');
    var selectThemeElem = document.querySelectorAll('.select-theme');
    var selectThemeItemElem = document.querySelectorAll('.select-theme__item');

    var setMetaColor = function(themeColor) {
      var metaMsapplicationTileColor = document.getElementsByName('msapplication-TileColor')[0];
      var metaThemeColor = document.getElementsByName('theme-color')[0];
      var metaMsapplicationNavbuttonColor = document.getElementsByName('msapplication-navbutton-color')[0];
      var metaAppleMobileWebAappStatusBarStyle = document.getElementsByName('apple-mobile-web-app-status-bar-style')[0];

      if (themeColor.includes('dark')) {
        metaMsapplicationTileColor.setAttribute('content', '#fcfcfa');
        metaThemeColor.setAttribute('content', '#403E41');
        metaMsapplicationNavbuttonColor.setAttribute('content', '#403E41');
        metaAppleMobileWebAappStatusBarStyle.setAttribute('content', '#403E41');
      } else if (themeColor.includes('light')) {
        metaMsapplicationTileColor.setAttribute('content', '#555');
        metaThemeColor.setAttribute('content', '#eee');
        metaMsapplicationNavbuttonColor.setAttribute('content', '#eee');
        metaAppleMobileWebAappStatusBarStyle.setAttribute('content', '#eee');
      } else if (themeColor.includes('hacker')) {
        metaMsapplicationTileColor.setAttribute('content', '#e3cd26');
        metaThemeColor.setAttribute('content', '#252526');
        metaMsapplicationNavbuttonColor.setAttribute('content', '#252526');
        metaAppleMobileWebAappStatusBarStyle.setAttribute('content', '#252526');
      } else if (themeColor.includes('solarized')) {
        metaMsapplicationTileColor.setAttribute('content', '#d3af86');
        metaThemeColor.setAttribute('content', '#51412c');
        metaMsapplicationNavbuttonColor.setAttribute('content', '#51412c');
        metaAppleMobileWebAappStatusBarStyle.setAttribute('content', '#51412c');
      } else if (themeColor.includes('kimbie')) {
        metaMsapplicationTileColor.setAttribute('content', '#586e75');
        metaThemeColor.setAttribute('content', '#eee8d5');
        metaMsapplicationNavbuttonColor.setAttribute('content', '#eee8d5');
        metaAppleMobileWebAappStatusBarStyle.setAttribute('content', '#eee8d5');
      } 
    }
    
    if (localTheme) {
      selectThemeItemElem ? 
      selectThemeItemElem.forEach(function (elem) {
        if (elem.text.trim() === localTheme) {
          elem.classList.add('is-active');
        } else {
          elem.classList.remove('is-active');
        }
      }) : null;

      setMetaColor(localTheme);
    } else {
      setMetaColor(rootEleme.className);
    }

    selectThemeItemElem ? 
    selectThemeItemElem.forEach(function (v, i) {
      v.addEventListener('click', function (e) {
        var selectedThemeVariant = e.target.text.trim();
        localStorage.setItem('theme', selectedThemeVariant);
        setMetaColor(selectedThemeVariant);

        rootEleme.removeAttribute('class');
        rootEleme.classList.add('theme__' + selectedThemeVariant);
        selectThemeElem.forEach(function(rootElem) {
          rootElem.querySelectorAll('a').forEach(function (elem) {
            if (elem.classList) {
              if (elem.text.trim() === selectedThemeVariant) {
                if (!elem.classList.contains('is-active')) {
                  elem.classList.add('is-active');
                }
              } else {
                if (elem.classList.contains('is-active')) {
                  elem.classList.remove('is-active');
                }
              }
            }
          });
        });

        if (window.mermaid) {
          if (selectedThemeVariant === "dark" || selectedThemeVariant === "hacker") {
            mermaid.initialize({ theme: 'dark' });
            location.reload();
          } else {
            mermaid.initialize({ theme: 'default' });
            location.reload();
          }
        }

        var utterances = document.querySelector('iframe');
        if (utterances) {
          utterances.contentWindow.postMessage({
            type: 'set-theme',
            theme: selectedThemeVariant === "dark" || selectedThemeVariant === "hacker" ? 'photon-dark' : selectedThemeVariant === 'kimbie' ? 'github-dark-orange' : 'github-light',
          }, 'https://utteranc.es');
        }
      });
    }) : null;
  


  
    
    var permalink = JSON.parse("\"https://hoontaeklee.github.io/en/posts/20200516_islr/\"");
    var searchResults = null;
    var searchMenu = null;
    var searchText = null;
    
    
    var enableSearchHighlight = JSON.parse("true");
    
    var searchResultPosition = JSON.parse("\"main\"");
    
    var sectionType = JSON.parse("\"posts\"");

    var fuse = null;

    (function initFuse() {
      var xhr = new XMLHttpRequest();
      xhr.open('GET', permalink + "index.json");
      xhr.setRequestHeader('Content-Type', 'application/json; charset=utf-8');
      xhr.onload = function () {
        if (xhr.status === 200) {
          fuse = new Fuse(JSON.parse(xhr.response.toString('utf-8')), {
            keys: sectionType.includes('publication') ? ['title', 'abstract'] : ['title', 'description', 'content'],
            includeMatches: enableSearchHighlight,
            shouldSort: true,
            threshold: 0.4,
            location: 0,
            distance: 100,
            maxPatternLength: 32,
            minMatchCharLength: 1,
          });
          window.fuse = fuse;
        }
        else {
          console.error('[' + xhr.status + ']Error:', xhr.statusText);
        }
      };
      xhr.send();
    })();

    function makeLi(ulElem, obj) {
      var li = document.createElement('li');
      li.className = 'search-result__item';
      
      var a = document.createElement('a');
      a.innerHTML = obj.title;
      a.setAttribute('class', 'search-result__item--title');
      a.setAttribute('href', obj.permalink);

      var descDiv = document.createElement('div');
      descDiv.setAttribute('class', 'search-result__item--desc');
      if (obj.description) {
        descDiv.innerHTML = obj.description;
      } else if (obj.content) {
        descDiv.innerHTML = obj.content.substring(0, 225);
      }
      
      li.appendChild(a);
      li.appendChild(descDiv);
      ulElem.appendChild(li);
    }

    function makeHighlightLi(ulElem, obj) {
      var li = document.createElement('li');
      li.className = 'search-result__item';
      var descDiv = null;

      var a = document.createElement('a');
      a.innerHTML = obj.item.title;
      a.setAttribute('class', 'search-result__item--title');
      a.setAttribute('href', obj.item.uri);

      if (obj.matches && obj.matches.length) {
        for (var i = 0; i < obj.matches.length; i++) {
          if ('title' === obj.matches[i].key) {
            a = document.createElement('a');
            a.innerHTML = generateHighlightedText(obj.matches[i].value, obj.matches[i].indices);
            a.setAttribute('class', 'search-result__item--title');
            a.setAttribute('href', obj.item.uri);
          }
          
          if ('description' === obj.matches[i].key) {
            descDiv = document.createElement('div');
            descDiv.setAttribute('class', 'search-result__item--desc');
            descDiv.innerHTML = generateHighlightedText(obj.item.description, obj.matches[i].indices);
          } else if ('content' === obj.matches[i].key) {
            if (!descDiv) {
              descDiv = document.createElement('div');
              descDiv.setAttribute('class', 'search-result__item--desc');
              descDiv.innerHTML = generateHighlightedText(obj.item.content.substring(0, 150), obj.matches[i].indices);
            }
          } else {
            if (obj.item.description) {
              descDiv = document.createElement('div');
              descDiv.setAttribute('class', 'search-result__item--desc');
              descDiv.innerHTML = obj.item.description;
            } else {
              descDiv = document.createElement('div');
              descDiv.setAttribute('class', 'search-result__item--desc');
              descDiv.innerHTML = obj.item.content.substring(0, 150);
            }
          }
        }

        li.appendChild(a);
        if (descDiv) {
          li.appendChild(descDiv);
        }
        if (li) {
          ulElem.appendChild(li);
        }
      }
    }

    function renderSearchResultsSide(searchText, results) {
      searchResults = document.getElementById('search-results');
      searchMenu = document.getElementById('search-menu');
      searchResults.setAttribute('class', 'dropdown is-active');
      
      var ul = document.createElement('ul');
      ul.setAttribute('class', 'dropdown-content search-content');

      if (results.length) {
        results.forEach(function (result) {
          var li = document.createElement('li');
          var a = document.createElement('a');
          a.setAttribute('href', result.uri);
          a.setAttribute('class', 'dropdown-item');
          a.appendChild(li);

          var titleDiv = document.createElement('div');
          titleDiv.innerHTML = result.title;
          titleDiv.setAttribute('class', 'menu-item__title');

          var descDiv = document.createElement('div');
          descDiv.setAttribute('class', 'menu-item__desc');
          if (result.description) {
            descDiv.innerHTML = result.description;
          } else if (result.content) {
            descDiv.innerHTML = result.content.substring(0, 150);
          }

          li.appendChild(titleDiv);
          li.appendChild(descDiv);
          ul.appendChild(a);
        });
      } else {
        var li = document.createElement('li');
        li.setAttribute('class', 'dropdown-item');
        li.innerText = 'No results found';
        ul.appendChild(li);
      }

      while (searchMenu.hasChildNodes()) {
        searchMenu.removeChild(
          searchMenu.lastChild
        );
      }
      
      searchMenu.appendChild(ul);
    }

    function renderSearchHighlightResultsSide(searchText, results) {
      searchResults = document.getElementById('search-results');
      searchMenu = document.getElementById('search-menu');
      searchResults.setAttribute('class', 'dropdown is-active');

      var ul = document.createElement('ul');
      ul.setAttribute('class', 'dropdown-content search-content');

      if (results.length) {
        results.forEach(function (result) {
          var li = document.createElement('li');
          var a = document.createElement('a');
          var descDiv = null;

          a.setAttribute('href', result.item.uri);
          a.setAttribute('class', 'dropdown-item');
          a.appendChild(li);

          var titleDiv = document.createElement('div');
          titleDiv.innerHTML = result.item.title;
          titleDiv.setAttribute('class', 'menu-item__title');
          
          if (result.matches && result.matches.length) {
            for (var i = 0; i < result.matches.length; i++) {
              if ('title' === result.matches[i].key) {
                titleDiv.innerHTML = generateHighlightedText(result.matches[i].value, result.matches[i].indices);
              }

              if ('description' === result.matches[i].key) {
                descDiv = document.createElement('div');
                descDiv.setAttribute('class', 'menu-item__desc');
                descDiv.innerHTML = generateHighlightedText(result.item.description, result.matches[i].indices);
              } else if ('content' === result.matches[i].key) {
                if (!descDiv) {
                  descDiv = document.createElement('div');
                  descDiv.setAttribute('class', 'menu-item__desc');
                  descDiv.innerHTML = generateHighlightedText(result.item.content.substring(0, 150), result.matches[i].indices);
                }
              } else {
                if (result.item.description) {
                  descDiv = document.createElement('div');
                  descDiv.setAttribute('class', 'menu-item__desc');
                  descDiv.innerHTML = result.item.description;
                } else {
                  descDiv = document.createElement('div');
                  descDiv.setAttribute('class', 'menu-item__desc');
                  descDiv.innerHTML = result.item.content.substring(0, 150);
                }
              }
            }
            
            li.appendChild(titleDiv);
            if (descDiv) {
              li.appendChild(descDiv);
            }
            ul.appendChild(a);
          }
        });
      } else {
        var li = document.createElement('li');
        li.setAttribute('class', 'dropdown-item');
        li.innerText = 'No results found';
        ul.appendChild(li);
      }

      while (searchMenu.hasChildNodes()) {
        searchMenu.removeChild(
          searchMenu.lastChild
        );
      }
      searchMenu.appendChild(ul);
    }

    function renderSearchResultsMobile(searchText, results) {
      searchResults = document.getElementById('search-mobile-results');

      var content = document.createElement('div');
      content.setAttribute('class', 'mobile-search__content');

      if (results.length > 0) {
        results.forEach(function (result) {
          var item = document.createElement('a');
          item.setAttribute('href', result.uri);
          item.innerHTML = '<div class="mobile-search__item"><div class="mobile-search__item--title">📄 ' + result.title + '</div><div class="mobile-search__item--desc">' + (result.description ? result.description : result.content) + '</div></div>';
          content.appendChild(item);
        });
      } else {
        var item = document.createElement('span');
        content.appendChild(item);
      }

      let wrap = document.getElementById('search-mobile-results');
      while (wrap.firstChild) {
        wrap.removeChild(wrap.firstChild)
      }
      searchResults.appendChild(content);      
    }

    function renderSearchHighlightResultsMobile(searchText, results) {
      searchResults = document.getElementById('search-mobile-results');

      var ul = document.createElement('div');
      ul.setAttribute('class', 'mobile-search__content');

      if (results.length) {
        results.forEach(function (result) {
          var li = document.createElement('li');
          var a = document.createElement('a');
          var descDiv = null;

          a.setAttribute('href', result.item.uri);
          a.appendChild(li);
          li.setAttribute('class', 'mobile-search__item');

          var titleDiv = document.createElement('div');
          titleDiv.innerHTML = result.item.title;
          titleDiv.setAttribute('class', 'mobile-search__item--title');
          
          if (result.matches && result.matches.length) {
            for (var i = 0; i < result.matches.length; i++) {
              if ('title' === result.matches[i].key) {
                titleDiv.innerHTML = generateHighlightedText(result.matches[i].value, result.matches[i].indices);
              }

              if ('description' === result.matches[i].key) {
                descDiv = document.createElement('div');
                descDiv.setAttribute('class', 'mobile-search__item--desc');
                descDiv.innerHTML = generateHighlightedText(result.item.description, result.matches[i].indices);
              } else if ('content' === result.matches[i].key) {
                if (!descDiv) {
                  descDiv = document.createElement('div');
                  descDiv.setAttribute('class', 'mobile-search__item--desc');
                  descDiv.innerHTML = generateHighlightedText(result.item.content.substring(0, 150), result.matches[i].indices);
                }
              } else {
                if (result.item.description) {
                  descDiv = document.createElement('div');
                  descDiv.setAttribute('class', 'mobile-search__item--desc');
                  descDiv.innerHTML = result.item.description;
                } else {
                  descDiv = document.createElement('div');
                  descDiv.setAttribute('class', 'mobile-search__item--desc');
                  descDiv.innerHTML = result.item.content.substring(0, 150);
                }
              }
            }
            
            li.appendChild(titleDiv);
            if (descDiv) {
              li.appendChild(descDiv);
            }
            ul.appendChild(a);
          }
        });
      } else {
        var item = document.createElement('span');
        ul.appendChild(item);
      }

      let wrap = document.getElementById('search-mobile-results');
      while (wrap.firstChild) {
        wrap.removeChild(wrap.firstChild)
      }
      searchResults.appendChild(ul);
    }

    function generateHighlightedText(text, regions) {
      if (!regions) {
        return text;
      }

      var content = '', nextUnhighlightedRegionStartingIndex = 0;

      regions.forEach(function(region) {
        if (region[0] === region[1]) {
          return null;
        }
        
        content += '' +
          text.substring(nextUnhighlightedRegionStartingIndex, region[0]) +
          '<span class="search__highlight">' +
            text.substring(region[0], region[1] + 1) +
          '</span>' +
        '';
        nextUnhighlightedRegionStartingIndex = region[1] + 1;
      });

      content += text.substring(nextUnhighlightedRegionStartingIndex);

      return content;
    };

    var searchElem = document.getElementById('search');
    var searchMobile = document.getElementById('search-mobile');
    var searchResultsContainer = document.getElementById('search-results');

    searchElem ?
    searchElem.addEventListener('input', function(e) {
      if (!e.target.value | window.innerWidth < 770) {
        searchResultsContainer ? searchResultsContainer.setAttribute('class', 'dropdown') : null;
        searchResult ? searchResult.setAttribute('data-display', 'none') : null;
        summaryContainer ? summaryContainer.setAttribute('data-display', 'block') : null;
        return null;
      }

      searchText = e.target.value;
      var results = fuse.search(e.target.value);
      
      if (searchResultPosition === "main") {
        if (enableSearchHighlight) {
          renderSearchHighlightResultsMain(searchText, results);
        } else {
          renderSearchResultsMain(searchText, results);
        }
      } else {
        if (enableSearchHighlight) {
          renderSearchHighlightResultsSide(searchText, results);
        } else {
          renderSearchResultsSide(searchText, results);
        }
        
        var dropdownItems = searchResultsContainer.querySelectorAll('.dropdown-item');
        dropdownItems ? dropdownItems.forEach(function(item) {
          item.addEventListener('mousedown', function(e) {
            e.target.click();
          });
        }) : null;
      }
    }) : null;

    searchElem ? 
    searchElem.addEventListener('blur', function() {
      if (window.innerWidth < 770) {
        return null;
      }
      searchResultsContainer ? searchResultsContainer.setAttribute('class', 'dropdown') : null;
    }) : null;

    searchElem ? 
    searchElem.addEventListener('click', function(e) {
      if (window.innerWidth < 770) {
        return null;
      }
      if (!e.target.value) {
        searchResultsContainer ? searchResultsContainer.setAttribute('class', 'dropdown') : null;
        return null;
      }

      searchText = e.target.value;
      var results = fuse.search(e.target.value);

      if (searchResultPosition === "main") {
        if (enableSearchHighlight) {
          renderSearchHighlightResultsMain(searchText, results);
        } else {
          renderSearchResultsMain(searchText, results);
        }
      } else{
        if (enableSearchHighlight) {
          renderSearchHighlightResultsSide(searchText, results);
        } else {
          renderSearchResultsSide(searchText, results);
        }

        var dropdownItems = searchResultsContainer.querySelectorAll('.dropdown-item');
        dropdownItems ? dropdownItems.forEach(function (item) {
          item.addEventListener('mousedown', function (e) {
            e.target.click();
          });
        }) : null;
      }
    }) : null;

    var searchMenuElem = document.getElementById("search-menu");
    var activeItem = document.querySelector('#search-menu .dropdown-item.is-active');
    var activeIndex = null;
    var items = null;
    var searchContainerMaxHeight = 350;

    searchElem ? 
    searchElem.addEventListener('keydown', function(e) {
      if (window.innerWidth < 770) {
        return null;
      }

      if (e.key === 'Escape') {
        searchResult ? searchResult.setAttribute('data-display', 'none') : null;
        summaryContainer ? summaryContainer.setAttribute('data-display', 'block') : null;
      }

      var items = document.querySelectorAll('#search-menu .dropdown-item');
      var keyCode = e.which || e.keyCode;

      if (!items || !items.length) {
        return null;
      }
      
      if (e.key === 'ArrowDown' || keyCode === 40) {
        if (activeIndex === null) {
          activeIndex = 0;
          items[activeIndex].classList.remove('is-active');
        } else {
          items[activeIndex].classList.remove('is-active');
          activeIndex = activeIndex === items.length - 1 ? 0 : activeIndex + 1;
        }
        items[activeIndex].classList.add('is-active');

        let overflowedPixel = items[activeIndex].offsetTop + items[activeIndex].clientHeight - searchContainerMaxHeight;
        if (overflowedPixel > 0) {
          document.querySelector(".search-content").scrollTop += items[activeIndex].getBoundingClientRect().height;
        } else if (activeIndex === 0) {
          document.querySelector(".search-content").scrollTop = 0;
        }
      } else if (e.key === 'ArrowUp' || keyCode === 38) {
        if (activeIndex === null) {
          activeIndex = items.length - 1;
          items[activeIndex].classList.remove('is-active');
        } else {
          items[activeIndex].classList.remove('is-active');
          activeIndex = activeIndex === 0 ? items.length - 1 : activeIndex - 1;
        }
        items[activeIndex].classList.add('is-active');
        
        let overflowedPixel = items[activeIndex].offsetTop + items[activeIndex].clientHeight - searchContainerMaxHeight;
        if (overflowedPixel < 0) {
          document.querySelector(".search-content").scrollTop -= items[activeIndex].getBoundingClientRect().height;
        } else {
          document.querySelector(".search-content").scrollTop = overflowedPixel + items[activeIndex].getBoundingClientRect().height;
        }
      } else if (e.key === 'Enter' || keyCode === 13) {
        if (items[activeIndex] && items[activeIndex].getAttribute('href')) {
          location.href = items[activeIndex].getAttribute('href');
        }
      } else if (e.key === 'Escape' || keyCode === 27) {
        e.target.value = null;
        if (searchResults) {
          searchResults.classList.remove('is-active');
        }
      }
    }) : null;

    searchMobile ? 
    searchMobile.addEventListener('input', function(e) {
      if (!e.target.value) {
        let wrap = document.getElementById('search-mobile-results');
        while (wrap.firstChild) {
          wrap.removeChild(wrap.firstChild);
        }
        return null;
      }

      searchText = e.target.value;
      var results = fuse.search(e.target.value);
      renderSearchResultsMobile(searchText, results);
      if (enableSearchHighlight) {
        renderSearchHighlightResultsMobile(searchText, results);
      } else {
        renderSearchResultsMobile(searchText, results);
      }
    }) : null;
  


  
    var mobileSearchInputElem = document.querySelector('#search-mobile');
    var mobileSearchClassElem = document.querySelector('.mobile-search');
    var mobileSearchBtnElem = document.querySelector('#mobileSearchBtn');
    var mobileSearchCloseBtnElem = document.querySelector('#search-mobile-close');
    var mobileSearchContainer = document.querySelector('#search-mobile-container');
    var mobileSearchResultsElem = document.querySelector('#search-mobile-results');
    var htmlElem = document.querySelector('html');

    if (mobileSearchClassElem) {
      mobileSearchClassElem.style.display = 'none';
    }

    mobileSearchBtnElem ? 
    mobileSearchBtnElem.addEventListener('click', function () {
      if (mobileSearchContainer) {
        mobileSearchContainer.style.display = 'block';
      }

      if (mobileSearchInputElem) {
        mobileSearchInputElem.focus();
      }

      if (htmlElem) {
        htmlElem.style.overflowY = 'hidden';
      }
    }) : null;

    mobileSearchCloseBtnElem ? 
    mobileSearchCloseBtnElem.addEventListener('click', function() {
      if (mobileSearchContainer) {
        mobileSearchContainer.style.display = 'none';
      }

      if (mobileSearchInputElem) {
        mobileSearchInputElem.value = '';
      }
      
      if (mobileSearchResultsElem) {
        while (mobileSearchResultsElem.firstChild) {
          mobileSearchResultsElem.removeChild(mobileSearchResultsElem.firstChild);
        }
      }

      if (htmlElem) {
        htmlElem.style.overflowY = 'visible';
      }
    }) : null;

    mobileSearchInputElem ?
    mobileSearchInputElem.addEventListener('keydown', function(e) {
      var keyCode = e.which || e.keyCode;
      if (e.key === 'Escape' || keyCode === 27) {
        if (mobileSearchContainer) {
          mobileSearchContainer.style.display = 'none';
        }
        
        if (mobileSearchInputElem) {
          mobileSearchInputElem.value = '';
        }

        if (mobileSearchResultsElem) {
          while (mobileSearchResultsElem.firstChild) {
            mobileSearchResultsElem.removeChild(mobileSearchResultsElem.firstChild);
          }
        }
        if (htmlElem) {
          htmlElem.style.overflowY = 'visible';
        }
      }
    }) : null;
  


  
    function renderSearchResultsMain(searchText, results) {
      var searchBody = document.querySelector('.search-result__body');
      var originUl = searchBody.querySelector('ul');
      var ul = document.createElement('ul');
      
      if (!searchText) {
        searchResult ? searchResult.setAttribute('data-display', 'none') : null;
        summaryContainer ? summaryContainer.setAttribute('data-display', 'block') : null;
      } else if (results) {
        if (results && results.length) {
          results.forEach(function (result) {
            makeLi(ul, result);
          });

          searchResult ? searchResult.setAttribute('data-display', 'block') : null;
          summaryContainer ? summaryContainer.setAttribute('data-display', 'none') : null;
        }
      }

      originUl.parentNode.replaceChild(ul, originUl);
    }

    function renderSearchHighlightResultsMain(searchText, results) {
      var searchBody = document.querySelector('.search-result__body');
      var originUl = searchBody.querySelector('ul');
      var ul = document.createElement('ul');

      if (!searchText) {
        searchResult ? searchResult.setAttribute('data-display', 'none') : null;
        summaryContainer ? summaryContainer.setAttribute('data-display', 'block') : null;
      } else if (results) {
        if (results && results.length) {
          results.forEach(function (result) {
            makeHighlightLi(ul, result);
          });

          searchResult ? searchResult.setAttribute('data-display', 'block') : null;
          summaryContainer ? summaryContainer.setAttribute('data-display', 'none') : null;
        }
      }

      originUl.parentNode.replaceChild(ul, originUl);
    }
  
  });
</script>    
    


<link rel="stylesheet" href="/css/main.min.css">


    
<meta name="description" content="" />
<meta name="keywords" content="">
<meta name="created" content="2018-04-05T16:00:00&#43;0900">
<meta name="modified" content="2020-05-16T19:02:31&#43;0900">
<meta property="article:published_time" content="2018-04-05T16:00:00&#43;0900">

<meta name="author" content="Hoontaek Lee">
<meta property="article:author" content="https://hoontaeklee.github.io/en/posts/20200516_islr/@Hoontaek Lee">


<meta property="og:site_name" content="bloght">
<meta property="og:title" content="ISLR Note">
<meta property="og:url" content="https://hoontaeklee.github.io/en/posts/20200516_islr/">
<meta property="og:type" content="article">
<meta property="og:description" content="">

<meta name="generator" content="Hugo 0.64.1" />
<meta name="msapplication-TileColor" content="#fff">

<meta name="theme-color" content="#fff">

<meta name="msapplication-navbutton-color" content="#fff">

<meta name="apple-mobile-web-app-status-bar-style" content="#fff">
<link rel="canonical" href="https://hoontaeklee.github.io/en/posts/20200516_islr/">
<link rel="manifest" href="/manifest.json">

  <link rel="apple-touch-icon" sizes="57x57" href="/favicon/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/favicon/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/favicon/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/favicon/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/favicon/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/favicon/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/favicon/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/favicon/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="/favicon/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="192x192" href="/favicon/android-icon-512x512.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/favicon/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/ms-icon-144x144.png">


    <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "WebPage",
    "headline": "ISLR Note",
    "datePublished": "2018-04-05T16:00:00+09:00",
    "dateModified": "2020-05-16T19:02:31+09:00",
    "url" : "https://hoontaeklee.github.io/en/posts/20200516_islr/",
    "description": "2. Statistical Learning 2.1. What Is Statistical Learning? Y = f(X) + e 여기서 함수 f는 X가 담고 있는 Y에 대한 systematic information이다. e는 f가 표현하지 못하는 random error term이다. e는 X에 독",
    "keywords": ["2020","Book Review","R"],
    "author": {
      "@type": "Person",
      "name": "Hoontaek Lee"
    },
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://hoontaeklee.github.io"
    },
    "publisher": {
      "@type": "Organization",
      "name": "bloght",
      "url": "https://hoontaeklee.github.io"
    }
  }
</script>

    
  
  







    
</head>

<body id="root" class="theme__dark">
    <script>
        var localTheme = localStorage.getItem('theme');
        if (localTheme) {
            document.getElementById('root').className = 'theme__' + localTheme;
        }
    </script>
    <div id="container">
        
        <div class="wrapper" data-type="posts" data-kind="page">
            <nav class="navbar" role="navigation" aria-label="main navigation" data-dir="ltr">
  <div class="navbar__brand">
    
    <a href="/en/" title="Home" rel="home" class="navbar__logo-link">
      <img src="/logo.png" alt="Home" class="navbar__logo">
    </a>
    
    
      <a href="/en/" title="Home" rel="home" class="navbar__title-link">
        <h6 class="navbar__title">bloght</h6>
      </a>
    
  </div>

  
<div class="theme theme-mobile" data-ani="true">
  <div class="dropdown">
    <button class="dropdown-trigger navbar__slide-down" aria-label="Select Theme Button" style="" data-ani="true">
      <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24"><path fill="none" d="M24 0H0v24h24V0z"/><path fill="currentColor" d="M6.34 7.93c-3.12 3.12-3.12 8.19 0 11.31C7.9 20.8 9.95 21.58 12 21.58s4.1-.78 5.66-2.34c3.12-3.12 3.12-8.19 0-11.31l-4.95-4.95c-.39-.39-1.02-.39-1.41 0L6.34 7.93zM12 19.59c-1.6 0-3.11-.62-4.24-1.76C6.62 16.69 6 15.19 6 13.59s.62-3.11 1.76-4.24L12 5.1v14.49z"/></svg>      
    </button>
    <div class="dropdown-content select-theme">
      
        
        <a href="#" class="dropdown-item select-theme__item is-active">
          dark
        </a>
        
        <a href="#" class="dropdown-item select-theme__item ">
          light
        </a>
        
        <a href="#" class="dropdown-item select-theme__item ">
          hacker
        </a>
        
        <a href="#" class="dropdown-item select-theme__item ">
          solarized
        </a>
        
        <a href="#" class="dropdown-item select-theme__item ">
          kimbie
        </a>
        
      
    </div>
  </div>
</div>


<div id="mobileSearchBtn" class="mobile-search__btn" data-ani="true">
  <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M15.5 14h-.79l-.28-.27c1.2-1.4 1.82-3.31 1.48-5.34-.47-2.78-2.79-5-5.59-5.34-4.23-.52-7.79 3.04-7.27 7.27.34 2.8 2.56 5.12 5.34 5.59 2.03.34 3.94-.28 5.34-1.48l.27.28v.79l4.25 4.25c.41.41 1.08.41 1.49 0 .41-.41.41-1.08 0-1.49L15.5 14zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/></svg>
</div>

<div id="search-mobile-container" class="mobile-search hide" data-dir="ltr">
  <div class="mobile-search__top">
    <input id="search-mobile" type="text" aria-label="Mobile Search" placeholder="Search" class="mobile-search__top--input"/>
    <div id="search-mobile-close" class="mobile-search__top--icon">
      <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24"><path opacity=".87" fill="none" d="M0 0h24v24H0V0z"/><path fill="currentColor" d="M12 2C6.47 2 2 6.47 2 12s4.47 10 10 10 10-4.47 10-10S17.53 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8zm3.59-13L12 10.59 8.41 7 7 8.41 10.59 12 7 15.59 8.41 17 12 13.41 15.59 17 17 15.59 13.41 12 17 8.41z"/></svg>
    </div>
  </div>
  <div id="search-mobile-results" class="mobile-search__body">
    
  </div>
</div>


<a role="button" class="navbar__burger" aria-label="menu" aria-expanded="false"
  data-ani="true">
  <span aria-hidden="true"></span>
  <span aria-hidden="true"></span>
  <span aria-hidden="true"></span>
</a>
<div class="navbarm__collapse" data-open="false">
  <ul>
    
    
      
      
      
      
      <li class="navbarm__menu--item ">
        <a href="/en/about">About</a>
      </li>
    
      
      
      
      
      <li class="navbarm__menu--item ">
        <a href="/en/archive">Archive</a>
      </li>
    
      
      
      
      
      <li class="navbarm__menu--item ">
        <a href="/en/tags">Tags</a>
      </li>
    

    
  </ul>
</div>
  <div class="navbar__menu">
  
<div class="theme" data-ani="true">
  <div class="dropdown">
    <button class="dropdown-trigger navbar__slide-down" aria-label="Select Theme Button" data-ani="true">
      <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24"><path fill="none" d="M24 0H0v24h24V0z"/><path fill="currentColor" d="M6.34 7.93c-3.12 3.12-3.12 8.19 0 11.31C7.9 20.8 9.95 21.58 12 21.58s4.1-.78 5.66-2.34c3.12-3.12 3.12-8.19 0-11.31l-4.95-4.95c-.39-.39-1.02-.39-1.41 0L6.34 7.93zM12 19.59c-1.6 0-3.11-.62-4.24-1.76C6.62 16.69 6 15.19 6 13.59s.62-3.11 1.76-4.24L12 5.1v14.49z"/></svg>      
    </button>
    <div class="dropdown-content select-theme">
      
        
        <a href="#" class="dropdown-item select-theme__item is-active">
          dark
        </a>
        
        <a href="#" class="dropdown-item select-theme__item ">
          light
        </a>
        
        <a href="#" class="dropdown-item select-theme__item ">
          hacker
        </a>
        
        <a href="#" class="dropdown-item select-theme__item ">
          solarized
        </a>
        
        <a href="#" class="dropdown-item select-theme__item ">
          kimbie
        </a>
        
      
    </div>
  </div>
</div>

  
  
  
  
  
  
  
  <a href="/en/about" class="navbar__menu-item navbar__slide-down " dir="ltr" data-ani="true">About</a>
  
  
  
  
  
  
  
  <a href="/en/archive" class="navbar__menu-item navbar__slide-down " dir="ltr" data-ani="true">Archive</a>
  
  
  
  
  
  
  
  <a href="/en/tags" class="navbar__menu-item navbar__slide-down " dir="ltr" data-ani="true">Tags</a>
  
  
</div>
</nav>
            
            

<main class="single__main main">
  
    <nav class="breadcrumb hide" aria-label="breadcrumbs">
  <script>document.querySelector('.breadcrumb').classList.remove('hide')</script>
  <ol>
    
  
  
  
  
  
  <li >
    
      <a href="https://hoontaeklee.github.io/en/" class="capitalize">Home</a>
    
  </li>
  
  
  <li >
    
      <a href="https://hoontaeklee.github.io/en/posts/" class="capitalize">Blog</a>
    
  </li>
  
  
  <li  class="is-active" >
    
      <span>ISLR Note</span>
    
  </li>
  
  </ol>
  
</nav>
  
  <noscript>
    Please enable Javascript to view the contents
  </noscript>
  <div class="single hide">
    <script>document.querySelector('.single').classList.remove('hide')</script>
    <h2 class="single__title" data-ani="true">ISLR Note</h2>
    <div class="single__meta">
      
<div class="single__infos">
  <time class="single__info" title="Written At">📅&nbsp;Apr 5, 2018 </time>  &middot; <span class="single__info" title="Reading Time"> ☕ 34 min read </span>&middot; <span class="single__info" title="WRITTEN BY">✍️&nbsp;Hoontaek Lee</span>
  <span class="single__info">
    
  </span>
</div>
      
<div class="single__tags caption">

  
    🏷️
  
  
    <li><a href="https://hoontaeklee.github.io/en/tags/2020/" class="single__tag" title="2020">#2020</a></li>
  

  
  
    <li><a href="https://hoontaeklee.github.io/en/tags/book-review/" class="single__tag" title="Book Review">#Book Review</a></li>
  

  
  
    <li><a href="https://hoontaeklee.github.io/en/tags/r/" class="single__tag" title="R">#R</a></li>
  

</div>
    </div>
    <article class="single__contents" data-dir="ltr" data-ani="true">
      
      <h1 id="2-statistical-learning">2. Statistical Learning</h1>
<h2 id="21-what-is-statistical-learning">2.1. What Is Statistical Learning?</h2>
<p><em>Y</em> = <em>f</em>(<em>X</em>) + <em>e</em><br />
여기서 함수 <em>f</em>는 <em>X</em>가 담고 있는 <em>Y</em>에 대한 <strong>systematic information</strong>이다.<br />
<em>e</em>는 <em>f</em>가 표현하지 못하는 <strong>random error term</strong>이다.<br />
<em>e</em>는 <em>X</em>에 독립이고 평균값은 0이다.</p>
<p><strong>Statistical learning</strong>은 위의 함수 <em>f</em>를 찾는 다양한 방법을 모두 일컫는다.</p>
<h3 id="211-why-estimate-f">2.1.1. Why Estimate <em>f</em>?</h3>
<ul>
<li>
<p>prediction</p>
<ul>
<li>측정값 <em>X</em>로 <em>Y</em> 값을 예측한다(<em>Y</em> = <em>f</em>(<em>X</em>)).</li>
<li><em>f</em>는 <em>black box</em>로 남아도 상관 없다(<em>Y</em>만 잘 맞추면 된다).</li>
<li>이 때 발생하는 에러는 두 가지: <u>reducible</u>, <u>irreducible</u>.</li>
<li>reducible: <em>f</em>를 더 잘 예측하면 줄일 수 있다.</li>
<li>irreducible: 측정 항목에서 어떤 중요한 변수를 놓치고 있거나,<br />
혹은 측정 불가능한 요소(예: 약물 투여 때 환자의 심리)가 개입하기 때문에 발생한다.</li>
</ul>
</li>
<li>
<p>inference</p>
<ul>
<li><em>Y</em>와 각 <em>X</em>의 관계를 정확히 파악하고 싶다.</li>
<li><em>f</em>는 <em>black box</em>로 남으면 안 된다.</li>
<li>어떤 <em>X</em>가 <em>Y</em>와 더 관계가 강한지, 여러 <em>X</em>와 <em>Y</em>의 관계는 선형인지 비선형인지 등.</li>
</ul>
</li>
</ul>
<p>문제에 따라서</p>
<ul>
<li>prediction과 inference 중 하나만, 혹은 둘 다 필요할 수 있다.</li>
<li>간단한 선형 모형으로도 만족할 수도 있고, 복잡한 비선형 모형을 사용해야 할 수도 있다.</li>
</ul>
<h3 id="212-how-do-we-estimate-f">2.1.2. How Do We Estimate <em>f</em>?</h3>
<p><em>f</em>를 찾는 데는 여러 방법이 있는데, 이들이 공통으로 가지는 특징이 있다.</p>
<ul>
<li>training data: {(<em>x</em>~1~, <em>y</em>~1~), &hellip;, (<em>x</em><em>~n~</em>, <em>y</em><em>~n~</em>)}</li>
<li>parametric or non-parametric method 중에 하나다.</li>
<li>parametric methods
<ul>
<li><em>f</em>의 형태(equation, distribution, &hellip;)를 상정한 후(parameter가 정해진다)</li>
<li>parameter 값을 추정해서 <em>f</em>를 결정한다.</li>
<li><em>f</em>를 찾는 문제가 몇개의 paraemters를 추정하는 문제로 바뀐다(쉬워진다).</li>
<li><em>f</em>의 형태를 잘못 상정했다면 오차가 커질 수 있다.</li>
<li>위의 경우를 방지하기 위해 <em>f</em>의 형태에 <u>flexibility</u>를 높이고자 한다면 더 많은 parameters가 필요하고,<br />
따라서 <u>overfitting</u>이 발생할 확률도 높아진다.</li>
</ul>
</li>
<li>non-parametric methods
<ul>
<li><em>f</em>에 특정한 형태를 상정하지 않는다.</li>
<li>때문에 <em>f</em>가 실제로 어떤 형태를 갖더라도 정확히 추정할 잠재력이 있는 방법이다.</li>
<li>단, parameter estimation이라는 쉬운 문제로 바꾸지 않았기 때문에<br />
parametric methods보다 훨씬 많은 관측 데이터가 필요하다.</li>
</ul>
</li>
</ul>
<h3 id="213-the-trade-off-between-prediction-accuracy-and-model-interpretability">2.1.3. The Trade-Off Between Prediction Accuracy and Model Interpretability</h3>
<p>restrictive &ndash;&gt; interpertable (inference 목적에 적합)<br />
하지만, prediction 목적에서도 꼭 the most flexible approach를 사용하는 게 정답은 아니다(2.2에서 다룰 예정).</p>
<h3 id="214-supervised-versus-unsupervised-learning">2.1.4. Supervised Versus Unsupervised Learning</h3>
<p>supervised: <em>Y</em> 관측값 존재 &lt;-&gt; unsupervised</p>
<h3 id="215-regression-versus-classification-problems">2.1.5. Regression Versus Classification Problems</h3>
<p><strong>response variable</strong>이<br />
연속형 &ndash;&gt; regression<br />
범주형 &ndash;&gt; classification</p>
<p>일반적으로 <strong>predictor</strong>는 연속형, 범주형 각각에 맞춰 코딩 가능하기 때문에 위의 판정에서는 덜 중요하다.</p>
<h2 id="22-assessing-model-accuracy">2.2. Assessing Model Accuracy</h2>
<p>모든 상황에 만능인 모델은 없다.<br />
해결해야 할 문제에 따라, 주어진 데이터에 따라 가장 적합한 모델이 매번 달라진다.</p>
<p>그래서 상황마다 매번 여러 모델을 비교해본다.</p>
<h3 id="221-measuring-the-quality-of-fit">2.2.1. Measuring the Quality of Fit</h3>
<p>Mean squared error(MSE): regression setting에서는 가장 많이 사용한다.</p>
<blockquote>
<p><em>MSE</em><br />
= $\frac{1}{n}$$\sum_{i=1}^{n}$(*y*~*i*~ - $\hat{f}$(*x*~*i*~))^2^<br />
= Ave(*y*~*i*~ - $\hat{f}$(*x*~*i*~)^2^)</p>
</blockquote>
<p>training MSE vs test MSE: 우리가 관심 있는 건 minimize(test MSE).</p>
<p>(Figure 2.9)</p>
<ol>
<li>training MSE는 flexibility가 증가할수록 단조 감소하는 패턴을 보이고,</li>
<li>test MSE는 flexibility와 U자형 관계를 보인다.<br />
즉, training MSE를 낮추기 위해 flexibility를 마구 증가시키면<br />
정작 test MSE는 restrictive model보다 오히려 더 높아질 수 있다(<strong>overfitting</strong>).</li>
</ol>
<p>2의 U자형 관계로부터 <strong>test MSE에 최솟값이 존재</strong>함을 확인했는데,<br />
<u>최소 MSE를 가지는 model을 찾는 방법</u>도 다루게 될 것이다(예: 5장의 cross-validation).</p>
<h3 id="222-the-bias-variance-trade-off">2.2.2. The Bias-Variance Trade-Off</h3>
<p>test MSE 기댓값 =  함숫값의 분산 + 함숫값의 bias 제곱 + 오차항 분산<br />
우변의 세 항 모두 0 이상이기 때문에 좌변의 최솟값은 오차항 분산(irreducible error)이 된다.</p>
<p>flexible <em>f</em> &ndash;&gt; high variance(데이터에 따라 <em>f</em> 형태가 쉽게 변한다), low bias(데이터를 잘 맞춘다)</p>
<p>(Figure 2.12)<br />
flexibility가 증가하기 시작하면</p>
<p>처음에는<br />
bias가 감소하는 속도 &gt; variance가 증가하는 속도  &ndash;&gt; test MSE 감소</p>
<p>일정 지점이 지나면<br />
bias가 감소하는 속도 &lt; variance가 증가하는 속도  &ndash;&gt; test MSE 증가</p>
<h3 id="223-the-classification-setting">2.2.3. The Classification Setting</h3>
<p>MSE &ndash;&gt; regression setting에서 사용한다.<br />
classification setting에서는 <strong>error rate</strong>를 사용한다(minimize).</p>
<blockquote>
<p>error rate = (<em>y</em> 범주를 잘못 예측한 데이터 개수) / (전체 데이터 개수)</p>
</blockquote>
<h1 id="5-resampling-methods">5. Resampling Methods</h1>
<p>Resampling Methods</p>
<ul>
<li>같은 training data에서 샘플 추출 -&gt; model fitting 반복하는 과정이다.</li>
<li>어떤 추가 정보(?)를 얻을 수 있다.</li>
<li>cross-validation: flexibility 결정하거나 test error 구할 때 사용한다.</li>
<li>bootstrap: parameter estimate accuracy 평가할 때 가장 많이 사용한다.</li>
</ul>
<p>model assessment: model performance 평가<br />
model selection: model flexibility 선택</p>
<h2 id="51-cross-validation">5.1. Cross-Validation</h2>
<h3 id="511-the-validation-set-approach">5.1.1. The Validation Set Approach</h3>
<p>전체 데이터를 같은 크기의 두 subsets - <em>training set</em> + <em>validation set</em> (or <em>hold-out set</em>) - 으로 나눈다. <strong>랜덤하게</strong>.<br />
training set을 이용해 model fitting 후 validation set으로 test error (e.g. MSE) 계산한다.</p>
<ul>
<li>두 가지 단점
<ul>
<li>데이터를 나눌 때마다 MSE가 달라진다.</li>
<li>model fitting에 수집한 데이터를 모두 활용할 수 없다 &ndash;&gt; MSE가 과대평가된다.</li>
</ul>
</li>
</ul>
<p>위 단점을 해결한다 &ndash;&gt; <strong>cross-validation</strong></p>
<h3 id="512-leave-one-out-cross-validation">5.1.2. Leave-One-Out Cross-Validation</h3>
<p>(<em>x</em>~1~, <em>y</em>~1) 제외한 <em>n</em>-1 개 데이터를 사용해 training한다.<br />
남겨둔 데이터로 test error rate(MSE~1~)를 계산한다.<br />
같은 방법으로 test 데이터를 (<em>x</em>~<em>n</em>~, <em>y</em>~<em>n</em>)까지 변경하며 n번 진행, MSE~<em>n</em>~까지 구한다.</p>
<p>test error rate = CV~(<em>n</em>)~ = Ave(MSE~<em>i</em>~)</p>
<ul>
<li>LOOCV 장점(= validation set approach의 단점 해결)
<ul>
<li>데이터를 충분히 사용하기 때문에 bias를 과대평가할 위험도가 validation set approach보다 낮다.</li>
<li>test error rate가 일정하다.</li>
</ul>
</li>
</ul>
<p>LOOCV는 대부분의 predictive modeling에 적용할 수 있다.<br />
least square linear (or polynomial) regression에서는 CV~(<em>n</em>)~을 더 간단하게 계산할 수 있다(식 5.2).</p>
<h3 id="513-k-fold-cross-validation">5.1.3. k-Fold Cross-Validation</h3>
<p>LOOCV와 비슷한데, test로 사용할 데이터를 한 개씩이 아니라 한 그룹씩 남기는 차이가 있다.</p>
<p>fold = group<br />
데이터를 같은 크기의 <em>k</em>개 그룹으로 랜덤하게 나눈다.<br />
1^st^ 그룹을 제외한 나머지로 training, 남겨둔 그룹으로 error rate 계산(MSE~1~)<br />
<em>k</em>^th^ 그룹까지 진행(MSE~<em>k</em>~).</p>
<p>test error rate = CV~(<em>k</em>)~ = Ave(MSE~<em>i</em>~)</p>
<p><u>LOOCV는 <em>k</em>=<em>n</em>인 <em>k</em>-Fold CV로 볼 수 있다.</u><br />
보통 <em>k</em>는 5나 10을 사용한다.</p>
<ul>
<li>계산량이 줄어들기 때문</li>
<li>5나 10을 사용해도 LOOCV와 flexiblility with minimum MSE 결과가 비슷하기 때문</li>
</ul>
<h3 id="514-bias-variance-trade-off-for-k-fold-cross-validation">5.1.4. Bias-Variance Trade-Off for k-Fold Cross-Validation</h3>
<p><em>k</em>-fold CV에서 <em>k</em> 값에 따라 bias-variance trade-off가 발생한다.</p>
<p><em>k</em>가 <em>n</em>에 가까울수록<br />
예측치의 bias는 감소하고() 분산은 증가한다.</p>
<p><em>k</em>로 5나 10을 많이 사용하는 이유 : test error rate가 가장 작기 때문</p>
<h3 id="515-cross-validation-on-classification-problems">5.1.5. Cross-Validation on Classification Problems</h3>
<p>CV 수식에서 MSE 대신 잘못 분류한 데이터 비율을 사용한다.</p>
<h2 id="52-the-bootstrap">5.2. The Bootstrap</h2>
<p>관측 데이터로부터 새로운 데이터셋을 만드는 기법이다.<br />
랜덤하게, 원래 관측데이터와 같은 크기만큼 재추출한다.<br />
복원 혹은 비복원 추출 선택.</p>
<p>예)<br />
데이터가 세 개 밖에 없어도<br />
크기가 3인 데이터셋 B개를 새로 만들어서<br />
각 데이터셋마다 estimates 계산하고(총 B개), 이로부터 standard error 계산한다.</p>
<ul>
<li>can be used <strong>to quantify the uncertainty</strong> associated with a given estimatior or statistical learning method (예: 선형회귀에서 추정한 모수값의 표준오차).</li>
<li>선형회귀 외 많은 모형에도 쉽게 적용 가능!</li>
</ul>
<pre><code>(식 5.8에서)

왜 괄호 안이 alpha - alpha_hat이 아니지?  
    
alpha의 참값을 모른다고 가정하기 때문에  
alpha_hat을 참값 대신 사용하고, 각 alpha마다 bootstrap을 B번 실행해서 alpha의 SS를 계산하는 건가?
</code></pre><h2 id="53-lab-cross-validation-and-the-bootstrap">5.3. Lab: Cross-Validation and the Bootstrap</h2>
<h3 id="531-the-validation-set-approach">5.3.1. The Validation Set Approach</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">library</span><span class="p">(</span><span class="n">ISLR</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span> <span class="c1"># set seed to get the same results at a later time</span>
<span class="n">train</span> <span class="o">=</span> <span class="nf">sample</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="m">392</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="m">196</span><span class="p">)</span> <span class="c1"># training subset</span>

<span class="c1"># fit a simple linear model</span>
<span class="n">lm.fit</span> <span class="o">=</span> <span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="n">horsepower</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="n">train</span><span class="p">)</span>
<span class="nf">attach</span><span class="p">(</span><span class="n">Auto</span><span class="p">)</span>
<span class="nf">mean</span><span class="p">(</span><span class="p">(</span><span class="n">mpg</span> <span class="o">-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">lm.fit</span><span class="p">,</span> <span class="n">Auto</span><span class="p">)</span><span class="p">)</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="n">]</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span> <span class="c1"># compute MSE</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 23.26601
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># fit a quadratic linear model </span>
<span class="n">lm.fit2</span> <span class="o">=</span> <span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="nf">poly</span><span class="p">(</span><span class="n">horsepower</span><span class="p">,</span> <span class="m">2</span><span class="p">)</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="n">train</span><span class="p">)</span>
<span class="nf">mean</span><span class="p">(</span><span class="p">(</span><span class="n">mpg</span> <span class="o">-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">lm.fit2</span><span class="p">,</span> <span class="n">Auto</span><span class="p">)</span><span class="p">)</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="n">]</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span> <span class="c1"># compute MSE</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 18.71646
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># fit a cubic linear model </span>
<span class="n">lm.fit3</span> <span class="o">=</span> <span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="nf">poly</span><span class="p">(</span><span class="n">horsepower</span><span class="p">,</span> <span class="m">3</span><span class="p">)</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="n">train</span><span class="p">)</span>
<span class="nf">mean</span><span class="p">(</span><span class="p">(</span><span class="n">mpg</span> <span class="o">-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">lm.fit3</span><span class="p">,</span> <span class="n">Auto</span><span class="p">)</span><span class="p">)</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="n">]</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span> <span class="c1"># compute MSE</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 18.79401
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">plot</span><span class="p">(</span><span class="n">horsepower</span><span class="p">,</span> <span class="n">mpg</span><span class="p">)</span> <span class="c1"># looks like a curve fit is better than a straight line</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/5.3.1.-1.png" alt="" /><!-- --></p>
<h3 id="532-leave-one-out-cross-validation">5.3.2. Leave-One-Out Cross-Validation</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">lm.fit</span> <span class="o">=</span> <span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="n">horsepower</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">)</span>
<span class="n">glm.fit</span> <span class="o">=</span> <span class="nf">glm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="n">horsepower</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">)</span>

<span class="nf">coef</span><span class="p">(</span><span class="n">lm.fit</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## (Intercept)  horsepower 
##  39.9358610  -0.1578447
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">coef</span><span class="p">(</span><span class="n">glm.fit</span><span class="p">)</span> <span class="c1"># glm() w/o family argument --&gt; lm()</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## (Intercept)  horsepower 
##  39.9358610  -0.1578447
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## cv for a simple linear fit</span>
<span class="nf">library</span><span class="p">(</span><span class="n">boot</span><span class="p">)</span>
<span class="n">glm.fit</span> <span class="o">=</span> <span class="nf">glm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="n">horsepower</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">)</span>
<span class="n">cv.err</span> <span class="o">=</span> <span class="nf">cv.glm</span><span class="p">(</span><span class="n">Auto</span><span class="p">,</span> <span class="n">glm.fit</span><span class="p">)</span>
<span class="n">cv.err</span><span class="o">$</span><span class="n">delta</span> <span class="c1"># CV(n) results: standard one, bias-corrected one</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 24.23151 24.23114
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## cv iteration for polynomial fit of order 1 to 5 </span>
<span class="n">cv.error</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">5</span><span class="p">)</span>
<span class="nf">for</span><span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">)</span><span class="p">{</span>
  <span class="n">glm.fit</span> <span class="o">=</span> <span class="nf">glm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="nf">poly</span><span class="p">(</span><span class="n">horsepower</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">)</span>
  <span class="n">cv.error</span><span class="n">[i</span><span class="n">]</span> <span class="o">=</span> <span class="nf">cv.glm</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">,</span> <span class="n">glmfit</span> <span class="o">=</span> <span class="n">glm.fit</span><span class="p">)</span><span class="o">$</span><span class="n">delta</span><span class="n">[1</span><span class="n">]</span>
<span class="p">}</span>
<span class="n">cv.error</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 24.23151 19.24821 19.33498 19.42443 19.03321
</code></pre><h3 id="533-k-fold-cross-validation">5.3.3. k-Fold Cross-Validation</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">set.seed</span><span class="p">(</span><span class="m">17</span><span class="p">)</span>
<span class="n">cv.error.10</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">10</span><span class="p">)</span>
<span class="nf">for</span><span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">)</span><span class="p">{</span>
  <span class="n">glm.fit</span> <span class="o">=</span> <span class="nf">glm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="nf">poly</span><span class="p">(</span><span class="n">horsepower</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">)</span>
  <span class="n">cv.error.10</span><span class="n">[i</span><span class="n">]</span> <span class="o">=</span> <span class="nf">cv.glm</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">,</span> <span class="n">glmfit</span> <span class="o">=</span> <span class="n">glm.fit</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="m">10</span><span class="p">)</span><span class="o">$</span><span class="n">delta</span><span class="n">[1</span><span class="n">]</span>
  <span class="c1"># much shorter running time than that of LOOCV</span>
<span class="p">}</span>

<span class="c1"># still cubic or higher order terms don&#39;t seem superior</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">cv.error.10</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">b&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/5.3.3.-1.png" alt="" /><!-- --></p>
<h3 id="534-the-bootstrap">5.3.4. The Bootstrap</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## accuracy of regression model --&gt; standard error of parameter estimated</span>
<span class="c1">## bootstrap can be applied to compute the se</span>

<span class="nf">library</span><span class="p">(</span><span class="n">boot</span><span class="p">)</span>

<span class="c1">## 1. create a function to compute statistics of interest</span>
<span class="n">alpha.fn</span> <span class="o">=</span> <span class="nf">function</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span><span class="p">{</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">$</span><span class="n">X</span><span class="n">[index</span><span class="n">]</span>
  <span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">$</span><span class="n">Y</span><span class="n">[index</span><span class="n">]</span>
  <span class="nf">return</span><span class="p">(</span><span class="p">(</span><span class="nf">var</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">-</span> <span class="nf">cov</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nf">var</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="nf">var</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">-</span> <span class="m">2</span> <span class="o">*</span> <span class="nf">cov</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span><span class="p">)</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1">## 2. boot()</span>


<span class="c1">## compute an alpha value (a kind of statistics)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="nf">alpha.fn</span><span class="p">(</span><span class="n">Portfolio</span><span class="p">,</span> <span class="nf">sample</span><span class="p">(</span><span class="m">100</span><span class="p">,</span> <span class="m">100</span><span class="p">,</span> <span class="n">replace</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span><span class="p">)</span> 
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 0.7368375
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## repeat 1000 times with bootstrap</span>
<span class="nf">boot</span><span class="p">(</span><span class="n">Portfolio</span><span class="p">,</span> <span class="n">alpha.fn</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="m">1000</span><span class="p">)</span> 
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Portfolio, statistic = alpha.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##      original       bias    std. error
## t1* 0.5758321 -0.001695873  0.09366347
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># se(alpha_hat) = 0.5758321 +- 0.08861826</span>


<span class="c1">## linear regression coef. estimates</span>
<span class="n">boot.fn</span> <span class="o">=</span> <span class="nf">function</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span><span class="p">{</span>
  <span class="nf">return</span><span class="p">(</span><span class="nf">coef</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="n">horsepower</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="n">index</span><span class="p">)</span><span class="p">)</span><span class="p">)</span>
<span class="p">}</span>

<span class="nf">boot.fn</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="m">1</span><span class="o">:</span><span class="m">392</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## (Intercept)  horsepower 
##  39.9358610  -0.1578447
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="nf">boot.fn</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="nf">sample</span><span class="p">(</span><span class="m">392</span><span class="p">,</span> <span class="m">392</span><span class="p">,</span> <span class="n">replace</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## (Intercept)  horsepower 
##  40.3404517  -0.1634868
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">boot.fn</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="nf">sample</span><span class="p">(</span><span class="m">392</span><span class="p">,</span> <span class="m">392</span><span class="p">,</span> <span class="n">replace</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## (Intercept)  horsepower 
##  40.1186906  -0.1577063
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># with replacement --&gt; the result can vary</span>

<span class="nf">boot</span><span class="p">(</span><span class="n">Auto</span><span class="p">,</span> <span class="n">boot.fn</span><span class="p">,</span> <span class="m">1000</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Auto, statistic = boot.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##       original        bias    std. error
## t1* 39.9358610  0.0544513229 0.841289790
## t2* -0.1578447 -0.0006170901 0.007343073
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># compare to</span>
<span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="n">horsepower</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">)</span><span class="p">)</span><span class="o">$</span><span class="n">coef</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>##               Estimate  Std. Error   t value      Pr(&gt;|t|)
## (Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187
## horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># se estimates are more accurate in boot() than in lm() (see ISLR 196p)</span>

<span class="c1">## better fit --&gt; more similar se between boot() and summary()</span>
<span class="n">boot.fn</span> <span class="o">=</span> <span class="nf">function</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span><span class="p">{</span>
  <span class="nf">coefficients</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="n">horsepower</span> <span class="o">+</span> <span class="nf">I</span><span class="p">(</span><span class="n">horsepower</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span><span class="p">,</span> 
                  <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> 
                  <span class="n">subset</span> <span class="o">=</span> <span class="n">index</span><span class="p">)</span><span class="p">)</span>
<span class="p">}</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="nf">boot</span><span class="p">(</span><span class="n">Auto</span><span class="p">,</span> <span class="n">boot.fn</span><span class="p">,</span> <span class="m">1000</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Auto, statistic = boot.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##         original        bias     std. error
## t1* 56.900099702  3.511640e-02 2.0300222526
## t2* -0.466189630 -7.080834e-04 0.0324241984
## t3*  0.001230536  2.840324e-06 0.0001172164
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">summary</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span> <span class="o">~</span> <span class="n">horsepower</span> <span class="o">+</span> <span class="nf">I</span><span class="p">(</span><span class="n">horsepower</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span><span class="p">,</span> 
                  <span class="n">data</span> <span class="o">=</span> <span class="n">Auto</span><span class="p">)</span><span class="p">)</span><span class="o">$</span><span class="n">coef</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>##                     Estimate   Std. Error   t value      Pr(&gt;|t|)
## (Intercept)     56.900099702 1.8004268063  31.60367 1.740911e-109
## horsepower      -0.466189630 0.0311246171 -14.97816  2.289429e-40
## I(horsepower^2)  0.001230536 0.0001220759  10.08009  2.196340e-21
</code></pre><h1 id="7-moving-beyond-linearity">7. Moving Beyond Linearity</h1>
<h2 id="74-regression-splines">7.4. Regression Splines</h2>
<h3 id="741-piecewise-polynomials">7.4.1. Piecewise Polynomials</h3>
<p>knot라고 부르는 위치를 기준으로 구간을 나눠서 polynomial regression fitting을 수행한다.<br />
knot에서 각 곡선이 툭툭 끊어질 수 있다.</p>
<h3 id="742-constraints-and-splines">7.4.2. Constraints and Splines</h3>
<p>툭툭 끊기지 않고 부드럽게 이어지는 spline curve를 만들기 위해 아래의 constraints를 추가 (삼차식일 경우)</p>
<ul>
<li>knot에서 함숫값</li>
<li>knot에서 미분계수</li>
<li>knot에서 이차미분계수</li>
</ul>
<p>일차식이라면 첫 번째 조건만으로도 충분하다.</p>
<h1 id="8-tree-based-methods">8. Tree-Based Methods</h1>
<ul>
<li><em>tree-based</em> methods = <em>decision tree</em> methods : 설명변수를 여러 구간으로 나눈다</li>
<li>regression, classification 모두 가능하다</li>
<li>해석이 (그나마) 용이하다</li>
<li>단순한 tree 구조만으로는 다른 머신러닝 기법에 비해 예측 정확도가 낮다</li>
<li><em>bagging</em>, <em>random forests</em>, <em>boosting</em> 이용 &ndash;&gt; 모형이 복잡해진다 &ndash;&gt;  예측 정확도 &lt;-&gt; 해석 용이성 trade-off</li>
</ul>
<h2 id="81-the-basics-of-decision-trees">8.1. The Basics of Decision Trees</h2>
<h3 id="811-regression-trees">8.1.1. Regression Trees</h3>
<p>decision tree의 형태와 관련된 용어는 거꾸로 꽂아 놓은 나무를 떠올리면 이해하기 쉽다.</p>
<ul>
<li>terminal nodes (leaves): 가장 아래 적혀있는 구역별 y값</li>
<li>internal node: 분기점</li>
<li>branch: 각 node를 잇는 선</li>
</ul>
<p>나무 상단에 위치할 수록 예측에 영향이 큰 조건(분기점)이다.<br />
조건에 따라 그릴 수 있고 위와 같이 해석이 가능하기 때문에 regression tree는 시각화, 해석이 모두 용이하다.</p>
<p>\</p>
<h4 id="recursive-binary-splitting"><strong>Recursive Binary Splitting</strong></h4>
<p>regression tree를 만드는 방법: 1. predictor의 구간을 나눈다, 2. 각 구간별로 예측값(평균, &hellip;)을 구한다.<br />
그렇다면 구간은 어떻게 나눌까? &ndash;&gt; 목적함수를 둔다.</p>
<ul>
<li>구간별 RSS를 구해서 그 합계가 최소가 되도록 구역을 나눈다</li>
</ul>
<p>하지만 가능한 모든 경우의 수에서 위의 계산을 하려면 양이 너무 많다.<br />
그래서 <em>top-down</em>, <em>greedy</em> approach 혹은 <em>recursive binary splitting</em> 알고리즘을 사용한다.</p>
<ul>
<li>top-down: 상위 노드(구역 갯수가 1개인 상태)에서 시작하기 때문</li>
<li>greedy: 구간을 나눌 때마다 지금보다 나은 방법이 아닌 최상의 방법(best split)을 찾기 때문</li>
</ul>
<p>다음과 같이 작동한다.</p>
<ol>
<li>먼저 어떤 <em>X</em>~<em>j</em>~를 어느 값(<em>s</em>)을 기준으로 나눠야 두 구역의 RSS 합이 최소가 될지 결정한다.</li>
<li>두 구역으로 나눠진다.</li>
<li>두 구역 중 어느 구역을 어떤 <em>j</em>, <em>s</em>로 나눠야 세 구역의 RSS 합이 최소가 될지 결정한다.</li>
<li>세 구역이 된다.</li>
<li>세 구역 중 어느 구역을 어떤 <em>j</em>, <em>s</em>로 나눠야 네 구역의 RSS 합이 최소가 될지 결정한다.</li>
<li>네 구역이 된다.</li>
<li>&hellip;</li>
<li><u>특정 조건</u>을 충족할 때까지 계속 구역을 나눈다.
<ul>
<li>특정 조건의 예: 모든 구역의 관측값이 5개 미만이다</li>
</ul>
</li>
</ol>
<p>\</p>
<h4 id="tree-pruning"><strong>Tree Pruning</strong></h4>
<p><em>recursive binary splitting</em> 알고리즘은 overffing이 발생하여 정작 test data에서는 성능이 안 좋을 수 있다.<br />
이를 방지하기 위해 RSS가 일정값 이상 감소하지 않으면 구역을 나누지 않는다!는 규칙을 넣을 수도 있지만,<br />
그 이후에 RSS가 확 감소하는 구획이 가능했었다면 이를 놓치게 된다.<br />
따라서 <em>recursive binary splitting</em>으로 아주 큰 나무를 만든 후 **가지치기(pruning)**하는 방법을 택한다.<br />
그렇다면 <u>어떤 기준</u>으로 가지를 쳐낼까?<br />
우리가 원하는 건 test error rate를 줄이는 건데, 그렇다면 모든 가능한 subtree에서 이를 계산한 후 비교해야 할까?</p>
<p>&ndash;&gt; <u><em>Cost complexity pruning</em> (or <em>weakest link pruning</em>)</u>을 사용한다!<br />
원래 목적함수(RSS)에 terminal node 갯수에 패널티를 주는 항($\alpha$|T|)을 추가했다.<br />
|T|은 subtree의 terminal node 갯수를 의미한다.<br />
$\alpha$마다 대응하는 subtree가 존재한다.<br />
$\alpha$가 0이라면 subtree는 원래 가장 커다란 나무와 같겠고,<br />
$\alpha$가 0보다 클 수록 |T|에 목적함수값이 영향을 많이 받게 되는데(증가),<br />
이 영향을 없애려면 RSS가 꽤 감소하는 구획이 아닌 한 |T|를 줄여야 할 것이다.</p>
<ol>
<li><em>recursive binary splitting</em>으로 커다란 나무를 만든다.</li>
<li>K-fold CV 방법으로 test error rate를 최소화하는 $\alpha$를 결정한 후,</li>
<li>이 $\alpha$에 대응하는 subtree를 최종 모형으로 결정한다.</li>
</ol>
<h3 id="812-classification-trees">8.1.2. Classification Trees</h3>
<p>Regression tree와 다른 점</p>
<ul>
<li>반응변수가 범주형(<u>설명변수도 범주형일 수 있다</u>)</li>
<li>terminal node에는 그 구역의 평균값이 아니라 가장 빈도가 높은 범주</li>
<li>구역마다 계산할 criteron은 RSS 대신 다른 것
<ul>
<li>가장 빈도가 높은 범주에 속하지 않는 데이터의 비율</li>
<li>위 비율 보다는 <em>Gini index</em>나 <em>Entropy</em>(Shannon index)를 더 많이 쓴다.</li>
<li>위 두 지수는 모두 <strong>impurity</strong>를 나타낸다. 그 구역이 다양한 범주의 데이터로 이루어져 있으면 값이<br />
커진다.</li>
</ul>
</li>
<li>predicted classification이 나눠지지 않는 node가 생길 수 있다(나눠도 두 구역 모두 같은 범주)
<ul>
<li>Gini index나 Entropy를 구획의 목적함수로 사용한다.</li>
<li>위와 같이 구역을 나누면 목적함수값이 줄어들기 때문에(error rate는 같지만) 알고리즘상 node가 추가된다.</li>
</ul>
</li>
</ul>
<h3 id="813-trees-versus-linear-models">8.1.3. Trees Versus Linear Models</h3>
<p>무엇이 더 나은지는 상황에 따라 다르다.</p>
<p>test error rate가 한쪽이 더 나을 수 있고,<br />
interpretability가 한쪽이 더 나을 수 있다.</p>
<h3 id="814-advantages-and-disadvantages-of-trees">8.1.4. Advantages and Disadvantages of Trees</h3>
<p><del>(8.1.3이랑 뭐가 달라)</del></p>
<p>(vs classical regression methods)<br />
(tree methods 입장에서)</p>
<p>장점</p>
<ul>
<li>비전문가에게도 설명하기 쉽다</li>
<li>인간의 의사결정과정을 더 비슷하게 모사한 방법이다</li>
<li>범주형 변수를 다루기 더 쉽다(더미변수 다루는 것보다 훨씬 쉽다)</li>
</ul>
<p>단점</p>
<ul>
<li>예측 정확도가 낮은 편이다(<em>bagging</em>, <em>random forests</em>, <em>boosting</em>으로 해결)</li>
<li>non-robust. 데이터에 따라 tree 구조가 변하기 쉽다</li>
</ul>
<h2 id="82-bagging-random-forests-boosting">8.2. Bagging, Random Forests, Boosting</h2>
<h3 id="821-bagging">8.2.1. Bagging</h3>
<p>Bagging = Bootstrap aggregation<br />
statistical learning method의 variance를 줄이기 위해 사용되는 general-purpose procecure이지만<br />
decision tree 관련해서 자주 쓰이기 때문에 여기서 소개한다.</p>
<p>원리</p>
<ul>
<li>평균의 분산은 분산을 n으로 나눈 것 &ndash;&gt; 평균을 구하면 분산이 낮아진다!</li>
<li>resampling 여러번 해서 training set 여러개 생성 &ndash;&gt; 각 set마다 tree 생성 &ndash;&gt; tree 예측값 평균</li>
<li>(training set 생성에 bootstrap이 사용된다)</li>
<li>범주형일 경우 가장 빈도가 높은 예측 범주로 결정(나무한테 투표권 부여!)</li>
<li>생성할 training set 갯수는 크게 중요치 x. 매우 커도 overfitting 없다. 충분히 큰 값으로 고르자.</li>
</ul>
<p><del>(bootstrap이랑 뭐가 달라)</del></p>
<p>\</p>
<h4 id="out-of-bag-error-estimation"><strong>Out-of-Bag Error Estimation</strong></h4>
<p>bagged model의 test error 구하는 방법: 각 모델에 CV 수행해서 결과 비교할 필요 없다!<br />
각 bagged tree는 전체 데이터 중 약 2/3를 사용하게 된다.<br />
이 2/3에 들지 못한 데이터를 out-of-bag(OOB) observation이라 부른다.<br />
전체 bagged tree가 <em>B</em>개 있다면, OOB obs. 한 개당 약 3/B개의 prediction을 구할 수 있다.<br />
이 3/B개 값을 평균(for regression)하거나 투표(for classification)하면 OOB MSE나 classification error를 구할 수 있다.<br />
이는 모델을 만들 때 사용하지 않은 데이터(OOB)를 이용해 모델 성능을 평가했으므로 유효한 방법이다.</p>
<p><del>이게 bootstrap + 3-fold CV랑 다를 게 뭐야</del></p>
<p>\</p>
<h4 id="variable-importance-measures"><strong>Variable Importance Measures</strong></h4>
<p>bagging을 수행하면 이제 더 이상 해석하기 수월한 모델이 아니게 된다.<br />
대신 bagged tree를 이용해 어떤 변수가 예측력이 높았는지 알 수 있다.</p>
<ul>
<li>각 predictor마다 구획 후 감소한 RSS(or Gini index)를 더해서 비교한다.</li>
<li>한 predictor가 여러 node에서 사용되었다면 각 node에서 발생한 RSS(or Gini index) 감소량을 모두 더해서 비교한다.</li>
</ul>
<h3 id="822-random-forests">8.2.2. Random Forests</h3>
<p>Bagging &lt; Random Forests</p>
<p>만약 어떤 predictor가 특히 영향력이 높다면,<br />
bagging에서는 이 predictor만 주로 사용하여 구역을 나누게 될 것이다.<br />
그 결과 bagged tree는 서로 거의 차이가 없을 것이고 예측 결과도 비슷할 것이다.<br />
이러한 highly correlated quantities를 평균해도 variance reduction 양은 별로 되지 않는다.</p>
<p>때문에 <strong>Randomforest</strong>는</p>
<ul>
<li>decorrelating으로 variance reduction을 높인다.
<ul>
<li>매 구획마다 몇 개의 predictor를 랜덤하게 뽑아서 이것만 고려한다.</li>
<li>즉 모든 predictor를 공평하게 경쟁시키는 게 아니다.</li>
<li>때문에 영향력 낮은 predictor도 node에 참여할 기회가 많아지고</li>
<li>resulted tree도 더욱 다양해진다(decorrelated).</li>
<li>보통 <em>m</em>=sqrt(<em>p</em>) 만큼 샘플링한다.</li>
<li>평균적으로 (<em>p</em>-<em>m</em>)/<em>p</em> 만큼의 node가 최강 predictor를 고려하지 않게 된다.</li>
<li>bagging과 마찬가지로 나무 갯수는 크게 중요x. 충분히 많이 만들자.</li>
</ul>
</li>
</ul>
<pre><code>왜 영향력이 높지 않은 변수를 사용하지? 왜 RF 결과가 더 좋아지지?

Averaging many highly correlated data does not lead to as large of a reduction in variance as averaging many uncorrelated quantities. In particular, this means that bagging will not lead to a substantial reduction in variance over a single tree in this setting

correlated quantities면 평균해도 variance가 별로 줄어들지 않는다?  
근데 
bagging은 highly correlated &amp; highly accurate인 반면
RF는 less correlated &amp; less accurate가 아닐까?  
그래서 variance reduction은 RF가 크지만 accuracy는 bagging이 더 크다? (근데 현실은 RF가 더 정확)

there by making the average of the resulting trees less variable and hence more reliable

decorrelated values를 평균하는 게 왜 less variable?
</code></pre><h3 id="823-boosting">8.2.3. Boosting</h3>
<p>Bagging과 마찬가지로 decision tree 외 다른 기법에도 두루 쓰일 수 있다.</p>
<p>작동 원리</p>
<ul>
<li>NULL 모델(fx=0), NULL residual(r~i~=y~i~) 생성</li>
<li>작은 나무 한 그루 생성, NULL 모델에 더하기, residual 계산</li>
<li>작은 나무 한 그루 생성, 기존 나무에 더하기, residual 계산</li>
<li>작은 나무 한 그루 생성, 기존 나무에 더하기, residual 계산</li>
<li>&hellip;</li>
</ul>
<p>나무 여러개를 만들어서 합치는 게 아니라,<br />
한 그루를 계속 키우는 방식. <em>learn slowly</em>.</p>
<p>관련 모수 3개</p>
<ul>
<li><em>B</em>: 만들 총 나무 수. <strong>너무 크면 overffiting 될 수 있다</strong>. CV 사용해서 B 결정한다.</li>
<li><em>$\lambda$</em>: shrinkage parameter. 새로 만든 작은 나무를 기존 나무에 더하기 전에 이 숫자를 곱해준다.<br />
즉 나무가 자라는(learning) 속도를 결정한다.
<ul>
<li>보통 천천히 배울 수록 최종 성능은 좋아진다.</li>
<li>0.01이나 0.001을 주로 사용한다.</li>
</ul>
</li>
<li><em>d</em>: 새로 만들 작은 나무의 나뭇잎 개수.
<ul>
<li>보통 1로 두는데, 이러면 각 나무는 가지가 1개 뿐이니 <em>stump</em>가 된다. (stump는 어울리는 용어가 아닌듯)</li>
</ul>
</li>
</ul>
<pre><code>bagging, RF, Boosting이 대략 어떻게 모델을 만든다는 느낌은 온다만
그 과정을 뚜렷하게 그리지는 못 하겠다.

bagging, RF에서 최종 모형은 평균값을 쓴다는 데, 이게 무슨 말이지?
Boosting에서 각 중간 모델(나무)를 기존 것에 더한다는데 이 '더한다'는 게 무슨 말이지?
Boosting에서 residual update는 왜 하지? 어떤 판정 기준으로 사용되는 것도 아니고.
</code></pre><h2 id="83-lab-decision-trees">8.3. Lab: Decision Trees</h2>
<h3 id="831-fitting-classification-trees">8.3.1. Fitting Classification Trees</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">library</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ISLR</span><span class="p">)</span>
<span class="nf">attach</span><span class="p">(</span><span class="n">Carseats</span><span class="p">)</span>

<span class="c1">## create a &#34;High&#34; column</span>
<span class="n">High</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="n">Sales</span> <span class="o">&lt;=</span> <span class="m">8</span><span class="p">,</span> <span class="s">&#34;</span><span class="s">No&#34;</span><span class="p">,</span> <span class="s">&#34;</span><span class="s">Yes&#34;</span><span class="p">)</span>
<span class="n">Carseats</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">Carseats</span><span class="p">,</span> <span class="n">High</span><span class="p">)</span>
<span class="nf">str</span><span class="p">(</span><span class="n">Carseats</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 'data.frame':	400 obs. of  12 variables:
##  $ Sales      : num  9.5 11.22 10.06 7.4 4.15 ...
##  $ CompPrice  : num  138 111 113 117 141 124 115 136 132 132 ...
##  $ Income     : num  73 48 35 100 64 113 105 81 110 113 ...
##  $ Advertising: num  11 16 10 4 3 13 0 15 0 0 ...
##  $ Population : num  276 260 269 466 340 501 45 425 108 131 ...
##  $ Price      : num  120 83 80 97 128 72 108 120 124 124 ...
##  $ ShelveLoc  : Factor w/ 3 levels &quot;Bad&quot;,&quot;Good&quot;,&quot;Medium&quot;: 1 2 3 3 1 1 3 2 3 3 ...
##  $ Age        : num  42 65 59 55 38 78 71 67 76 76 ...
##  $ Education  : num  17 10 12 14 13 16 15 10 10 17 ...
##  $ Urban      : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 2 1 2 2 1 1 ...
##  $ US         : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 1 2 1 2 1 2 ...
##  $ High       : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 1 1 2 1 2 1 1 ...
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## try to fit a classification tree</span>
<span class="n">tree.carseats</span> <span class="o">=</span> <span class="nf">tree</span><span class="p">(</span><span class="n">High</span> <span class="o">~</span> <span class="n">. </span><span class="o">-</span><span class="n">Sales</span><span class="p">,</span> <span class="n">Carseats</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">tree.carseats</span><span class="p">)</span> 
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Classification tree:
## tree(formula = High ~ . - Sales, data = Carseats)
## Variables actually used in tree construction:
## [1] &quot;ShelveLoc&quot;   &quot;Price&quot;       &quot;Income&quot;      &quot;CompPrice&quot;   &quot;Population&quot; 
## [6] &quot;Advertising&quot; &quot;Age&quot;         &quot;US&quot;         
## Number of terminal nodes:  27 
## Residual mean deviance:  0.4575 = 170.7 / 373 
## Misclassification error rate: 0.09 = 36 / 400
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># training error rate = 9%</span>
<span class="c1"># deviance: smaller is good</span>
<span class="c1"># residual mean deviance: deviance / (n - |T|)</span>

<span class="nf">plot</span><span class="p">(</span><span class="n">tree.carseats</span><span class="p">)</span> <span class="c1"># plot tree</span>
<span class="nf">text</span><span class="p">(</span><span class="n">tree.carseats</span><span class="p">,</span> <span class="n">pretty</span> <span class="o">=</span> <span class="m">0</span><span class="p">)</span> <span class="c1"># add text</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.1-1.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## test error rate</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">2</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="nf">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="nf">nrow</span><span class="p">(</span><span class="n">Carseats</span><span class="p">)</span><span class="p">,</span> <span class="m">200</span><span class="p">)</span>
<span class="n">Carseats.test</span> <span class="o">=</span> <span class="n">Carseats</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="n">]</span>
<span class="n">High.test</span> <span class="o">=</span> <span class="n">High</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="n">]</span>
<span class="n">tree.carseats</span> <span class="o">=</span> <span class="nf">tree</span><span class="p">(</span><span class="n">High</span> <span class="o">~</span> <span class="n">. </span><span class="o">-</span><span class="n">Sales</span><span class="p">,</span> <span class="n">Carseats</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="n">train</span><span class="p">)</span>
<span class="n">tree.pred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">object</span> <span class="o">=</span> <span class="n">tree.carseats</span><span class="p">,</span> 
                    <span class="n">newdata</span> <span class="o">=</span> <span class="n">Carseats.test</span><span class="p">,</span>
                    <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">class&#34;</span><span class="p">)</span> <span class="c1"># specifying the tree is for classification</span>

<span class="c1"># test error rate = diagonal / whole</span>
<span class="nf">sum</span><span class="p">(</span><span class="nf">diag</span><span class="p">(</span><span class="nf">table</span><span class="p">(</span><span class="n">tree.pred</span><span class="p">,</span> <span class="n">High.test</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> <span class="o">/</span> <span class="nf">sum</span><span class="p">(</span><span class="nf">table</span><span class="p">(</span><span class="n">tree.pred</span><span class="p">,</span> <span class="n">High.test</span><span class="p">)</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 0.77
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## pruninig (cost complexity pruning)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">3</span><span class="p">)</span>
<span class="n">cv.carseats</span> <span class="o">=</span> <span class="nf">cv.tree</span><span class="p">(</span><span class="n">tree.carseats</span><span class="p">,</span> 
                      <span class="n">FUN</span> <span class="o">=</span> <span class="n">prune.misclass</span><span class="p">)</span> <span class="c1"># for classification problem</span>
<span class="nf">names</span><span class="p">(</span><span class="n">cv.carseats</span><span class="p">)</span> 
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] &quot;size&quot;   &quot;dev&quot;    &quot;k&quot;      &quot;method&quot;
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># size: # of leaf</span>
<span class="c1"># k: alpha in eq 8.4 (cost for tree complexity)</span>
<span class="c1"># dev: cv error rate</span>
<span class="n">cv.carseats</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## $size
## [1] 21 19 14  9  8  5  3  2  1
## 
## $dev
## [1] 74 76 81 81 75 77 78 85 81
## 
## $k
## [1] -Inf  0.0  1.0  1.4  2.0  3.0  4.0  9.0 18.0
## 
## $method
## [1] &quot;misclass&quot;
## 
## attr(,&quot;class&quot;)
## [1] &quot;prune&quot;         &quot;tree.sequence&quot;
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">)</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">cv.carseats</span><span class="o">$</span><span class="n">size</span><span class="p">,</span> <span class="n">cv.carseats</span><span class="o">$</span><span class="n">dev</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">b&#34;</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">cv.carseats</span><span class="o">$</span><span class="n">k</span><span class="p">,</span> <span class="n">cv.carseats</span><span class="o">$</span><span class="n">dev</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">b&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.1-2.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># tree with 9 leaves is turned out to be the best tree</span>
<span class="c1"># fit the tree explicitly</span>
<span class="n">prune.carseats</span> <span class="o">=</span> <span class="nf">prune.misclass</span><span class="p">(</span><span class="n">tree.carseats</span><span class="p">,</span> <span class="n">best</span> <span class="o">=</span> <span class="m">9</span><span class="p">)</span> 
<span class="c1"># best: # of leaves. result of cost-complexity </span>

<span class="nf">plot</span><span class="p">(</span><span class="n">prune.carseats</span><span class="p">)</span>
<span class="nf">text</span><span class="p">(</span><span class="n">prune.carseats</span><span class="p">,</span> <span class="n">pretty</span> <span class="o">=</span> <span class="m">0</span><span class="p">)</span>

<span class="n">tree.pred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">prune.carseats</span><span class="p">,</span> <span class="n">Carseats.test</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">class&#34;</span><span class="p">)</span>
<span class="nf">sum</span><span class="p">(</span><span class="nf">diag</span><span class="p">(</span><span class="nf">table</span><span class="p">(</span><span class="n">tree.pred</span><span class="p">,</span> <span class="n">High.test</span><span class="p">)</span><span class="p">)</span><span class="p">)</span> <span class="o">/</span> <span class="nf">sum</span><span class="p">(</span><span class="nf">table</span><span class="p">(</span><span class="n">tree.pred</span><span class="p">,</span> <span class="n">High.test</span><span class="p">)</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 0.775
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># pruned tree has simpler structure and more accurate prediction</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.1-3.png" alt="" /><!-- --></p>
<h3 id="832-fitting-regression-trees">8.3.2. Fitting Regression Trees</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## fit a regreession tree</span>
<span class="nf">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="nf">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="nf">nrow</span><span class="p">(</span><span class="n">Boston</span><span class="p">)</span><span class="p">,</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">Boston</span><span class="p">)</span> <span class="o">/</span> <span class="m">2</span><span class="p">)</span>
<span class="n">tree.boston</span> <span class="o">=</span> <span class="nf">tree</span><span class="p">(</span><span class="n">medv</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">Boston</span><span class="p">,</span> <span class="n">subset</span> <span class="o">=</span> <span class="n">train</span><span class="p">)</span>

<span class="nf">summary</span><span class="p">(</span><span class="n">tree.boston</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Regression tree:
## tree(formula = medv ~ ., data = Boston, subset = train)
## Variables actually used in tree construction:
## [1] &quot;rm&quot;    &quot;lstat&quot; &quot;crim&quot;  &quot;age&quot;  
## Number of terminal nodes:  7 
## Residual mean deviance:  10.38 = 2555 / 246 
## Distribution of residuals:
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -10.1800  -1.7770  -0.1775   0.0000   1.9230  16.5800
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">plot</span><span class="p">(</span><span class="n">tree.boston</span><span class="p">)</span>
<span class="nf">text</span><span class="p">(</span><span class="n">tree.boston</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.2-1.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## prune</span>
<span class="n">cv.boston</span> <span class="o">=</span> <span class="nf">cv.tree</span><span class="p">(</span><span class="n">tree.boston</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">cv.boston</span><span class="o">$</span><span class="n">size</span><span class="p">,</span> <span class="n">cv.boston</span><span class="o">$</span><span class="n">dev</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">b&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.2-2.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">prune.boston</span> <span class="o">=</span> <span class="nf">prune.tree</span><span class="p">(</span><span class="n">tree.boston</span><span class="p">,</span> <span class="n">best</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">prune.boston</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Regression tree:
## snip.tree(tree = tree.boston, nodes = 5L)
## Variables actually used in tree construction:
## [1] &quot;rm&quot;    &quot;lstat&quot;
## Number of terminal nodes:  5 
## Residual mean deviance:  13.69 = 3396 / 248 
## Distribution of residuals:
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -10.1800  -1.9770  -0.1775   0.0000   2.4230  16.5800
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">plot</span><span class="p">(</span><span class="n">prune.boston</span><span class="p">)</span>
<span class="nf">text</span><span class="p">(</span><span class="n">prune.boston</span><span class="p">,</span> <span class="n">pretty</span> <span class="o">=</span> <span class="m">0</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.2-3.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">yhat</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">tree.boston</span><span class="p">,</span> <span class="n">newdata</span> <span class="o">=</span> <span class="n">Boston</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="n">]</span><span class="p">)</span>
<span class="n">boston.test</span> <span class="o">=</span> <span class="n">Boston</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="s">&#34;</span><span class="s">medv&#34;</span><span class="n">]</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">boston.test</span><span class="p">)</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.2-4.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">mean</span><span class="p">(</span><span class="p">(</span><span class="n">yhat</span> <span class="o">-</span> <span class="n">boston.test</span><span class="p">)</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span> <span class="c1"># MSE</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 35.28688
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># here, pruned tree has simpler structure but it has larger MSE</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="833-bagging-and-random-forests">8.3.3. Bagging and Random Forests</h3>
<ul>
<li>(8.3.2의 decision tree 결과와 비교해보기)</li>
<li><code>randomForest</code> 패키지 하나로 충분하다(Bagging은 random forest 중 <em>m</em>=<em>p</em>인 a special case).</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## perform bagging</span>
<span class="nf">library</span><span class="p">(</span><span class="n">randomForest</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## randomForest 4.6-14
</code></pre><pre><code>## Type rfNews() to see new features/changes/bug fixes.
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">bag.boston</span> <span class="o">=</span> <span class="nf">randomForest</span><span class="p">(</span><span class="n">medv</span> <span class="o">~</span> <span class="n">. </span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Boston</span><span class="p">,</span> 
                          <span class="n">subset</span> <span class="o">=</span> <span class="n">train</span><span class="p">,</span>
                          <span class="n">mtry</span> <span class="o">=</span> <span class="m">13</span><span class="p">,</span> <span class="c1"># 구획할 때 샘플수링할 설명변수 개수</span>
                          <span class="n">importance</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
<span class="n">bag.boston</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Call:
##  randomForest(formula = medv ~ ., data = Boston, mtry = 13, importance = TRUE,      subset = train) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 13
## 
##           Mean of squared residuals: 11.39601
##                     % Var explained: 85.17
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## get test error rate</span>
<span class="n">yhat.bag</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">bag.boston</span><span class="p">,</span> <span class="n">newdata</span> <span class="o">=</span> <span class="n">Boston</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="n">]</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">yhat.bag</span><span class="p">,</span> <span class="n">boston.test</span><span class="p">)</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.3-1.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">mean</span><span class="p">(</span><span class="p">(</span><span class="n">yhat.bag</span> <span class="o">-</span> <span class="n">boston.test</span><span class="p">)</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span> 
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 23.59273
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># 13.50808 (bagging) vs 26.83413 (a regression tree)</span>

<span class="c1">## change the number of tree to grow</span>
<span class="n">bag.boston</span> <span class="o">=</span> <span class="nf">randomForest</span><span class="p">(</span><span class="n">medv</span> <span class="o">~</span> <span class="n">.,</span> 
                          <span class="n">data</span> <span class="o">=</span> <span class="n">Boston</span><span class="p">,</span>
                          <span class="n">subset</span> <span class="o">=</span> <span class="n">train</span><span class="p">,</span>
                          <span class="n">mtry</span> <span class="o">=</span> <span class="m">13</span><span class="p">,</span>
                          <span class="n">ntree</span> <span class="o">=</span> <span class="m">25</span><span class="p">)</span>
<span class="n">yhat.bag</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">bag.boston</span><span class="p">,</span> 
                   <span class="n">newdata</span> <span class="o">=</span> <span class="n">Boston</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="n">]</span><span class="p">)</span>
<span class="nf">mean</span><span class="p">(</span><span class="p">(</span><span class="n">yhat.bag</span> <span class="o">-</span> <span class="n">boston.test</span><span class="p">)</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span> 
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 23.66716
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## random forests</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">rf.boston</span> <span class="o">=</span> <span class="nf">randomForest</span><span class="p">(</span><span class="n">medv</span> <span class="o">~</span><span class="n">.,</span> 
                         <span class="n">data</span> <span class="o">=</span> <span class="n">Boston</span><span class="p">,</span>
                         <span class="n">subset</span> <span class="o">=</span> <span class="n">train</span><span class="p">,</span>
                         <span class="n">mtry</span> <span class="o">=</span> <span class="m">6</span><span class="p">,</span>
                         <span class="n">importance</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

<span class="n">yhat.rf</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">rf.boston</span><span class="p">,</span>
                  <span class="n">newdata</span> <span class="o">=</span> <span class="n">Boston</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="n">]</span><span class="p">)</span>
<span class="nf">mean</span><span class="p">(</span><span class="p">(</span><span class="n">yhat.rf</span> <span class="o">-</span> <span class="n">boston.test</span><span class="p">)</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 19.62021
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># 11.40256 (rf) vs 13.50808 (bagging) vs 26.83413 (a regression tree)</span>

<span class="nf">importance</span><span class="p">(</span><span class="n">rf.boston</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>##           %IncMSE IncNodePurity
## crim    16.697017    1076.08786
## zn       3.625784      88.35342
## indus    4.968621     609.53356
## chas     1.061432      52.21793
## nox     13.518179     709.87339
## rm      32.343305    7857.65451
## age     13.272498     612.21424
## dis      9.032477     714.94674
## rad      2.878434      95.80598
## tax      9.118801     364.92479
## ptratio  8.467062     823.93341
## black    7.579482     275.62272
## lstat   27.129817    6027.63740
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># %IncMSE: 그 변수가 없을 때 모델 정확도가 줄어드는 정도(MSE가 증가하는 정도?)</span>
<span class="c1"># IncNodePurity: 그 변수가 없을 때 Gini index가 줄어드는 정도(purity가 증가하는 정도)</span>
<span class="c1"># node impurity: regression은 RSS로, classification은 deviance로 계산</span>
<span class="nf">varImpPlot</span><span class="p">(</span><span class="n">rf.boston</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.3-2.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># rm and lstat의 영향이 가장 크더라</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="834-boosting">8.3.4. Boosting</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## fit a boosted model</span>
<span class="nf">library</span><span class="p">(</span><span class="n">gbm</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## Loaded gbm 2.1.5
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">boost.boston</span> <span class="o">=</span> <span class="nf">gbm</span><span class="p">(</span><span class="n">medv</span> <span class="o">~</span> <span class="n">.,</span> 
                   <span class="n">data</span> <span class="o">=</span> <span class="n">Boston</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
                   <span class="n">distribution</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">gaussian&#34;</span><span class="p">,</span> <span class="c1"># binary classification --&gt; &#34;bernoulli&#34;</span>
                   <span class="n">n.trees</span> <span class="o">=</span> <span class="m">5000</span><span class="p">,</span> <span class="c1"># # of tree to grow</span>
                   <span class="n">interaction.depth</span> <span class="o">=</span> <span class="m">4</span><span class="p">)</span> <span class="c1"># depth (= # of node layer) of each tree</span>

<span class="nf">summary</span><span class="p">(</span><span class="n">boost.boston</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.4-1.png" alt="" /><!-- --></p>
<pre><code>##             var    rel.inf
## rm           rm 43.9919329
## lstat     lstat 33.1216941
## crim       crim  4.2604167
## dis         dis  4.0111090
## nox         nox  3.4353017
## black     black  2.8267554
## age         age  2.6113938
## ptratio ptratio  2.5403035
## tax         tax  1.4565654
## indus     indus  0.8008740
## rad         rad  0.6546400
## zn           zn  0.1446149
## chas       chas  0.1443986
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># rel.inf: relative influence</span>

<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">)</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">boost.boston</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">rm&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.4-2.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">plot</span><span class="p">(</span><span class="n">boost.boston</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">lstat&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/8.3.4-3.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1">## predict</span>
<span class="n">yhat.boost</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">boost.boston</span><span class="p">,</span>
                     <span class="n">newdata</span> <span class="o">=</span> <span class="n">Boston</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
                     <span class="n">n.trees</span> <span class="o">=</span> <span class="m">5000</span><span class="p">)</span>
<span class="nf">mean</span><span class="p">(</span><span class="p">(</span><span class="n">yhat.boost</span> <span class="o">-</span> <span class="n">boston.test</span><span class="p">)</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 18.84709
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># 10.81479 (boost) vs 11.40256 (rf) vs 13.50808 (bagging) vs 26.83413 (a regression tree)</span>

<span class="c1">## manipulate shrinkage parameter</span>
<span class="n">boost.boston</span> <span class="o">=</span> <span class="nf">gbm</span><span class="p">(</span><span class="n">medv</span> <span class="o">~</span> <span class="n">.,</span> 
                   <span class="n">data</span> <span class="o">=</span> <span class="n">Boston</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
                   <span class="n">distribution</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">gaussian&#34;</span><span class="p">,</span>
                   <span class="n">n.trees</span> <span class="o">=</span> <span class="m">5000</span><span class="p">,</span>
                   <span class="n">interaction.depth</span> <span class="o">=</span> <span class="m">4</span><span class="p">,</span>
                   <span class="n">shrinkage</span> <span class="o">=</span> <span class="m">0.2</span><span class="p">,</span> <span class="c1"># default = 0.001</span>
                   <span class="n">verbose</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span>

<span class="n">yhat.boost</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">boost.boston</span><span class="p">,</span>
                     <span class="n">newdata</span> <span class="o">=</span> <span class="n">Boston</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
                     <span class="n">n.trees</span> <span class="o">=</span> <span class="m">5000</span><span class="p">)</span>
<span class="nf">mean</span><span class="p">(</span><span class="p">(</span><span class="n">yhat.boost</span> <span class="o">-</span> <span class="n">boston.test</span><span class="p">)</span> <span class="n">^</span> <span class="m">2</span><span class="p">)</span> <span class="c1"># vs 10.81479 (wih lambda = 0.001)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] 18.33455
</code></pre><h1 id="9-support-vector-machines">9. Support Vector Machines</h1>
<p><em>Support vector machine</em> (SVM)</p>
<ul>
<li>1990년대에 컴싸 분야에서 개발했다.</li>
<li>one of the best &ldquo;out of the box&rdquo; classifier.
<ul>
<li>&ldquo;out of box&rdquo;: 완제품? 특별한 작업 없이 바로 써먹을 수 있는 classifier.</li>
</ul>
</li>
<li><em>maximal margin classifier</em>의 일반화 버전
<ul>
<li><em>maximal margin classifier</em>: linear boundary 있을 때만 사용 가능</li>
<li><em>support vector classifier</em>: extension</li>
<li><em>support vector machine</em>: further extension</li>
</ul>
</li>
<li>class가 2개인 classification 문제 해결을 위해 만들었다.</li>
<li>하지만 2개보다 더 많은 class를 가지는 문제, 심지어 regression에도 적용할 수 있다.</li>
</ul>
<h2 id="91-maximal-margin-classifier">9.1. Maximal Margin Classifier</h2>
<h3 id="911-what-is-a-hyperplane">9.1.1. What Is a Hyperplane?</h3>
<ul>
<li><em>Hyperplane</em>: <em>p</em>차원 공간에서는 (<em>p-1</em>) 차원의 <strong>flat</strong> affine subspace가 된다.
<ul>
<li>affine space: 벡터공간에 점(point)의 개념을 추가한 것. 원점은 따로 존재하지 않음.</li>
<li>예로, 2차원 공간에서는 직선이 되고, 3차원 공간에서는 2차원 평면이 된다.</li>
<li>4차원 이상이면 시각화가 곤란하지만 개념은 똑같다.</li>
</ul>
</li>
<li>수식으로는, <em>$\beta$</em>~0~+<em>$\beta$</em>~1~<em>X</em>~<em>1</em>~+<em>$\beta$</em>~2~<em>X</em>~<em>2</em>~+&hellip;+<em>$\beta$</em>~<em>p</em>~<em>X</em>~<em>p</em>~=0을 만족하는 모든 <em>X</em>=(<em>X</em>~1~, &hellip;, <em>X</em>~p~)^<em>T</em>^로 쓸 수 있다.
<ul>
<li>Hyperplane은 <em>p</em>차원 공간을 두 영역으로 나누게 된다(좌변이 0보다 큰 곳, 작은 곳)</li>
</ul>
</li>
</ul>
<h3 id="912-classification-using-a-separating-hyperplane">9.1.2. Classification Using a Separating Hyperplane</h3>
<ul>
<li>Hyperplane이 만드는 두 구역의 class를 각각 1, -1로 indexing.</li>
<li><em>separating hyperplane</em>: 한 구역에 한 class만 있게 만드는 hyperplane.
<ul>
<li><em>y</em>~<em>i</em>~(<em>$\beta$</em>~0~+<em>$\beta$</em>~1~<em>X</em>~1~+<em>$\beta$</em>~2~<em>X</em>~2~+&hellip;+<em>$\beta$</em>~<em>p</em>~<em>X</em>~<em>p</em>~)&gt;0을 만족한다(<em>y</em>~<em>i</em>는 해당 class의 index).</li>
<li>왜냐햐면 좌변&gt;0인 class는 1로 indexing, 좌변&lt;0인 class는 -1로 indexing하기 때문.</li>
</ul>
</li>
<li>좌변 절댓값이 0보다 클수록 hyperplane에서 멀어진다 &ndash;&gt; 어느 구역에 속할지 더 쉽게 구분할 수 있다.</li>
</ul>
<h3 id="913-the-maximal-margin-classifier">9.1.3. The Maximal Margin Classifier</h3>
<p><em>Maximal margin classifier</em> (or <em>optimal separating hyperplane</em>)</p>
<ul>
<li>hyperplane을 하나 찾았다면, 이를 살짝살짝 움직이면서 무수히 많은 놈들을 더 만들 수 있다.</li>
<li>이 중 어떤 놈을 선택해야 할까?</li>
<li>두 그룹 사이를 아슬아슬하게 스쳐가듯 나누기보다는 최대한 멀찌감치 나누고 싶다.</li>
<li>hyperplane에서 각 point의 거리를 계산했을 때, 이 거리의 최솟값을 <strong>margin</strong>이라 한다.</li>
<li><strong>margin</strong>이 최대인 hyperplane = <em>maximal margin classifier</em></li>
<li><em>p</em>가 커지면 overfitting하는 경향이 있다.</li>
</ul>
<p>여기서 <em>support vector</em>는 maximal margin에 위치하는 points를 의미한다.</p>
<ul>
<li>support: maximal margin hyperplane 선택에 도움을 주기 때문</li>
<li>vector:  각 point는 <em>p</em>차원 공간의 벡터이기 때문</li>
</ul>
<p>이에 따라 maximual margin hyperplane은 support vector에만 영향을 받게 된다.<br />
반대로 말하면 support vector 외 다른 점들이 maximal margin 밖 어디를 뛰어댕겨도 hyperplane은 움직이지 않는다.</p>
<h3 id="914-construction-of-the-maximal-margin-classifier">9.1.4. Construction of the Maximal Margin Classifier</h3>
<p>the Maximal Margin Classifier를 구할 때 사용하는 세 목적함수</p>
<ol>
<li>maximize <em>M</em>
<ul>
<li>margin을 최대화한다. the Maximal Margin Classifier의 정의.</li>
</ul>
</li>
<li>모든 점에서 <em>y</em>~<em>i</em>~(<em>$\beta$</em>~0~+<em>$\beta$</em>~1~<em>X</em>~<em>1</em>~+<em>$\beta$</em>~1~<em>X</em>~<em>2</em>~+&hellip;+<em>$\beta$</em>~1~<em>X</em>~<em>p</em>~)&gt;=<em>M</em></li>
<li>$\sum_{j = 1}^{p}$$\beta$~*j*~^2^=1
<ul>
<li>2와 3이 합쳐져서 &ndash;&gt; 모든 관측값은 그에 맞는 구역에 위치하고 margin은 <em>M</em>이상이어야 한다.</li>
<li><em>p</em>차원 공간의 한 점에서 hyperplane까지 거리를 구하면 분자는 2의 좌변(<em>y</em>~<em>i</em>~ 제외한), 분모는 sqrt($\sum_{j = 1}^{p}$$\beta$~*j*~^2^)가 된다.</li>
<li>조건 3이 있기 때문에 2의 우변이 <em>M</em>일 수 있다(없다면 저 분모 값을 고려해서 우변을 바꿔야겠지?)</li>
</ul>
</li>
</ol>
<p>위 세 목적함수를 두고 어찌어찌 최적화 문제를 풀어 hyperplane을 구한다(자세한 건 생략)</p>
<h3 id="915-the-non-separable-case">9.1.5. The Non-separable Case</h3>
<p>위 최적화 문제의 해답(=maximal margin classifier)은 커녕<br />
separating hyperplane 조차 구할 수 없는 경우가 많다.<br />
\</p>
<p>&ndash;&gt; 두 구역을 딱딱 구분하는 것이 아닌 얼추 구분해내는 soft margin을 적용한다.<br />
&ndash;&gt; support vector classifier(m.m.c.를 non-separatable case로 확장) 등을 사용한다.</p>
<h2 id="92-support-vector-classifiers">9.2. Support Vector Classifiers</h2>
<h3 id="921-overview-of-the-support-vector-classifier">9.2.1. Overview of the Support Vector Classifier</h3>
<p>Maximal Margin Classifier는 <strong>모든 관측값을 정확하게 분류</strong> 해내려고 한다.<br />
이런 hyperplane은 존재하기도 힘들뿐더러,<br />
존재한다고 해도 아래와 같은 특징을 가지는 매우 예민한 놈일 것이다.</p>
<ul>
<li>관측값 하나하나에 민감하게 반응한다(완벽주의)</li>
<li>maximal margin이 매우 작아질 수 있다(아슬아슬) &ndash;&gt; 불-편</li>
<li>overfitting 가능성(완벽주의)</li>
</ul>
<p>따라서</p>
<ul>
<li><strong>대부분</strong>의 관측값을 잘 분류해내면서 Margin도 일정 값 이상을 유지하는</li>
<li>때문에 관측값 하나하나에 쉽게 변하지 않는(덜 민감한, robust)</li>
</ul>
<p>놈이 필요하다.<br />
&ndash;&gt; <em>support vector classifier</em> (or <em>soft margin classifier</em>)</p>
<h3 id="922-details-of-the-support-vector-classifier">9.2.2. Details of the Support Vector Classifier</h3>
<p>the Support Vector Classifier를 구할 때 사용하는 목적함수</p>
<ol>
<li>maximize <em>M</em>
<ul>
<li>margin을 최대화한다.</li>
</ul>
</li>
<li>$\sum_{j = 1}^{p}$$\beta$~*j*~^2^ = 1</li>
<li>모든 점에서 <em>y</em>~<em>i</em>~(<em>$\beta$</em>~0~ + <em>$\beta$</em>~1~<em>X</em>~<em>1</em>~ + <em>$\beta$</em>~1~<em>X</em>~<em>2</em>~ + &hellip; + <em>$\beta$</em>~1~<em>X</em>~<em>p</em>~) &gt;= <em>M</em>(1-$\epsilon$~<em>i</em>~)</li>
<li>$\epsilon$~<em>i</em>~ &gt;= 0, $\sum_{i=1}^{n}$$\epsilon$~*i*~ &lt;= *C*</li>
</ol>
<p>Maximal Margin Classifier의 목적함수와 비교</p>
<ul>
<li>1, 2번 조건은 같다.
<ul>
<li>1번은 margin을 최대화하기 위한 것</li>
<li>2번은 조건 3의 우변을 <em>M</em>으로 두기 위한 보조 장치</li>
</ul>
</li>
<li>3번 조건은 우변이 M(1-$\epsilon$~<em>i</em>~)로 바뀌었고, 4번 조건은 새로 추가됐다.
<ul>
<li>3번의 $\epsilon$~<em>i</em>~은 <strong>slack variable</strong></li>
<li>4번의 <em>C</em>는 <strong>tolerance</strong></li>
</ul>
</li>
</ul>
<p>Maximal Margin Classifier 보다 느슨한 classifier를 만들기 위해 tuning parameter <em>C</em>(tolerance)를 추가했다. <br />
hyperplane과 margin을 그어서 데이터를 분류했을 때,</p>
<ul>
<li>slack이 0이면 margin 이상의 거리에서 잘 분류한 것 (남방한계선 침범하지 않고 남한에 위치)</li>
<li>slack이 0보다 크면 margin 미만의 거리에서 잘 분류한 것 (남한측 DMZ에 위치)</li>
<li>slack이 1보다 크면 잘못 분류한 것 (탈남. 북한 DMZ or 북한 영토 침범)</li>
</ul>
<p>으로 볼 수 있다.</p>
<p><em>C</em>는 slack의 budget으로 생각할 수 있다. <em>C</em>만큼의 포인트가 있고 slack 값에 따라 포인트가 차감되는 형식이다. 포인트가 0이라면 slack은 모두 0이어야 하고(= Maximal Margin Classifier) 포인트가 많을 수록 더 많은, 혹은 더 값이 큰 slack이 발생할 수 있다. 이런 의미에서 <em>C</em>를 SVC의 tolerance라 부르는 것이다.</p>
<p>Support Vector Classifier에서도 hyperplane을 결정할 때 영향을 미치는 값들을 <em>support vector</em>라 하는데 Maximal margin classifier 때와는 대상이 조금 다르다.</p>
<ul>
<li>Maximal Margin Classifier: maximal margin에 위치하는 points($\epsilon$ = 0)</li>
<li>Support Vector Classifier: maximal margin에 혹은 그보다 더 반대 영역에 가까이 위치하는 points ($\epsilon$ &gt;= 0)</li>
</ul>
<p><em>C</em>가 클 수록 support vector가 더 많아지기 때문에 hyperplane의 variance가 작아지고 bias는 커진다. <br />
<em>C</em>가 작을 수록 support vector가 더 많아지기 때문에 hyperplane의 variance가 커지고,  bias는 작아진다.<br />
즉, <em>C</em>를 이용해 Classifier의 bias-variance trade-off를 조절할 수 있다.<br />
<em>C</em>는 다른 classifier에서 사용한 것처럼 cross-validation으로 추정한다.</p>
<p>Support vecotr classifier는 전체 관측값 중 일부(support vector)만 사용해 분류하기 때문에 관측치를 모두 사용하는 방법(e.g. linear discriminant analysis)보다는 관측값(또는 이상값)에 덜 민감하다.</p>
<h2 id="93-support-vector-machines">9.3. Support Vector Machines</h2>
<ul>
<li>9.3.1: non-linear boundary일 때 사용하는 메커니즘 소개</li>
<li>9.3.2: 위 메커니즘을 자동화한 방법 소개(SVM)</li>
</ul>
<h3 id="931-classification-with-non-liinear-decision-boundaries">9.3.1. Classification with Non-liinear Decision Boundaries</h3>
<p>key = Enlarging the feature space</p>
<ul>
<li>직선으로 부족하면 곡선을 만든다(2차항, 3차항, &hellip; 추가).</li>
<li>목적함수는 변하지 않는다(predictor+계수만 늘어날 뿐)</li>
</ul>
<p>항을 늘리면 계산량도 부쩍부쩍 는다.</p>
<p>SVM를 이용하면 효율적으로 문제를 해결할 수 있도록 feature space를 결정할 수 있다.</p>
<h3 id="932-the-support-vector-machine">9.3.2. The Support Vector Machine</h3>
<p>SVM은 feature space를 확장할 때 <em>kernel</em>을 이용한다(자세한 계산은 복잡하다. 지금은 feature space를 확장한다는 아이디어를 수행하다고 생각하자).</p>
<p>Support vector classfier의 목적 함수에는 관측치의 <em>inner product</em>외 다른 계산은 포함하지 않았다.</p>
<ul>
<li>inner product = &lt;<em>x</em>~<em>i</em>~, <em>x</em>~*i&rsquo;*~&gt; = $\sum_{j=1}^{p}$x~*ij*~x~*i&rsquo;j*~</li>
</ul>
<p>이는 inner product만으로도 support vector classifier의 목적함수를 표현할 수 있다는 뜻이다.</p>
<ul>
<li><em>f</em>(<em>x</em>) = $\beta$~0~ + $\sum_{i=1}^{n}$$\alpha$~i~&lt;*x*~*i*~, *x*~*i&rsquo;*~&gt;</li>
</ul>
<p>여기서 $\alpha$~i~는 각 관측치마다 부여하는 weighting factor 정도의 의미가 된다.<br />
<u>support vector가 아니라면</u> hyperplane 결정에 영향이 없으므로 $\alpha$~i~ = 0이 되고,<br />
<u>support vector에서는</u> 일정 값이 정해진다(원래 식에서는 이 값이 $\beta$ 계수들이 된다).</p>
<p>$\alpha$~i~를 추정하기 위해서는$\binom{n}{2}$개의 &lt;<em>x</em>~<em>i</em>~, <em>x</em>~*i&rsquo;*~&gt;를 계산하게 된다.</p>
<ul>
<li>margin을 결정하려면 가능한 모든 한 쌍의 관측치 조합마다 거리를 계산해서 비교해야 하기 때문</li>
</ul>
<p>위의 inner product 관련 항을 **일반화(generalization)**하여 아래와 같이 표현해보자.</p>
<ul>
<li><em>K</em>(<em>x</em>~<em>i</em>~, <em>x</em>~*i&rsquo;*~)</li>
</ul>
<p>위의 <em>K</em>가 바로 <em>kernel</em>이다. kernel은 두 관측치가 얼마나 비슷한지(혹은 다른지)를 정량적으로 표현해준다(거리).<br />
kernel이 inner product 항을 **일반화(generalization)**했다고 표현한 이유는 여러 종류의 inner product 표현이 존재하기 때문이다.<br />
즉, SVM에 다양한 종류의 kernel을 사용할 수 있다는 의미다.</p>
<ul>
<li><em>K</em>(<em>x</em>~<em>i</em>~, <em>x</em>~*i&rsquo;*~) = $\sum_{j=1}^{p}$x~*ij*~x~*i&rsquo;j*~ (linear kernel)</li>
<li><em>K</em>(<em>x</em>~<em>i</em>~, <em>x</em>~*i&rsquo;*~) = (1 + $\sum_{j=1}^{p}$x~*ij*~x~*i&rsquo;j*~)^*d*^ (polynomial kernel)</li>
<li><em>K</em>(<em>x</em>~<em>i</em>~, <em>x</em>~*i&rsquo;*~) = exp(-$\gamma$$\sum_{j=1}^{p}$(*x*~*ij*~ - *x*~*i&rsquo;j*~)^2^) (radial kernel)
<ul>
<li>$\gamma$가 클수록 non-linear</li>
</ul>
</li>
</ul>
<p>polynomial kernel에서 d가 1이면 linear kernel이 된다(1은 상수항이기 때문에 $\beta$~0~에 흡수된다).</p>
<p>위와 같이 다양한 kernel을 모두 가질 수 있는 것이 <strong>support vector machine</strong>이고,<br />
SVM 중 linear kernel을 사용하는 경우(혹은 <em>d</em>=1인 polynomial kernel)가 <strong>support vector classifier</strong>인 것이다.</p>
<pre><code>SVC와 SVM을 다른 관점에서 설명하는 것 같아 헷갈린다.

support vector classifier에서는 hyperplane에서 support vector까지의 &quot;거리&quot; 개념으로 목적함수가 내포하는 의미를 설명해줬다.

반면 support vector machine에서는 inner product를 이용해 목적함수의 꼴을 설명해줬다.

게다가 
SVC에서는 한 점과 hyperplane까지의 거리를 이용했는데,
SVM에서는 두 점사이의 거리를 다룬다. 하지만 두 점의 거리만 다루지는 않는 것 같다.
xi와 xi'는 두 관측값의 거리였고, x와 xi는 새로운 관측값과 training points 간의 거리였다.
(여기서 training points는 hyperplane(혹은 margin?)을 의미하는 것 같다)

SVM에서도 SVC와 같은 개념(거리와 margin을 비교)이 적용될 수 있다면
SVM의 kernel을 
&quot;두 점 사이의 거리를 표현하는 다양한 종류의 함수&quot;라고 이해하는 게 편할 것 같다.
SVC에서 직선꼴의 hyperplane과 한 점까지의 거리를 계산하는 kernel을 사용한 것처럼
SVM에서는 곡선꼴의 hyperplane과 한 점까지의 거리를 계산하는 (복잡하게 생긴) kernel을 사용한 것이다.
</code></pre><h3 id="933-an-application-to-the-heart-disease-data">9.3.3. An Application to the Heart Disease Data</h3>
<h2 id="94-svms-with-more-than-two-classes">9.4. SVMs with More than Two Classes</h2>
<p>SVM을 K-class case로 확장하는 방법엔 대표적으로 두 가지가 있다.</p>
<ul>
<li><em>One-versus-one</em> (or <em>all-pairs</em>) approach</li>
<li><em>One-versus-all</em> approach</li>
</ul>
<h3 id="941-one-versus-one-classification">9.4.1. One-Versus-One Classification</h3>
<p><em>K</em> classes 중 두 개 classes를 선택해서 binary classification한다.</p>
<ul>
<li>$\binom{k}{2}$개 SVM을 만든다</li>
<li>각 SVM은 <em>K</em> classes 중 <em>k</em>th, *k&rsquo;*th class에 대한 two-class setting 문제를 풀게 된다</li>
<li>$\binom{k}{2}$개 SVM을 가지고 각 관측치를 어느 class로 분류헀는지 투표한다</li>
<li>가장 많은 표를 얻은 class가 각 관측치의 최종 분류 결과가 된다</li>
</ul>
<h3 id="942-one-versus-all-classification">9.4.2. One-Versus-All Classification</h3>
<p><em>K</em> classes 중 <em>k</em>th class를 선택해서 (<em>k</em>th class) vs (나머지 <em>k</em>-1 classes)에 대해 binary classification한다.</p>
<p>관측치 x를 분류하려 한다면,</p>
<ul>
<li><em>K</em>개 SVM을 만든다</li>
<li>각 SVM의 kernel에서 계산한 값(=거리) 중 가장 큰 값을 가진 SVM의 class <em>K</em>로 분류한다
<ul>
<li>값이 클 수록 더 안정적으로 해당 class에 속하기 때문</li>
</ul>
</li>
</ul>
<pre><code>본문에서는 linear kernel 수식으로만 서술했는데 그냥 예를 든 거겠지?
</code></pre><h2 id="95-relationship-to-logistic-regression">9.5. Relationship to Logistic Regression</h2>
<p>SVM이 처음 나온 1990년대에는 hyperplane과 kernel 이용한다는 점이 참신하게 느껴졌다고 한다.<br />
하지만 SVM은 기존 classical classification approaches와 궤를 같이한다는 점이 밝혀졌다.</p>
<p>support vector classifier의 목적함수는 아래처럼 쓸 수 있다(또?).</p>
<ul>
<li>$\beta$~p~에 대해 minimize{ $\sum_{i=1}^{n}$ max[0, 1 - *y*~*i*~*f*(*x*~*i*~)] + $\lambda$$\sum_{j=1}^{p}$$\beta$^2^~j~ }
<ul>
<li>$\lambda$는 variance-bias trade-off를 조절하는 tuning parameter다(SVC의 <em>C</em>)</li>
</ul>
</li>
</ul>
<p>위에서 minimize 안은 <strong>Loss + Penalty</strong> 형태로 이루어져 있다.<br />
SVM에서 loss는 한 점에서 hyperplane까지의 거리, penalty는 tolerance이다.<br />
SVM와 같은 loss function을 <em>hinge loss</em>라 한다. 여기서 support vector가 아닌 관측값은 loss값이 0이 된다.</p>
<p>logistic regression, linear discriminant analysis, lasso regression, ridge regression 역시 <strong>Loss + Penalty</strong> 형태로 이루어져 있었다.<br />
또한 이들 방법에서도 non-linear kernel을 사용할 수 있다. 단지 historical reasons 때문에 non-linear kernel은 SVM에서 더 자주 사용할 뿐이다.</p>
<p>Logistic regression과 SVC는 비슷한 결과를 보이는 경우가 많은데,<br />
이들의 <em>y</em>~<em>i</em>~(<em>$\beta$</em>~0~+<em>$\beta$</em>~1~<em>X</em>~1~+<em>$\beta$</em>~2~<em>X</em>~2~+&hellip;+<em>$\beta$</em>~<em>p</em>~<em>X</em>~<em>p</em>~)에 따른 Loss function 값이 비슷하기 때문이다.</p>
<ul>
<li>loss가 비슷하다 = 비슷한 범주로 분류한다</li>
<li>다만 SVC에서는 support vector가 아니면 loss가 0인 반면,<br />
logistic regressioin에서는 loss가 0인 경우는 없다).</li>
</ul>
<h4 id="support-vector-regression-vs-least-squares-regression"><strong>Support vector regression vs least squares regression</strong></h4>
<p>Loss function이 다르다.</p>
<ul>
<li>least squares regression: residual sum of squares를 최소로하는 $\beta$~0~, &hellip;, $\beta$~<em>p</em>~</li>
<li>support vector regression: 특정 값 이상의 절댓값을 가지는 관측치만 loss function에 영향을 미친다(svc와 비슷)</li>
</ul>
<pre><code>support vector regression 좀 자세히 설명해주지 --&gt; 9.6.3에 조금 나온ㄷ
</code></pre><h2 id="96-lab-support-vector-machines">9.6. Lab: Support Vector Machines</h2>
<p>여기서는 <code>e1071</code> 패키지를 사용한다. <br />
<code>LiblineaR</code> 패키지도 있는데, predictor가 꽤 많은 상황에서 사용하면 좋다.</p>
<h3 id="961-support-vector-classifier">9.6.1. Support Vector Classifier</h3>
<p>svc: <code>e1071::svm()</code></p>
<ul>
<li>kernel: &ldquo;linear&quot;일 때는 svm 중에서도 svc가 된다(책에서 소개한 것과는 조금 다른 목적함수를 푼다).</li>
<li>cost: tolerance 조절 모수. cost가 작으면 slack이 커지고 support vector가 많아진다.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># make a two-dimensional example data</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">(</span><span class="nf">rnorm</span><span class="p">(</span><span class="m">20</span> <span class="o">*</span> <span class="m">2</span><span class="p">)</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="m">-1</span><span class="p">,</span> <span class="m">10</span><span class="p">)</span><span class="p">,</span> <span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">10</span><span class="p">)</span><span class="p">)</span>
<span class="n">x</span><span class="n">[y</span> <span class="o">==</span> <span class="m">1</span><span class="p">,</span> <span class="n">]</span> <span class="o">=</span> <span class="n">x</span><span class="n">[y</span> <span class="o">==</span> <span class="m">1</span><span class="p">,</span> <span class="n">]</span> <span class="o">+</span> <span class="m">1</span> <span class="c1"># add 1 for last 10 data</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> 
     <span class="n">col</span> <span class="o">=</span> <span class="p">(</span><span class="m">3</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="p">)</span> <span class="c1"># non-linear boundary </span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-1-1.png" alt="" /><!-- --></p>
<p>For classification problem,<br />
class variable should be in <strong>factor type</strong>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">dat</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> 
                 <span class="n">y</span> <span class="o">=</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">e1071</span><span class="p">)</span>
<span class="n">svmfit</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span> 
             <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="p">,</span>
             <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">linear&#34;</span><span class="p">,</span>
             <span class="n">cost</span> <span class="o">=</span> <span class="m">10</span><span class="p">,</span> 
             <span class="n">scale</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="c1"># don&#39;t do normalization</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">svmfit</span><span class="p">,</span> <span class="n">dat</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-2-1.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># cross: support vector</span>
<span class="c1"># circle: !(support vector)</span>

<span class="c1"># return index of support vector</span>
<span class="n">svmfit</span><span class="o">$</span><span class="n">index</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1]  1  2  5  7 14 16 17
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">summary</span><span class="p">(</span><span class="n">svmfit</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Call:
## svm(formula = y ~ ., data = dat, kernel = &quot;linear&quot;, cost = 10, scale = FALSE)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  10 
## 
## Number of Support Vectors:  7
## 
##  ( 4 3 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  -1 1
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># cost = 10</span>
<span class="c1"># # of support vector = 7 (4 in class &#34;-1&#34;)</span>
</code></pre></td></tr></table>
</div>
</div><p>SVC with a smaller cost.<br />
tolerance가 더 높아지고 margin이 넓어지고 support vector가 더 많아질 것이다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">svmfit</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
             <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="p">,</span>
             <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">linear&#34;</span><span class="p">,</span>
             <span class="n">cost</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">,</span>
             <span class="n">scale</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span>

<span class="nf">plot</span><span class="p">(</span><span class="n">svmfit</span><span class="p">,</span> <span class="n">dat</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-3-1.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">svmfit</span><span class="o">$</span><span class="n">index</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>##  [1]  1  2  3  4  5  7  9 10 12 13 14 15 16 17 18 20
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">summary</span><span class="p">(</span><span class="n">svmfit</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Call:
## svm(formula = y ~ ., data = dat, kernel = &quot;linear&quot;, cost = 0.1, scale = FALSE)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  0.1 
## 
## Number of Support Vectors:  16
## 
##  ( 8 8 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  -1 1
</code></pre><p><code>tune()</code>: 원하는 모수 값 범위에서 10-fold CV를 수행해준다.</p>
<ul>
<li>error: <code>tune.control()</code> <strong>error.fun</strong>에서 지정한 함수로 에러를 구한다. 이렇게 구한 에러를 <strong>sampling.aggregate</strong>에서 지정한 함수로 요약한다
<ul>
<li><strong>error.fun</strong> 기본값: classification은 misclassification rate가, regression에서는 MSE가 사용된다</li>
<li><strong>sampling.aggregate</strong> 기본값: mean</li>
</ul>
</li>
<li>dispersion: <code>tune.control()</code> <strong>error.fun</strong>에서 지정한 함수로 에러를 구한다. 이렇게 구한 에러를 <strong>sampling.dispersion</strong>에서 지정한 함수로 요약한다
<ul>
<li><strong>sampling.dispersion</strong> 기본값: sd</li>
</ul>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">tune.out</span> <span class="o">=</span> <span class="nf">tune</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> 
                <span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="p">,</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">linear&#34;</span><span class="p">,</span>
                <span class="n">ranges</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">cost</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">0.001</span><span class="p">,</span> <span class="m">0.01</span><span class="p">,</span> <span class="m">0.1</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">5</span><span class="p">,</span> <span class="m">10</span><span class="p">,</span> <span class="m">100</span><span class="p">)</span><span class="p">)</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">tune.out</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Parameter tuning of 'svm':
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  cost
##   0.1
## 
## - best performance: 0.05 
## 
## - Detailed performance results:
##    cost error dispersion
## 1 1e-03  0.55  0.4377975
## 2 1e-02  0.55  0.4377975
## 3 1e-01  0.05  0.1581139
## 4 1e+00  0.15  0.2415229
## 5 5e+00  0.15  0.2415229
## 6 1e+01  0.15  0.2415229
## 7 1e+02  0.15  0.2415229
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># extract information of the best model </span>
<span class="n">bestmod</span> <span class="o">=</span> <span class="n">tune.out</span><span class="o">$</span><span class="n">best.model</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">bestmod</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Call:
## best.tune(method = svm, train.x = y ~ ., data = dat, ranges = list(cost = c(0.001, 
##     0.01, 0.1, 1, 5, 10, 100)), kernel = &quot;linear&quot;)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  0.1 
## 
## Number of Support Vectors:  16
## 
##  ( 8 8 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  -1 1
</code></pre><p><code>predict()</code>: 만들어놓은 svm으로 새로운 데이터의 class를 예측(regression에서는 값을 예측)한다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">xtest</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">(</span><span class="nf">rnorm</span><span class="p">(</span><span class="m">20</span> <span class="o">*</span> <span class="m">2</span><span class="p">)</span><span class="p">,</span>
               <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span>
<span class="n">ytest</span> <span class="o">=</span> <span class="nf">sample</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">-1</span><span class="p">,</span> <span class="m">1</span><span class="p">)</span><span class="p">,</span> <span class="m">20</span><span class="p">,</span> <span class="n">rep</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
<span class="n">xtest</span><span class="n">[ytest</span> <span class="o">==</span> <span class="m">1</span><span class="p">,</span> <span class="n">]</span> <span class="o">=</span> <span class="n">xtest</span><span class="n">[ytest</span> <span class="o">==</span> <span class="m">1</span><span class="p">,</span> <span class="n">]</span> <span class="o">+</span> <span class="m">1</span>
<span class="n">testdat</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">xtest</span><span class="p">,</span>
                     <span class="n">y</span> <span class="o">=</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">ytest</span><span class="p">)</span><span class="p">)</span>

<span class="n">ypred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">bestmod</span><span class="p">,</span>
                <span class="n">testdat</span><span class="p">)</span>
<span class="nf">table</span><span class="p">(</span><span class="n">predict</span> <span class="o">=</span> <span class="n">ypred</span><span class="p">,</span>
      <span class="n">truth</span> <span class="o">=</span> <span class="n">testdat</span><span class="o">$</span><span class="n">y</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>##        truth
## predict -1 1
##      -1  9 3
##      1   2 6
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># with another cost (0.01)</span>

<span class="n">svmfit</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
             <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="p">,</span>
             <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">linear&#34;</span><span class="p">,</span>
             <span class="n">cost</span> <span class="o">=</span> <span class="m">0.01</span><span class="p">,</span>
             <span class="n">scale</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span>
<span class="n">ypred</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">svmfit</span><span class="p">,</span> <span class="n">testdat</span><span class="p">)</span>
<span class="nf">table</span><span class="p">(</span><span class="n">predict</span> <span class="o">=</span> <span class="n">ypred</span><span class="p">,</span>
      <span class="n">truth</span> <span class="o">=</span> <span class="n">testdat</span><span class="o">$</span><span class="n">y</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>##        truth
## predict -1  1
##      -1 10  4
##      1   1  5
</code></pre><p>Linearly separable한 경우</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">x</span><span class="n">[y</span> <span class="o">==</span> <span class="m">1</span><span class="p">,</span> <span class="n">]</span> <span class="o">=</span> <span class="n">x</span><span class="n">[y</span> <span class="o">==</span> <span class="m">1</span><span class="p">,</span> <span class="n">]</span> <span class="o">+</span> <span class="m">0.5</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> 
     <span class="n">col</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="m">5</span><span class="p">)</span> <span class="o">/</span> <span class="m">2</span><span class="p">,</span>
     <span class="n">pch</span> <span class="o">=</span> <span class="m">19</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-6-1.png" alt="" /><!-- --></p>
<p>이제 linearly separable한 경우가 됐다.<br />
cost를 높여서(= tolerance를 아주 낮춰서) 아주 철저하게 분류해보자.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">dat</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span>
                 <span class="n">y</span> <span class="o">=</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="p">)</span>
<span class="n">svmfit</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
             <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="p">,</span>
             <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">linear&#34;</span><span class="p">,</span>
             <span class="n">cost</span> <span class="o">=</span> <span class="m">1e5</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">svmfit</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Call:
## svm(formula = y ~ ., data = dat, kernel = &quot;linear&quot;, cost = 1e+05)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  1e+05 
## 
## Number of Support Vectors:  3
## 
##  ( 1 2 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  -1 1
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">plot</span><span class="p">(</span><span class="n">svmfit</span><span class="p">,</span> <span class="n">dat</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-7-1.png" alt="" /><!-- --></p>
<p>training 데이터를 완벽히 분류해냈지만,<br />
margin이 매우 작다(파란색 support vector와 가장 가까운 동그라미 사이 거리가 매우 가깝다).<br />
때문에 test error는 높을 수 있다.<br />
cost를 낮춰보자.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">svmfit</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span> 
             <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="p">,</span>
             <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">linear&#34;</span><span class="p">,</span>
             <span class="n">cost</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">svmfit</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Call:
## svm(formula = y ~ ., data = dat, kernel = &quot;linear&quot;, cost = 1)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  1 
## 
## Number of Support Vectors:  7
## 
##  ( 4 3 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  -1 1
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">plot</span><span class="p">(</span><span class="n">svmfit</span><span class="p">,</span>
     <span class="n">dat</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-8-1.png" alt="" /><!-- --></p>
<p>분홍색 한 개가 하늘색으로 잘못 분류됐지만, 그 대신 margin이 더 커졌다.<br />
cost가 매우 높은 경우보다 test error는 더 낮을 것이다!</p>
<h3 id="962-support-vector-machine">9.6.2. Support Vector Machine</h3>
<p>Non-linear kernel을 사용하려면<br />
<code>svm()</code> 함수의 <code>kernel</code>인자로 &ldquo;linear&quot;대신 다른 것을 사용한다.</p>
<ul>
<li>&ldquo;polynomial&rdquo;: <code>d</code>인자를 이용해 다항의 차수를 조절한다</li>
<li>&ldquo;radial&rdquo;: ```gamma``인자를 이용해 <strong>$\lambda$</strong>를 조절한다(<strong>$\lambda$</strong>가 작을 수록 선형에 가깝다)</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">library</span><span class="p">(</span><span class="n">e1071</span><span class="p">)</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">(</span><span class="nf">rnorm</span><span class="p">(</span><span class="m">200</span> <span class="o">*</span> <span class="m">2</span><span class="p">)</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span>
<span class="n">x</span><span class="n">[1</span><span class="o">:</span><span class="m">100</span><span class="p">,</span> <span class="n">]</span> <span class="o">=</span> <span class="n">x</span><span class="n">[1</span><span class="o">:</span><span class="m">100</span><span class="p">,</span> <span class="n">]</span> <span class="o">+</span> <span class="m">2</span>
<span class="n">x</span><span class="n">[101</span><span class="o">:</span><span class="m">150</span><span class="p">,</span> <span class="n">]</span> <span class="o">=</span> <span class="n">x</span><span class="n">[101</span><span class="o">:</span><span class="m">150</span><span class="p">,</span> <span class="n">]</span> <span class="o">-</span> <span class="m">2</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">150</span><span class="p">)</span><span class="p">,</span> <span class="nf">rep</span><span class="p">(</span><span class="m">2</span><span class="p">,</span> <span class="m">50</span><span class="p">)</span><span class="p">)</span>
<span class="n">dat</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> 
                 <span class="n">y</span> <span class="o">=</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># non-linear boundary</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-9-1.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">train</span> <span class="o">=</span> <span class="nf">sample</span><span class="p">(</span><span class="m">200</span><span class="p">,</span> <span class="m">100</span><span class="p">)</span>
<span class="n">svmfit</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
             <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
             <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">radial&#34;</span><span class="p">,</span>
             <span class="n">gamma</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span>
             <span class="n">cost</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">svmfit</span><span class="p">,</span> <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-9-2.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">summary</span><span class="p">(</span><span class="n">svmfit</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Call:
## svm(formula = y ~ ., data = dat[train, ], kernel = &quot;radial&quot;, gamma = 1, 
##     cost = 1)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  radial 
##        cost:  1 
## 
## Number of Support Vectors:  31
## 
##  ( 16 15 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  1 2
</code></pre><p>Cost를 높여보자.</p>
<ul>
<li>더욱 구불구불해지고</li>
<li>overfitting 가능성이 높아진다</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">svmfit</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
             <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
             <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">radial&#34;</span><span class="p">,</span>
             <span class="n">gamma</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span>
             <span class="n">cost</span> <span class="o">=</span> <span class="m">1e5</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">svmfit</span><span class="p">,</span> <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-10-1.png" alt="" /><!-- --></p>
<p>SVC에서 헀던 것처럼,<br />
<code>tune()</code> 함수(10-fold cross validation 수행해준다)를 이용해<br />
최적의 $\lambda$와 cost값을 찾아보자.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">tune.out</span> <span class="o">=</span> <span class="nf">tune</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span>
                <span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">radial&#34;</span><span class="p">,</span>
                <span class="n">ranges</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">cost</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">0.1</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">10</span><span class="p">,</span> <span class="m">100</span><span class="p">,</span> <span class="m">1000</span><span class="p">)</span><span class="p">,</span>
                              <span class="n">gamma</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">0.5</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">4</span><span class="p">)</span><span class="p">)</span><span class="p">)</span>

<span class="nf">help</span><span class="p">(</span><span class="n">tune</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## starting httpd help server ... done
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">summary</span><span class="p">(</span><span class="n">tune.out</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Parameter tuning of 'svm':
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  cost gamma
##     1   0.5
## 
## - best performance: 0.07 
## 
## - Detailed performance results:
##     cost gamma error dispersion
## 1  1e-01   0.5  0.26 0.15776213
## 2  1e+00   0.5  0.07 0.08232726
## 3  1e+01   0.5  0.07 0.08232726
## 4  1e+02   0.5  0.14 0.15055453
## 5  1e+03   0.5  0.11 0.07378648
## 6  1e-01   1.0  0.22 0.16193277
## 7  1e+00   1.0  0.07 0.08232726
## 8  1e+01   1.0  0.09 0.07378648
## 9  1e+02   1.0  0.12 0.12292726
## 10 1e+03   1.0  0.11 0.11005049
## 11 1e-01   2.0  0.27 0.15670212
## 12 1e+00   2.0  0.07 0.08232726
## 13 1e+01   2.0  0.11 0.07378648
## 14 1e+02   2.0  0.12 0.13165612
## 15 1e+03   2.0  0.16 0.13498971
## 16 1e-01   3.0  0.27 0.15670212
## 17 1e+00   3.0  0.07 0.08232726
## 18 1e+01   3.0  0.08 0.07888106
## 19 1e+02   3.0  0.13 0.14181365
## 20 1e+03   3.0  0.15 0.13540064
## 21 1e-01   4.0  0.27 0.15670212
## 22 1e+00   4.0  0.07 0.08232726
## 23 1e+01   4.0  0.09 0.07378648
## 24 1e+02   4.0  0.13 0.14181365
## 25 1e+03   4.0  0.15 0.13540064
</code></pre><h3 id="963-roc-curves">9.6.3. ROC Curves</h3>
<p><code>ROCR</code> 패키지 사용</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">library</span><span class="p">(</span><span class="n">ROCR</span><span class="p">)</span>

<span class="c1"># numerical score (pred)와 class label (truth)를 입력받아</span>
<span class="c1"># ROC 커브를 그리는 함수</span>
<span class="n">rocplot</span> <span class="o">=</span> <span class="nf">function</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">truth</span><span class="p">,</span> <span class="kc">...</span><span class="p">)</span><span class="p">{</span>
  <span class="n">predob</span> <span class="o">=</span> <span class="nf">prediction</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">truth</span><span class="p">)</span>
  <span class="n">perf</span> <span class="o">=</span> <span class="nf">performance</span><span class="p">(</span><span class="n">predob</span><span class="p">,</span> <span class="s">&#34;</span><span class="s">tpr&#34;</span><span class="p">,</span> <span class="s">&#34;</span><span class="s">fpr&#34;</span><span class="p">)</span>
  <span class="nf">plot</span><span class="p">(</span><span class="n">perf</span><span class="p">,</span> <span class="kc">...</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><p><strong>Support vector regressor와 support vector machine</strong></p>
<ul>
<li>support vector regressor는 <em>$\beta$</em>~0~ + <em>$\beta$</em>~1~<em>X</em>~<em>1</em>~ + <em>$\beta$</em>~1~<em>X</em>~<em>2</em>~ + &hellip; + <em>$\beta$</em>~1~<em>X</em>~<em>p</em>~를 predicted value로 사용한다.</li>
<li>support vector machine은 위 값의 부호를 이용해 class label을 부여한다.</li>
<li><code>svm()</code>에 입력하는 response variable이 numeric이면 svr, factor면 svm</li>
</ul>
<p><code>svm()</code>에서는&hellip;</p>
<ul>
<li>decision.values = TRUE로 두면, class가 아닌 fitted value를 얻을 수 있다</li>
<li><code>predict()</code> 결과 중 decision.values 속성에 fitted value가 나타나 있다</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">svmfit.opt</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
                 <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
                 <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">radial&#34;</span><span class="p">,</span>
                 <span class="n">gamma</span> <span class="o">=</span> <span class="m">2</span><span class="p">,</span>
                 <span class="n">cost</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span>
                 <span class="n">decision.values</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
<span class="n">fitted</span> <span class="o">=</span> <span class="nf">attributes</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">svmfit.opt</span><span class="p">,</span> 
                            <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span> 
                            <span class="n">decision.values</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span><span class="p">)</span><span class="o">$</span><span class="n">decision.values</span>

<span class="nf">rocplot</span><span class="p">(</span><span class="n">fitted</span><span class="p">,</span> <span class="n">dat</span><span class="n">[train</span> <span class="p">,</span> <span class="s">&#34;</span><span class="s">y&#34;</span><span class="n">]</span><span class="p">,</span>
        <span class="n">main</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">Training Data&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-13-1.png" alt="" /><!-- --></p>
<p>꽤 잘 맞추는 듯하다. 여기서 $\lambda$를 높이면(more non-linear) training fitness를 더 높일 수 있다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">svmfit.flex</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
                  <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
                  <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">radial&#34;</span><span class="p">,</span>
                  <span class="n">gamma</span> <span class="o">=</span> <span class="m">50</span><span class="p">,</span>
                  <span class="n">cost</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span>
                  <span class="n">decision.values</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
<span class="n">fitted.flex</span> <span class="o">=</span> <span class="nf">attributes</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">svmfit.flex</span><span class="p">,</span>
                                 <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
                                 <span class="n">decision.values</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span><span class="p">)</span><span class="o">$</span><span class="n">decision.values</span>

<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">1</span><span class="p">)</span><span class="p">)</span>
<span class="nf">rocplot</span><span class="p">(</span><span class="n">fitted</span><span class="p">,</span> <span class="n">dat</span><span class="n">[train</span> <span class="p">,</span> <span class="s">&#34;</span><span class="s">y&#34;</span><span class="n">]</span><span class="p">,</span>
        <span class="n">main</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">Training Data&#34;</span><span class="p">)</span>
<span class="nf">rocplot</span><span class="p">(</span><span class="n">fitted.flex</span><span class="p">,</span> <span class="n">dat</span><span class="n">[train</span><span class="p">,</span> <span class="s">&#34;</span><span class="s">y&#34;</span><span class="n">]</span><span class="p">,</span>
        <span class="n">add</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">red&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-14-1.png" alt="" /><!-- --></p>
<p>$\lambda$를 높였을 때 훨씬 정확한 것처럼 보인다.<br />
그러나 test error는&hellip;</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">fitted.test</span> <span class="o">=</span> <span class="nf">attributes</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">svmfit.opt</span><span class="p">,</span>
                                 <span class="n">dat</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span>
                                 <span class="n">decision.values</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span><span class="p">)</span><span class="o">$</span><span class="n">decision.values</span>
<span class="n">fitted.flex.test</span> <span class="o">=</span> <span class="nf">attributes</span><span class="p">(</span><span class="nf">predict</span><span class="p">(</span><span class="n">svmfit.flex</span><span class="p">,</span>
                                      <span class="n">dat</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span> 
                                      <span class="n">decision.values</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span><span class="p">)</span><span class="o">$</span><span class="n">decision.values</span>
<span class="nf">rocplot</span><span class="p">(</span><span class="n">fitted.test</span><span class="p">,</span> <span class="n">dat</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="s">&#34;</span><span class="s">y&#34;</span><span class="n">]</span><span class="p">,</span>
        <span class="n">main</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">Test Data&#34;</span><span class="p">)</span>
<span class="nf">rocplot</span><span class="p">(</span><span class="n">fitted.flex.test</span><span class="p">,</span> <span class="n">dat</span><span class="n">[</span><span class="o">-</span><span class="n">train</span><span class="p">,</span> <span class="s">&#34;</span><span class="s">y&#34;</span><span class="n">]</span><span class="p">,</span>
        <span class="n">add</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">red&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-15-1.png" alt="" /><!-- --></p>
<h3 id="964-svm-with-multiple-classes">9.6.4. SVM with Multiple Classes</h3>
<p>Class가 세 개 이상이면 <code>svm()</code>은 기본값으로 one-versus-one approach를 사용한다.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">set.seed</span><span class="p">(</span><span class="m">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nf">rbind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> 
          <span class="nf">matrix</span><span class="p">(</span><span class="nf">rnorm</span><span class="p">(</span><span class="m">50</span> <span class="o">*</span> <span class="m">2</span><span class="p">)</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">50</span><span class="p">)</span><span class="p">)</span>
<span class="n">x</span><span class="n">[y</span> <span class="o">==</span> <span class="m">0</span><span class="p">,</span> <span class="m">2</span><span class="n">]</span> <span class="o">=</span> <span class="n">x</span><span class="n">[y</span> <span class="o">==</span> <span class="m">0</span><span class="p">,</span> <span class="m">2</span><span class="n">]</span> <span class="o">+</span> <span class="m">2</span>
<span class="n">dat</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="p">)</span>
<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">1</span><span class="p">)</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="m">1</span><span class="p">)</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-16-1.png" alt="" /><!-- --></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">svmfit</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
             <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="p">,</span>
             <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">radial&#34;</span><span class="p">,</span>
             <span class="n">cost</span> <span class="o">=</span> <span class="m">10</span><span class="p">,</span>
             <span class="n">gamma</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">svmfit</span><span class="p">,</span> <span class="n">dat</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img src="ISLR_files/figure-html/unnamed-chunk-16-2.png" alt="" /><!-- --></p>
<h3 id="965-application-to-gene-expression-data">9.6.5. Application to Gene Expression Data</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">library</span><span class="p">(</span><span class="n">ISLR</span><span class="p">)</span>
<span class="nf">names</span><span class="p">(</span><span class="n">Khan</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## [1] &quot;xtrain&quot; &quot;xtest&quot;  &quot;ytrain&quot; &quot;ytest&quot;
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">str</span><span class="p">(</span><span class="n">Khan</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## List of 4
##  $ xtrain: num [1:63, 1:2308] 0.7733 -0.0782 -0.0845 0.9656 0.0757 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:63] &quot;V1&quot; &quot;V2&quot; &quot;V3&quot; &quot;V4&quot; ...
##   .. ..$ : NULL
##  $ xtest : num [1:20, 1:2308] 0.14 1.164 0.841 0.685 -1.956 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:20] &quot;V1&quot; &quot;V2&quot; &quot;V4&quot; &quot;V6&quot; ...
##   .. ..$ : NULL
##  $ ytrain: num [1:63] 2 2 2 2 2 2 2 2 2 2 ...
##  $ ytest : num [1:20] 3 2 4 2 1 3 4 2 3 1 ...
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">table</span><span class="p">(</span><span class="n">Khan</span><span class="o">$</span><span class="n">ytrain</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
##  1  2  3  4 
##  8 23 12 20
</code></pre><p>feature 개수(2308)가 train 데이터 개수(63)에 비해 훨씬 많다.<br />
이런 경우 굳이 non-linear kernel을 사용할 필요 없다.</p>
<ul>
<li>데이터가 적고 feature가 많으면 hyperplane을 찾기 쉽다(고 한다&hellip;).</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">dat</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">Khan</span><span class="o">$</span><span class="n">xtrain</span><span class="p">,</span>
                 <span class="n">y</span> <span class="o">=</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">Khan</span><span class="o">$</span><span class="n">ytrain</span><span class="p">)</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">.,</span>
          <span class="n">data</span> <span class="o">=</span> <span class="n">dat</span><span class="p">,</span>
          <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#34;</span><span class="s">linear&#34;</span><span class="p">,</span>
          <span class="n">cost</span> <span class="o">=</span> <span class="m">10</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>## 
## Call:
## svm(formula = y ~ ., data = dat, kernel = &quot;linear&quot;, cost = 10)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  10 
## 
## Number of Support Vectors:  58
## 
##  ( 20 20 11 7 )
## 
## 
## Number of Classes:  4 
## 
## Levels: 
##  1 2 3 4
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">table</span><span class="p">(</span><span class="n">out</span><span class="o">$</span><span class="n">fitted</span><span class="p">,</span> <span class="n">dat</span><span class="o">$</span><span class="n">y</span><span class="p">)</span> <span class="c1"># no training error</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>##    
##      1  2  3  4
##   1  8  0  0  0
##   2  0 23  0  0
##   3  0  0 12  0
##   4  0  0  0 20
</code></pre><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">dat.te</span> <span class="o">=</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">Khan</span><span class="o">$</span><span class="n">xtest</span><span class="p">,</span>
                    <span class="n">y</span> <span class="o">=</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">Khan</span><span class="o">$</span><span class="n">ytest</span><span class="p">)</span><span class="p">)</span>
<span class="n">pred.te</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">newdata</span> <span class="o">=</span> <span class="n">dat.te</span><span class="p">)</span>
<span class="nf">table</span><span class="p">(</span><span class="n">pred.te</span><span class="p">,</span> <span class="n">dat.te</span><span class="o">$</span><span class="n">y</span><span class="p">)</span> <span class="c1"># test error: 20개 중 2개 틀렸다</span>
</code></pre></td></tr></table>
</div>
</div><pre><code>##        
## pred.te 1 2 3 4
##       1 3 0 0 0
##       2 0 6 2 0
##       3 0 0 4 0
##       4 0 0 0 5
</code></pre>
    </article>
    <script>
  'use strict';
  
  function wrap(el, wrapper) {
    el.parentNode.insertBefore(wrapper, el);
    wrapper.appendChild(el);
  }

  (function () {
    var singleContentsElem = document.querySelector('.single__contents');
    singleContentsElem ? 
    singleContentsElem.querySelectorAll('pre > code').forEach(function(elem) {
      var dataLang = elem.getAttribute('data-lang');
      var dataLangWrapper = document.createElement('div');
      var code = null;
      var codeTitle = null;

      if (dataLang && dataLang.includes(':')) {
        code = dataLang.split(':')[0];
        codeTitle = dataLang.split(':')[1];

        dataLangWrapper.className = 'language-' + code;
        dataLangWrapper.setAttribute('data-lang', codeTitle);

        elem.className = 'language-' + code;
        elem.setAttribute('data-lang', codeTitle);
        elem.setAttribute('id', codeTitle);
      } else if (!dataLang) {
        dataLangWrapper.setAttribute('data-lang', 'Code');
        dataLangWrapper.className = 'language-code';
      }

      if (!dataLang || codeTitle) {
        wrap(elem.parentNode, dataLangWrapper);
      }

    }) : null;
  })();

  var langCodeElem = document.querySelectorAll('.language-code');
  langCodeElem ? langCodeElem.forEach(function (elem) {
    var newElem = document.createElement('span');
    newElem.className = 'copy-to-clipboard';
    newElem.setAttribute('title', 'Copy to clipboard');
    elem.append(newElem);
  }) : null;
  
</script>
    
<div class="donation">
  <div class="donation__message">
    Share on
  </div>
  <div class="donation__icons">
    
    
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fhoontaeklee.github.io%2fen%2fposts%2f20200516_islr%2f" title="Facebook" aria-label="Facebook Share Button" class="donation__item" target="_blank" rel="noreferrer" data-type="share">
          <svg data-name="facebook" enable-background="new 0 0 24 24" viewBox="0 0 24 24" width="35" height="35" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="m15.997 3.985h2.191v-3.816c-.378-.052-1.678-.169-3.192-.169-3.159 0-5.323 1.987-5.323 5.639v3.361h-3.486v4.266h3.486v10.734h4.274v-10.733h3.345l.531-4.266h-3.877v-2.939c.001-1.233.333-2.077 2.051-2.077z"/></svg>
        </a>
      
    
      
        <a href="https://twitter.com/intent/tweet?text=ISLR%20Note&url=https%3a%2f%2fhoontaeklee.github.io%2fen%2fposts%2f20200516_islr%2f&hashtags=2020%2cBook%20Review%2cR&via=Hoontaek%20Lee" title="Twitter" aria-label="Twitter Share Button" class="donation__item" target="_blank" rel="noreferrer" data-type="share">
          <svg data-name="twitter" enable-background="new 0 0 24 24" viewBox="0 0 24 24" width="35" height="35" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="m21.534 7.113c.976-.693 1.797-1.558 2.466-2.554v-.001c-.893.391-1.843.651-2.835.777 1.02-.609 1.799-1.566 2.165-2.719-.951.567-2.001.967-3.12 1.191-.903-.962-2.19-1.557-3.594-1.557-2.724 0-4.917 2.211-4.917 4.921 0 .39.033.765.114 1.122-4.09-.2-7.71-2.16-10.142-5.147-.424.737-.674 1.58-.674 2.487 0 1.704.877 3.214 2.186 4.089-.791-.015-1.566-.245-2.223-.606v.054c0 2.391 1.705 4.377 3.942 4.835-.401.11-.837.162-1.29.162-.315 0-.633-.018-.931-.084.637 1.948 2.447 3.381 4.597 3.428-1.674 1.309-3.8 2.098-6.101 2.098-.403 0-.79-.018-1.177-.067 2.18 1.405 4.762 2.208 7.548 2.208 8.683 0 14.342-7.244 13.986-14.637z"/></svg>
        </a>
      
    
  </div>
</div>

    
    
<div class="whoami__gutter"></div>
<hr class="hr-slash whoami-hr"/>
<section class="whoami">
  <div class="whoami__image-wrapper">
    
    
      
        <img data-src="/images/whoami/avatar.jpg" src="data:image/svg+xml,%0A%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24'%3E%3Cpath fill='none' d='M0 0h24v24H0V0z'/%3E%3Cpath fill='%23aaa' d='M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm-1 16H6c-.55 0-1-.45-1-1V6c0-.55.45-1 1-1h12c.55 0 1 .45 1 1v12c0 .55-.45 1-1 1zm-4.44-6.19l-2.35 3.02-1.56-1.88c-.2-.25-.58-.24-.78.01l-1.74 2.23c-.26.33-.02.81.39.81h8.98c.41 0 .65-.47.4-.8l-2.55-3.39c-.19-.26-.59-.26-.79 0z'/%3E%3C/svg%3E" alt="Hoontaek Lee" class="lazyload whoami__image"/>
      
    
  </div>
  <div class="whoami__contents">
    <div class="whoami__written-by">
      WRITTEN BY
    </div>
    <div class="whoami__title">
      
        Hoontaek Lee
      
    </div>
    <div class="whoami__desc">
      
        Tree-Forest-Climate Researcher
      
    </div>
    <div class="whoami__social">
      
      
      
      
      
      
      
      
      <a href="mailto:lht3718@email.com" title="email" aria-label="email">
        <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path fill="currentColor" d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm-.4 4.25l-7.07 4.42c-.32.2-.74.2-1.06 0L4.4 8.25c-.25-.16-.4-.43-.4-.72 0-.67.73-1.07 1.3-.72L12 11l6.7-4.19c.57-.35 1.3.05 1.3.72 0 .29-.15.56-.4.72z"/></svg>
      </a>
      
      
      
      
      
      
      
      <a href="https://github.com/hoontaeklee" title="github" aria-label="github">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="25" height="25" viewBox="0 0 24 24" version="1.1">
<g id="surface3680">
<path fill="currentColor" d="M 10.898438 2.101562 C 6.300781 2.601562 2.601562 6.300781 2.101562 10.800781 C 1.601562 15.5 4.300781 19.699219 8.398438 21.300781 C 8.699219 21.398438 9 21.199219 9 20.800781 L 9 19.199219 C 9 19.199219 8.601562 19.300781 8.101562 19.300781 C 6.699219 19.300781 6.101562 18.101562 6 17.398438 C 5.898438 17 5.699219 16.699219 5.398438 16.398438 C 5.101562 16.300781 5 16.300781 5 16.199219 C 5 16 5.300781 16 5.398438 16 C 6 16 6.5 16.699219 6.699219 17 C 7.199219 17.800781 7.800781 18 8.101562 18 C 8.5 18 8.800781 17.898438 9 17.800781 C 9.101562 17.101562 9.398438 16.398438 10 16 C 7.699219 15.5 6 14.199219 6 12 C 6 10.898438 6.5 9.800781 7.199219 9 C 7.101562 8.800781 7 8.300781 7 7.601562 C 7 7.199219 7 6.601562 7.300781 6 C 7.300781 6 8.699219 6 10.101562 7.300781 C 10.601562 7.101562 11.300781 7 12 7 C 12.699219 7 13.398438 7.101562 14 7.300781 C 15.300781 6 16.800781 6 16.800781 6 C 17 6.601562 17 7.199219 17 7.601562 C 17 8.398438 16.898438 8.800781 16.800781 9 C 17.5 9.800781 18 10.800781 18 12 C 18 14.199219 16.300781 15.5 14 16 C 14.601562 16.5 15 17.398438 15 18.300781 L 15 20.898438 C 15 21.199219 15.300781 21.5 15.699219 21.398438 C 19.398438 19.898438 22 16.300781 22 12.101562 C 22 6.101562 16.898438 1.398438 10.898438 2.101562 Z M 10.898438 2.101562 "/>
</g>
</svg>

      </a>
      
      
      
      
      
      
      
      <a href="https://scholar.google.co.kr/" title="google-scholar" aria-label="google-scholar">
        <svg fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="25" height="25"><path d="M 25 2 C 12.309534 2 2 12.309534 2 25 C 2 37.690466 12.309534 48 25 48 C 37.690466 48 48 37.690466 48 25 C 48 12.309534 37.690466 2 25 2 z M 25 4 C 36.609534 4 46 13.390466 46 25 C 46 36.609534 36.609534 46 25 46 C 13.390466 46 4 36.609534 4 25 C 4 13.390466 13.390466 4 25 4 z M 21 11 L 11 20 L 17.78125 20 C 17.80125 22.847 19.967531 25.730469 23.769531 25.730469 C 24.129531 25.730469 24.529688 25.690391 24.929688 25.650391 C 24.749688 26.100391 24.560547 26.470078 24.560547 27.080078 C 24.560547 28.230078 25.140391 28.920078 25.650391 29.580078 C 24.020391 29.690078 20.989766 29.879531 18.759766 31.269531 C 16.629766 32.559531 15.980469 34.43 15.980469 35.75 C 15.980469 38.47 18.500469 41 23.730469 41 C 29.930469 41 33.220703 37.510547 33.220703 34.060547 C 33.220703 31.530547 31.779453 30.279922 30.189453 28.919922 L 28.900391 27.890625 C 28.500391 27.570625 27.949219 27.120312 27.949219 26.320312 C 27.949219 25.510313 28.500703 24.989766 28.970703 24.509766 C 30.480703 23.309766 32 21.960234 32 19.240234 C 32 18.197234 31.756203 17.348391 31.408203 16.650391 L 35 13.570312 L 35 17.277344 C 34.405 17.623344 34 18.261 34 19 L 34 25 C 34 26.104 34.896 27 36 27 C 37.104 27 38 26.104 38 25 L 38 19 C 38 18.262 37.595 17.624344 37 17.277344 L 37 12 C 37 11.957 36.980609 11.920906 36.974609 11.878906 L 38 11 L 21 11 z M 24.269531 14.240234 C 27.269531 14.240234 28.820312 18.35 28.820312 21 C 28.820312 21.65 28.739922 22.819922 27.919922 23.669922 C 27.339922 24.259922 26.370938 24.699219 25.460938 24.699219 C 22.370938 24.699219 20.949219 20.620156 20.949219 18.160156 C 20.949219 17.210156 21.14 16.220938 21.75 15.460938 C 22.33 14.710938 23.339531 14.240234 24.269531 14.240234 z M 26.039062 30.609375 C 26.409063 30.609375 26.590859 30.610391 26.880859 30.650391 C 29.620859 32.630391 30.800781 33.620234 30.800781 35.490234 C 30.800781 37.760234 28.97 39.460938 25.5 39.460938 C 21.64 39.460938 19.160156 37.590469 19.160156 34.980469 C 19.160156 32.370469 21.459766 31.499219 22.259766 31.199219 C 23.769766 30.679219 25.719062 30.609375 26.039062 30.609375 z"/></svg>
      </a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      <a href="https://stackoverflow.com/users/7578494/hoontaek" title="stack-overflow" aria-label="stack-overflow">
        <svg fill="#000000" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="25" height="25"><path fill="currentColor" d="M 9.914063 0.71875 L 9.085938 1.28125 L 11.894531 5.367188 L 12.71875 4.800781 Z M 7.695313 2.453125 L 7.039063 3.207031 L 10.917969 6.582031 L 11.574219 5.828125 Z M 6.226563 4.804688 L 5.773438 5.695313 L 10.210938 7.953125 L 10.664063 7.0625 Z M 5.363281 7.140625 L 5.136719 8.109375 L 9.976563 9.242188 L 10.203125 8.265625 Z M 3 9 L 3 14 L 12 14 L 12 9 L 11 9 L 11 13 L 4 13 L 4 9 Z M 5.03125 9.25 L 4.96875 10.25 L 9.972656 10.566406 L 10.035156 9.570313 Z M 5 11 L 5 12 L 10 12 L 10 11 Z"/></svg>
      </a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </div>
  </div>
</section>
<hr class="hr-slash whoami-hr" />


    <section class="related">
    
    
  </section>
    <div class="grow"></div>
<nav class="pagination-single">
  
    
      <a href="https://hoontaeklee.github.io/en/posts/20171200_%EC%96%B4%EC%84%9C%EC%99%80-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%9D%80-%EC%B2%98%EC%9D%8C%EC%9D%B4%EC%A7%80/" class="pagination-single__left">
        <div class="pagination-single__icon">
          <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path fill="currentColor" d="M19 11H7.83l4.88-4.88c.39-.39.39-1.03 0-1.42-.39-.39-1.02-.39-1.41 0l-6.59 6.59c-.39.39-.39 1.02 0 1.41l6.59 6.59c.39.39 1.02.39 1.41 0 .39-.39.39-1.02 0-1.41L7.83 13H19c.55 0 1-.45 1-1s-.45-1-1-1z"/></svg>
        </div>
        <div class="pagination-single__left-title">어서와 머신러닝은 처음이지</div>      
      </a>
    
    <div class="grow"></div>
    
      <a href="https://hoontaeklee.github.io/en/posts/20181100_%EC%B1%85%EB%B2%8C%EB%A0%88%EC%9D%98%EA%B3%B5%EB%B6%80/" class="pagination-single__right">      
        <div class="pagination-single__right-title">책벌레의 공부</div>
        <div class="pagination-single__icon">
          <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path fill="currentColor" d="M5 13h11.17l-4.88 4.88c-.39.39-.39 1.03 0 1.42.39.39 1.02.39 1.41 0l6.59-6.59c.39-.39.39-1.02 0-1.41l-6.58-6.6c-.39-.39-1.02-.39-1.41 0-.39.39-.39 1.02 0 1.41L16.17 11H5c-.55 0-1 .45-1 1s.45 1 1 1z"/></svg>
        </div>
      </a>
    
  
</nav>
    
  
    <div id="utterances"></div>
<noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>
<script>
  document.addEventListener('DOMContentLoaded', function () {
    try {
      
      var owner = JSON.parse("\"hoontaeklee\"");
      
      var repo = JSON.parse("\"bloght-hugo-comments\"");
      var localTheme = localStorage.getItem('theme');
      var utterTheme = localTheme === "dark" || localTheme === "hacker" ? 'photon-dark' : localTheme === 'kimbie' ? 'github-dark-orange' : 'github-light'

      var myScript = document.createElement('script');
      myScript.setAttribute('src', 'https://utteranc.es/client.js');
      myScript.setAttribute('repo', `${owner}/${repo}`);
      myScript.setAttribute('issue-term', 'pathname');
      myScript.setAttribute('theme', utterTheme);
      myScript.setAttribute('crossorigin', 'anonymous');
      myScript.setAttribute('async', '');

      myScript.onload = function() {
      }

      document.getElementById('utterances').appendChild(myScript);
    } catch (err) {
      console.log(err);
    }
  });
</script>

  

    <div class="modal micromodal-slide" id="modal" aria-hidden="true">
  <div class="modal__overlay" tabindex="-1" data-micromodal-close>
    <div class="modal__container" role="dialog" aria-modal="true" aria-labelledby="modal-title">
      
      <div class="modal__content" id="modal-content">
        <div id="mySwipe" class="swipe">
          <div class="swipe-wrap">
          </div>
        </div>
      </div>

      <span class="modal__items">
        
        <span class="modal__header">
          <div class="modal__paging" title="Page Info" aria-label="Current Page">
          </div>
          <div class="modal__icon modal__toolbar modal__toolbar--close" title="Close" aria-label="Close Button" data-micromodal-close>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 26 26" width="25" height="25"><path fill="currentColor" d="M 21.734375 19.640625 L 19.636719 21.734375 C 19.253906 22.121094 18.628906 22.121094 18.242188 21.734375 L 13 16.496094 L 7.761719 21.734375 C 7.375 22.121094 6.746094 22.121094 6.363281 21.734375 L 4.265625 19.640625 C 3.878906 19.253906 3.878906 18.628906 4.265625 18.242188 L 9.503906 13 L 4.265625 7.761719 C 3.882813 7.371094 3.882813 6.742188 4.265625 6.363281 L 6.363281 4.265625 C 6.746094 3.878906 7.375 3.878906 7.761719 4.265625 L 13 9.507813 L 18.242188 4.265625 C 18.628906 3.878906 19.257813 3.878906 19.636719 4.265625 L 21.734375 6.359375 C 22.121094 6.746094 22.121094 7.375 21.738281 7.761719 L 16.496094 13 L 21.734375 18.242188 C 22.121094 18.628906 22.121094 19.253906 21.734375 19.640625 Z"/></svg>
          </div>
          <div class="modal__icon modal__toolbar modal__toolbar--full" title="Full Screen" aria-label="Full Screen Button">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="25" height="25"><path fill="currentColor" d="M 5 3 C 3.9069372 3 3 3.9069372 3 5 L 3 8 A 1.0001 1.0001 0 1 0 5 8 L 5 5 L 8 5 A 1.0001 1.0001 0 1 0 8 3 L 5 3 z M 16 3 A 1.0001 1.0001 0 1 0 16 5 L 19 5 L 19 8 A 1.0001 1.0001 0 1 0 21 8 L 21 5 C 21 3.9069372 20.093063 3 19 3 L 16 3 z M 3.984375 14.986328 A 1.0001 1.0001 0 0 0 3 16 L 3 19 C 3 20.093063 3.9069372 21 5 21 L 8 21 A 1.0001 1.0001 0 1 0 8 19 L 5 19 L 5 16 A 1.0001 1.0001 0 0 0 3.984375 14.986328 z M 19.984375 14.986328 A 1.0001 1.0001 0 0 0 19 16 L 19 19 L 16 19 A 1.0001 1.0001 0 1 0 16 21 L 19 21 C 20.093063 21 21 20.093063 21 19 L 21 16 A 1.0001 1.0001 0 0 0 19.984375 14.986328 z"/></svg>
          </div>
          <div class="modal__icon modal__toolbar modal__toolbar--normal" title="Normal Screen" aria-label="Normal Screen Button">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="25" height="25"><path fill="currentColor" d="M 16.96875 4.972656 C 15.867188 4.988281 14.984375 5.894531 15 7 L 15 15 L 7 15 C 6.277344 14.988281 5.609375 15.367188 5.246094 15.992188 C 4.878906 16.613281 4.878906 17.386719 5.246094 18.007813 C 5.609375 18.632813 6.277344 19.011719 7 19 L 19 19 L 19 7 C 19.007813 6.460938 18.796875 5.941406 18.414063 5.558594 C 18.03125 5.175781 17.511719 4.964844 16.96875 4.972656 Z M 32.96875 4.972656 C 31.921875 4.988281 31.0625 5.8125 31.003906 6.859375 C 31 6.90625 31 6.953125 31 7 L 31 19 L 43 19 C 43.066406 19 43.132813 19 43.199219 18.992188 C 44.269531 18.894531 45.070313 17.972656 45.015625 16.902344 C 44.964844 15.828125 44.074219 14.988281 43 15 L 35 15 L 35 7 C 35.007813 6.460938 34.796875 5.941406 34.414063 5.558594 C 34.03125 5.175781 33.511719 4.964844 32.96875 4.972656 Z M 7 31 C 6.277344 30.988281 5.609375 31.367188 5.246094 31.992188 C 4.878906 32.613281 4.878906 33.386719 5.246094 34.007813 C 5.609375 34.632813 6.277344 35.011719 7 35 L 15 35 L 15 43 C 14.988281 43.722656 15.367188 44.390625 15.992188 44.753906 C 16.613281 45.121094 17.386719 45.121094 18.007813 44.753906 C 18.632813 44.390625 19.011719 43.722656 19 43 L 19 31 Z M 31 31 L 31 43 C 30.988281 43.722656 31.367188 44.390625 31.992188 44.753906 C 32.613281 45.121094 33.386719 45.121094 34.007813 44.753906 C 34.632813 44.390625 35.011719 43.722656 35 43 L 35 35 L 43 35 C 43.722656 35.011719 44.390625 34.632813 44.753906 34.007813 C 45.121094 33.386719 45.121094 32.613281 44.753906 31.992188 C 44.390625 31.367188 43.722656 30.988281 43 31 Z"/></svg>
          </div>
        </span>
        
        <div class="modal__icon modal__arrow modal__arrow--left" title="Arrow Left" aria-label="Arrow Left Button">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 26 26" width="28" height="28"><path fill="currentColor" d="M 23.28125 11 L 10 10 L 10 6.851563 C 10 6.523438 9.839844 6.277344 9.519531 6.03125 C 9.199219 5.949219 8.878906 5.949219 8.640625 6.113281 C 5.359375 8.410156 2.238281 12.257813 2.160156 12.421875 C 2.082031 12.578125 2.007813 12.8125 2.003906 12.976563 C 2.003906 12.980469 2 12.988281 2 12.992188 C 2 13.15625 2.078125 13.402344 2.160156 13.484375 C 2.238281 13.648438 5.28125 17.507813 8.640625 19.804688 C 8.960938 19.96875 9.28125 20.050781 9.519531 19.886719 C 9.839844 19.722656 10 19.476563 10 19.148438 L 10 16 L 23.28125 15 C 23.679688 14.679688 24 13.875 24 12.992188 C 24 12.195313 23.761719 11.320313 23.28125 11 Z"/></svg>
        </div>
        
        <div class="modal__icon modal__arrow modal__arrow--right" title="Arrow Right" aria-label="Arrow Right Button">

          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 26 26" width="28" height="28"><path fill="currentColor" d="M 2.71875 11.023438 L 16 10.023438 L 16 6.875 C 16 6.546875 16.160156 6.300781 16.480469 6.054688 C 16.800781 5.972656 17.121094 5.972656 17.359375 6.136719 C 20.640625 8.433594 23.761719 12.28125 23.839844 12.445313 C 23.917969 12.601563 23.992188 12.835938 23.996094 13 C 23.996094 13.003906 24 13.011719 24 13.015625 C 24 13.179688 23.921875 13.425781 23.839844 13.507813 C 23.761719 13.671875 20.71875 17.53125 17.359375 19.828125 C 17.039063 19.992188 16.71875 20.074219 16.480469 19.910156 C 16.160156 19.746094 16 19.5 16 19.171875 L 16 16.023438 L 2.71875 15.023438 C 2.320313 14.703125 2 13.898438 2 13.015625 C 2 12.21875 2.238281 11.34375 2.71875 11.023438 Z"/></svg>
        </div>

        <div class="modal__caption">
          <div class="modal__caption--text">
          </div>
        </div>

      </span>
    </div>
  </div>
</div>


<script defer src="/js/swipe.min.08ff2be1b74347bad9e267f732f1388d271b2f9d97b6a8a87bd6a510f17c5ad2.js"></script>

<script defer src="/js/micromodal.min.de01b44b2f383056bbcaf6ee921fd385d79108ec1129afd0eb2f3f5a07e11f45.js"></script>

<script defer src="/js/helper/fadeinout.min.js"></script>

<script>
document.addEventListener('DOMContentLoaded', function () {
  
   
  var docElem = document.documentElement;

   
  function openFullscreen() {
    if (docElem.requestFullscreen) {
      docElem.requestFullscreen();
    } else if (docElem.mozRequestFullScreen) {  
      docElem.mozRequestFullScreen();
    } else if (docElem.webkitRequestFullscreen) {  
      docElem.webkitRequestFullscreen();
    } else if (docElem.msRequestFullscreen) {  
      docElem.msRequestFullscreen();
    }
  }

   
  function closeFullscreen() {
    if (document.fullscreenElement ||
      document.webkitFullscreenElement ||
      document.mozFullScreenElement) {
      if (document.exitFullscreen) {
        document.exitFullscreen();
      } else if (document.mozCancelFullScreen) {  
        document.mozCancelFullScreen();
      } else if (document.webkitExitFullscreen) {  
        document.webkitExitFullscreen();
      } else if (document.msExitFullscreen) {  
        document.msExitFullscreen();
      }
    }
  }

  var modal = document.getElementById('modal');
  var galleryContainerElem = document.querySelector('.gallery__container');
  var swipeWrapElem = document.querySelector('.swipe-wrap');
  var mySwipeElem = document.getElementById('mySwipe');
  var arrowLeftElem = document.querySelector('.modal__arrow--left');
  var arrowRightElem = document.querySelector('.modal__arrow--right');
  var closeElem = document.querySelector('.modal__toolbar--close');
  var fullElem = document.querySelector('.modal__toolbar--full');
  var normalElem = document.querySelector('.modal__toolbar--normal');
  var captionElem = document.querySelector('.modal__caption');
  var pagingElem = document.querySelector('.modal__paging');
  var itemsElem = document.querySelector('.modal__items');
  var imgTotalNum = null;
  var myFadeTimeout = null;
  var mySwipe = null;
  var keydownFunction = function (e) {
    if (e.key === 'ArrowRight') {
      if (modal && modal.classList.contains('is-open')) {
        mySwipe.next();
      }
    } else if (e.key === 'ArrowLeft') {
      if (modal && modal.classList.contains('is-open')) {
        mySwipe.prev();
      }
    }
  }

  if (galleryContainerElem) {
    imgTotalNum = galleryContainerElem.querySelectorAll('img').length;
  } else {
    galleryContainerElem = document.querySelector('.single__contents');
    imgTotalNum = galleryContainerElem.querySelectorAll('img').length;
  }

  MicroModal.init({
    onClose: function () {
      if (mySwipe) {
        mySwipe.kill();
        mySwipe = null;
        closeFullscreen();
      }
      window.removeEventListener('keydown', keydownFunction);
    },
    disableScroll: true,
    disableFocus: true,
    awaitOpenAnimation: false,
    awaitCloseAnimation: false,
    debugMode: false,
  });

  var imageLoad = function(src) {
    return new Promise(function(resolve, reject) {
      var newImg = new Image;
      newImg.onload = function() {
        resolve(newImg);
      }
      newImg.onerror = reject;
      newImg.src = src;
    });
  }

  galleryContainerElem.querySelectorAll('img').forEach(function (elem, idx) {
    elem.style.cursor = 'pointer';

    var clonedElem = elem.cloneNode(true);
    clonedElem.style.maxHeight = '100%';
    clonedElem.style.maxWidth = '100%';
    clonedElem.onclick = function (e) {
      e.stopPropagation();
    }

    var wrapper = document.createElement('div');
    wrapper.style.width = '100%';
    wrapper.style.height = '100vh';
    wrapper.setAttribute('data-micromodal-close', '');
    wrapper.onclick = function () {
      if (mySwipe) {
        mySwipe.kill();
        mySwipe = null;
      }
    }
    wrapper.onmouseenter = function () {
      clearTimeout(myFadeTimeout);
      fadeIn(itemsElem, 200);
    };
    wrapper.onmouseleave = function () {
      myFadeTimeout = setTimeout(function () {
        fadeOut(itemsElem, 200);
      }, 2500);
    }
    wrapper.ontouchstart = function() {
      fadeIn(itemsElem, 200);
    }
    wrapper.append(clonedElem);
    swipeWrapElem.append(wrapper);

    elem.addEventListener('click', async function (e) {
      MicroModal.show('modal');
      if (mySwipe) {
        mySwipe.kill();
        mySwipe = null;
      }

      var imgSrc = e.target.getAttribute('data-src') || e.target.getAttribute('src');
      var img = await imageLoad(imgSrc);
      clonedElem.style.width = img.width + 'px';
      clonedElem.style.height = img.height + 'px';
      
      
      mySwipe = new Swipe(mySwipeElem, {
        startSlide: idx,
        draggable: true,
        autoRestart: false,
        continuous: false,
        disableScroll: true,
        stopPropagation: true,
        callback: async function (index, element) {
          
          var imgElem = element.querySelector('img');
          var imgSrc = imgElem.getAttribute('data-src') || imgElem.getAttribute('src');
          var img = await imageLoad(imgSrc);
          imgElem.style.width = img.width + 'px';
          imgElem.style.height = img.height + 'px';

          
          if (captionElem && imgElem) {
            var caption = null;
            if (imgElem.getAttribute('data-caption')) {
              caption = imgElem.getAttribute('data-caption');
            } else if (imgElem.getAttribute('title')) {
              caption = imgElem.getAttribute('title');
            } else if (imgElem.getAttribute('alt')) {
              caption = imgElem.getAttribute('alt');
            } else {
              caption = imgElem.getAttribute('src');
            }

            captionElem.querySelector('.modal__caption--text').innerText = caption;
            pagingElem.innerText = (index + 1) + ' / ' + imgTotalNum;

            clearTimeout(myFadeTimeout);
            fadeIn(itemsElem, 200);
          }
        },
      });

      fadeIn(itemsElem);

      
      if (captionElem) {
        var caption = null;
        if (e.target.getAttribute('data-caption')) {
          caption = e.target.getAttribute('data-caption');
        } else if (e.target.getAttribute('title')) {
          caption = e.target.getAttribute('title');
        } else if (e.target.getAttribute('alt')) {
          caption = e.target.getAttribute('alt');
        } else {
          caption = e.target.getAttribute('src');
        }

        captionElem.querySelector('.modal__caption--text').innerText = caption;
        pagingElem.innerText = (idx + 1) + ' / ' + imgTotalNum;
      }

      if (normalElem && fullElem) {
        normalElem.style.zIndex = -1;
        normalElem.style.opacity = 0;
        fullElem.style.zIndex = 25;
        fullElem.style.opacity = 1;
      }
    });

    window.addEventListener('keydown', keydownFunction);
  });

  arrowLeftElem ?
    arrowLeftElem.addEventListener('click', function (e) {
      if (mySwipe) {
        mySwipe.prev();
      }
    }) : null;
  arrowRightElem ?
    arrowRightElem.addEventListener('click', function (e) {
      if (mySwipe) {
        mySwipe.next();
      }
    }) : null;

  closeElem ?
    closeElem.addEventListener('click', function () {
      if (mySwipe) {
        mySwipe.kill();
        mySwipe = null;
      }
      closeFullscreen();
      MicroModal.close('modal');
    }) : null;

  fullElem ?
    fullElem.addEventListener('click', function (e) {
      openFullscreen();
      if (normalElem) {
        normalElem.style.zIndex = 25;
        normalElem.style.opacity = 1;
        fullElem.style.zIndex = -1;
        fullElem.style.opacity = 0;
      }
    }) : null;

  normalElem ?
    normalElem.addEventListener('click', function (e) {
      closeFullscreen();
      if (fullElem) {
        fullElem.style.zIndex = 25;
        fullElem.style.opacity = 1;
        normalElem.style.zIndex = -1;
        normalElem.style.opacity = 0;
      }
    }) : null;
  
});
</script>

    <div class="hide">
      

<div class="search">
  <span class="icon">
    <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path d="M15.5 14h-.79l-.28-.27c1.2-1.4 1.82-3.31 1.48-5.34-.47-2.78-2.79-5-5.59-5.34-4.23-.52-7.79 3.04-7.27 7.27.34 2.8 2.56 5.12 5.34 5.59 2.03.34 3.94-.28 5.34-1.48l.27.28v.79l4.25 4.25c.41.41 1.08.41 1.49 0 .41-.41.41-1.08 0-1.49L15.5 14zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/></svg>
  </span>
  <input id="search" aria-label="Site Search" class="input" type="text" placeholder="Search" autocomplete="off">
  <div id="search-results" class="dropdown">
    <div id="search-menu" class="dropdown-menu" role="menu">
    </div>
  </div>
</div>


    </div>
  </div>
</main>


<script>
  
  
  

  var enableToc = JSON.parse("true");
  var toc = JSON.parse("null");
  var tocPosition = JSON.parse("\"outer\"");
  
  var singleMainElem = document.querySelector('.single__main');
  var singleSideElem = document.querySelector('.single__side');

  enquire.register("screen and (max-width: 769px)", {
    match: function () {
      if ((enableToc || toc) && tocPosition !== "outer") {
        if (singleMainElem && singleSideElem) {
          singleMainElem.classList.remove('main-main');
          singleMainElem.classList.add('main');
          singleSideElem.classList.remove('main-side');
          singleSideElem.classList.add('hide');
        }
      } else if (tocPosition === "outer") {
        if (singleMainElem && !singleMainElem.classList.contains('main-main')) {
          singleMainElem.classList.remove('main-main');
          singleMainElem.classList.add('main');
        }
        if (singleSideElem && !singleSideElem.classList.contains('hide')) {
          singleSideElem.classList.add('hide');
        }
      }
    },
    unmatch: function () {
      if ((enableToc || toc) && tocPosition !== "outer") {
        singleMainElem.classList.remove('main');
        singleMainElem.classList.add('main-main');
        singleSideElem.classList.remove('hide');
        singleSideElem.classList.add('main-side');
      } else if (tocPosition === "outer") {
        if (singleMainElem && !singleMainElem.classList.contains('main-main')) {
          singleMainElem.classList.remove('main-main');
          singleMainElem.classList.add('main');
        }
        if (singleSideElem && !singleSideElem.classList.contains('hide')) {
          singleSideElem.classList.add('hide');
        }
      }

      var navCollapseBtn = document.querySelector('.navbar__burger');
      var navCollapse = document.getElementsByClassName('navbarm__collapse')[0];
      if (navCollapse) {
        navCollapse.setAttribute('data-open', false);
        navCollapse.style.maxHeight = 0;
        navCollapseBtn.classList.remove('is-active');
      }
      document.getElementsByClassName('navbar__menu')[0].classList.remove('is-active');
      document.getElementsByClassName('mobile-search')[0].classList.add('hide');
    },
    setup: function () { },
    deferSetup: true,
    destroy: function () { },
  });
</script>




<script defer src="/js/clipboard.min.c168d3a04c45a631be76437054619a4a3b30107960cb9730be96012fef5762b0.js"></script>

<script defer src="/js/helper/getParents.min.js"></script>

<script defer src="/js/helper/closest.min.js"></script>

<script defer src="/js/helper/prev.min.js"></script>

<script defer src="/js/helper/prop.min.js"></script>

<script defer src="/js/helper/fadeinout.min.js"></script>

















<script>
  'use strict';

  window.onload = function() {
    var navbar = document.querySelector('.navbar');
    var singleContentsElem = document.querySelector('.single__contents');

    
    
    
    var enableBusuanzi = JSON.parse("false");
    var busuanziPagePV = JSON.parse("true");
    
    if (enableBusuanzi && busuanziPagePV) {
      var pagePvElem = document.querySelector('#busuanzi_value_page_pv');
      pagePvElem.textContent = pagePvElem.textContent.replace(/(\d)(?=(\d\d\d)+(?!\d))/g, "$1,");
    }    
    


    
    
    
    
    
    
    var enableToc = JSON.parse("true");
    var toc = JSON.parse("null");
    var hideToc = JSON.parse("false");
    var tocFlexbox = document.querySelector('.toc__flexbox');
    var tocFlexboxOuter = document.querySelector('.toc__flexbox--outer');
    var tocFolding = JSON.parse("true");
    
    if ((enableToc || toc) && document.querySelector('.toc')) {
      var tableOfContentsElem = document.querySelector('.toc').querySelector('#TableOfContents');

      if (false === tocFolding) {

      } else {
        tableOfContentsElem.querySelectorAll('ul') ?
          tableOfContentsElem.querySelectorAll('ul').forEach(function (rootUl) {
            rootUl.querySelectorAll('li').forEach(function (liElem) {
              liElem.querySelectorAll('ul').forEach(function (ulElem) {
                ulElem.style.display = 'none';
              });
            });
          }) : null;
      }

      if (tableOfContentsElem) {
        if (tableOfContentsElem.querySelectorAll('a').length > 0) {
          tableOfContentsElem.querySelectorAll('a').forEach(function (elem) {
            elem.addEventListener('click', function () {
              var id = elem.getAttribute('id');
              navbar.classList.remove('navbar--show');
              navbar.classList.remove('navbar--hide');
              navbar.classList.add('navbar--hide');

              document.querySelector('.toc').querySelectorAll('a').forEach(function (elem) {
                elem.classList.remove('active');
              });
              elem.classList.add('active');

              var curElem = tableOfContentsElem.querySelector('[href="#' + id + '"]');
              if (curElem && curElem.nextElementSibling) {
                curElem.nextElementSibling.style.display = 'block';
              }
              if (curElem) {
                getParents(curElem, 'ul') ?
                  getParents(curElem, 'ul').forEach(function (elem) {
                    elem.style.display = 'block';
                  }) : null;
              }
            });
          });
        } else {
          if (tocFlexbox) {
            tocFlexbox.setAttribute('data-position', '');
            if (!tocFlexbox.classList.contains('hide')) {
              tocFlexbox.classList.add('hide');
            }
          }
          if (tocFlexboxOuter) {
            tocFlexboxOuter.setAttribute('data-position', '');
            if (!tocFlexboxOuter.classList.contains('hide')) {
              tocFlexboxOuter.classList.add('hide');
            }
          }
        }
      }

      
      var toggleTocElem = document.getElementById("toggle-toc");
      var visibleTocElem = document.getElementById('visible-toc');
      var tocElem = document.querySelector('.toc');
      var mainElem = document.querySelector('main');
      var sideElem = document.querySelector('side');
      var tocFlexboxElem = document.querySelector('.toc__flexbox');

      toggleTocElem ? 
      toggleTocElem.addEventListener('change', function(e) {
        if (e.target.checked) {
          if (tocElem) {
            fadeIn(tocElem, 200);
          }
          if (tocFlexboxElem) {
            tocFlexboxElem.setAttribute('data-position', 'fixed');
          }

          if (mainElem) {
            mainElem.classList.remove('main-main');
            mainElem.classList.remove('main');
            mainElem.classList.add('main-main');
          }
          if (sideElem) {
            sideElem.classList.remove('main-side');
          }
        } else {
          if (tocElem) {
            fadeOut(tocElem, 200);
          }
          if (tocFlexboxElem) {
            tocFlexboxElem.setAttribute('data-position', 'absolute');
          }

          if (mainElem) {
            mainElem.classList.remove('main-main');
            mainElem.classList.remove('main');
            mainElem.classList.add('main');
          }
          if (sideElem) {
            sideElem.classList.remove('main-side');
          }
        }
      }) : null;

      visibleTocElem ?
      visibleTocElem.addEventListener('change', function(e) {
        if (e.target.checked) {
          if (tocElem) {
            fadeIn(tocElem, 200);
          }
        } else {
          if (tocElem) {
            fadeOut(tocElem, 200);
          }
        }
      }) : null;
    }
    


    
    var tables = document.querySelectorAll('.single__contents > table');
    for (let i = 0; i < tables.length; i++) {
      var table = tables[i];
      var wrapper = document.createElement('div');
      wrapper.className = 'table-wrapper';
      table.parentElement.replaceChild(wrapper, table);
      wrapper.appendChild(table);
    }
    


    
    var text, clip = new ClipboardJS('.anchor');
    var headers = singleContentsElem.querySelectorAll("h1, h2, h3, h4");

    
    var languagedir = JSON.parse("\"ltr\"");

    headers ? 
    headers.forEach(function (elem) {
      var url = encodeURI(document.location.origin + document.location.pathname);
      var link = url + "#" + elem.getAttribute('id');
      var newElemOuter = document.createElement('span');
      newElemOuter.classList.add('anchor');
      newElemOuter.classList.add('hide');
      newElemOuter.setAttribute('data-clipboard-text', link);
      newElemOuter.style.position = 'relative';

      var newElemInner = document.createElement('span');
      newElemInner.style.fontSize = '1rem';
      newElemInner.style.position = 'absolute';
      newElemInner.style.top = '50%';
      newElemInner.style.transform = 'translateY(-50%)';
      newElemInner.innerText = "🔗";

      if (languagedir === "rtl") {
        newElemInner.style.left = '-2rem';
      } else {
        newElemInner.style.right = '-2rem';
      }

      newElemOuter.append(newElemInner);
      elem.append(newElemOuter);

      elem.addEventListener('mouseenter', function() {
        this.querySelector('.anchor').classList.remove('hide');
      });
      elem.addEventListener('mouseleave', function () {
        this.querySelector('.anchor').classList.add('hide');
      });
    }) : null;

    document.querySelectorAll('.anchor').forEach(function(elem) {
      elem.addEventListener('mouseleave', function() {
        elem.setAttribute('aria-label', null);
        elem.classList.remove('tooltipped');
        elem.classList.remove('tooltipped-s');
        elem.classList.remove('tooltipped-w');
      });
    });

    clip.on('success', function (e) {
      e.clearSelection();
      e.trigger.setAttribute('aria-label', 'Link copied to clipboard!');
      e.trigger.classList.add('tooltipped');
      e.trigger.classList.add('tooltipped-s');
    });
    


    
    var clipInit = false;
    var preChromaElem = document.querySelectorAll('pre.chroma');
    var langCodeElem = document.querySelectorAll('.language-code');
    var dolorCodeElem = document.querySelectorAll('div.language-\\$');
    var gtCodeElem = document.querySelectorAll('div.language-\\>');

    var makeClipboard = function(elem) {
      var code = elem,
        text = elem.textContent;
        
      if (text.length > 15) {
        if (!clipInit) {
          var text, clip = new ClipboardJS('.copy-to-clipboard', {
            text: function (trigger) {
              var codeElem = prev(trigger).querySelectorAll('code');
              if (codeElem.length > 1) {
                text = prev(trigger).querySelector('code[class^="language-"]').textContent;
              } else {
                text = prev(trigger).querySelector('code').textContent;
              }

              return text.replace(/^\$\s/gm, '');
            }
          });

          var inPre;
          clip.on('success', function (e) {
            e.clearSelection();
            inPre = prop(e.trigger.parentNode, 'tagName') == 'PRE';
            e.trigger.setAttribute('aria-label', 'Copied to clipboard!');
            e.trigger.classList.add('tooltipped');
            e.trigger.classList.add('tooltipped-w');
          });

          clip.on('error', function (e) {
            inPre = prop(e.trigger.parentNode, 'tagName') == 'PRE';
            e.trigger.setAttribute('aria-label', e.action.toString());
            e.trigger.classList.add('tooltipped');
            e.trigger.classList.add('tooltipped-w');
          });

          clipInit = true;
        }

        var notAllowedClass = ['language-mermaid', 'language-viz', 'language-wave', 'language-chart', 'language-msc', 'language-flowchart'];
        var isNotAllowedIncluded = false;
        var curClassName = code.getAttribute('class');

        for (var i = 0; i < notAllowedClass.length; i++) {
          if (curClassName && curClassName.startsWith(notAllowedClass[i])) {
            isNotAllowedIncluded = true;
            break;
          }
        }

        if (!isNotAllowedIncluded) {
          if (curClassName) {
            var newClipboardElem = document.createElement('span');
            newClipboardElem.setAttribute('class', 'copy-to-clipboard');
            newClipboardElem.setAttribute('title', 'Copy to clipboard');
            closest(code, 'div.chroma').append(newClipboardElem);
          }
        }
      }
    }

    var makeSymbolClipboard = function(elem) {
      var clipboardSpan = document.createElement('span');
      clipboardSpan.setAttribute('class', 'copy-to-clipboard');
      clipboardSpan.setAttribute('title', 'Copy to clipboard');
      elem.parentNode.parentNode.insertBefore(clipboardSpan, elem.parentNode.nextElementSibling);
    }

    preChromaElem ? 
    preChromaElem.forEach(function(elem) {
      elem.querySelectorAll('code').forEach(function(codeElem) {
        makeClipboard(codeElem);
      });
    }) : null;
    
    langCodeElem ? 
    langCodeElem.forEach(function(elem) {
      elem.querySelectorAll('code').forEach(function (codeElem) {
        makeClipboard(codeElem);
      });
    }) : null;

    dolorCodeElem ? 
    dolorCodeElem.forEach(function(elem) {
      elem.querySelectorAll('code').forEach(function (codeElem) {
        makeSymbolClipboard(codeElem);
      });
    }) : null;

    gtCodeElem ?
    gtCodeElem.forEach(function(elem) {
      elem.querySelectorAll('code').forEach(function (codeElem) {
        makeSymbolClipboard(codeElem);
      });
    }) : null;
    


    
    dolorCodeElem ?
    dolorCodeElem.forEach(function(elem) {
      var lnts = elem.parentNode.parentNode ? elem.parentNode.parentNode.querySelectorAll('.lnt') : null;
      lnts ? 
      lnts.forEach(function(lnt) {
        lnt.innerHTML = '$<br/>';
      }) : null;
    }) : null;

    gtCodeElem ?
    gtCodeElem.forEach(function(elem) {
      var lnts = elem.parentNode.parentNode ? elem.parentNode.parentNode.querySelectorAll('.lnt') : null;
      lnts ? 
      lnts.forEach(function(lnt) {
        lnt.innerHTML = '><br/>';
      }) : null;
    }) : null;
    


    
    
    var lib = JSON.parse("null");

    if (lib && lib.includes('mermaid')) {
      
      var themeVariant = localStorage.getItem('theme') || JSON.parse("\"dark\"");

      if (themeVariant === "dark" || themeVariant === "hacker") {
        mermaid.initialize({ theme: 'dark' });
      } else {
        mermaid.initialize({ theme: 'default' });
      }
      
      var mermaids = [];
      [].push.apply(mermaids, document.getElementsByClassName('language-mermaid'));
      mermaids.forEach(function(elem) {
        var elemParentNode = elem.parentNode;

        if (elemParentNode !== document.body) {
          elemParentNode.parentNode.insertBefore(elem, elemParentNode);
          elemParentNode.parentNode.removeChild(elemParentNode);
        }

        var newElemWrapper = document.createElement('div');
        newElemWrapper.classList.add('mermaid');
        newElemWrapper.style.padding = '34px 4px 6px';
        newElemWrapper.innerHTML = elem.innerHTML;
        elem.replaceWith(newElemWrapper);
      });
    }
    
    

    
    if (lib && lib.includes('katex')) {
      var mathElements = document.getElementsByClassName('math');
      var options = {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "\\[", right: "\\]", display: true },
          { left: "$", right: "$", display: false },
          { left: "\\(", right: "\\)", display: false }
        ],
      };

      renderMathInElement(document.querySelector('.single__contents'), options);
    }
    


    
    if (lib && lib.includes('flowchartjs')) {
      
      var options = JSON.parse("{\"arrow-end\":\"block\",\"element-color\":\"black\",\"fill\":\"white\",\"flowstate\":{\"approved\":{\"fill\":\"#58C4A3\",\"font-size\":12,\"no-text\":\"n/a\",\"yes-text\":\"APPROVED\"},\"current\":{\"fill\":\"yellow\",\"font-color\":\"red\",\"font-weight\":\"bold\"},\"future\":{\"fill\":\"#FFFF99\"},\"invalid\":{\"fill\":\"#444444\"},\"past\":{\"fill\":\"#CCCCCC\",\"font-size\":12},\"rejected\":{\"fill\":\"#C45879\",\"font-size\":12,\"no-text\":\"REJECTED\",\"yes-text\":\"n/a\"},\"request\":{\"fill\":\"blue\"}},\"font-color\":\"black\",\"font-size\":14,\"line-color\":\"black\",\"line-length\":50,\"line-width\":3,\"no-text\":\"no\",\"scale\":1,\"symbols\":{\"end\":{\"class\":\"end-element\"},\"start\":{\"element-color\":\"green\",\"fill\":\"yellow\",\"font-color\":\"red\"}},\"text-margin\":10,\"x\":0,\"y\":0,\"yes-text\":\"yes\"}");
      var jsonContent = null;

      var flowchartPrefix = "language-flowchart";
      var index = 0;
      Array.prototype.forEach.call(document.querySelectorAll("[class^=" + flowchartPrefix + "]"), function(x){
          x.style.display = 'none'
          x.parentNode.style.backgroundColor = "transparent"
          jsonContent = x.innerText;

          var node0 = document.createElement('div');
          node0.id = 'flowchart' + index;
          x.parentNode.insertBefore(node0, x);

          var diagram = flowchart.parse(jsonContent);
          diagram.drawSVG("flowchart"+index, options);

          index +=1;
      });      
    }
    


    
    


    
    if (lib && lib.includes('msc')) {
      
      var options = JSON.parse("{\"theme\":\"hand\"}");
      var jsonContent = null;

      var index = 0;
      var chartPrefix = "language-msc";
      Array.prototype.forEach.call(document.querySelectorAll("[class^=" + chartPrefix + "]"), function (x) {
        x.style.display = 'none'
        x.parentNode.style.backgroundColor = "transparent"
        jsonContent = x.innerText;
        var node0 = document.createElement('div');
        node0.id = 'msc' + index;
        x.parentNode.insertBefore(node0, x);
        var diagram = Diagram.parse(jsonContent);
        diagram.drawSVG("msc" + index, options);
        index += 1;
      });
    }
    


    
    if (lib && lib.includes('chart')) {
      var borderColor = "#666";
      var bgColor = "#ddd";
      var borderWidth = 2;

      Chart.defaults.global.elements.rectangle.borderWidth = borderWidth;
      Chart.defaults.global.elements.rectangle.borderColor = borderColor;
      Chart.defaults.global.elements.rectangle.backgroundColor = bgColor;

      Chart.defaults.global.elements.line.borderWidth = borderWidth;
      Chart.defaults.global.elements.line.borderColor = borderColor;
      Chart.defaults.global.elements.line.backgroundColor = bgColor;

      Chart.defaults.global.elements.point.borderWidth = borderWidth;
      Chart.defaults.global.elements.point.borderColor = borderColor;
      Chart.defaults.global.elements.point.backgroundColor = bgColor;

      var chartPrefix = "language-chart";
      var index = 0;
      var jsonContent = null;

      Array.prototype.forEach.call(document.querySelectorAll("[class^=" + chartPrefix + "]"), function (x) {
        x.style.display = 'none'
        x.parentNode.style.backgroundColor = "transparent"
        jsonContent = x.innerText;
        var node0 = document.createElement('canvas');
        var source = null;
        node0.height = 200;
        node0.style.height = 200;
        node0.id = 'myChart' + index;
        source = JSON.parse(jsonContent);
        x.parentNode.insertBefore(node0, x);
        var ctx = document.getElementById('myChart' + index).getContext('2d');
        var myChart = new Chart(ctx, source);
        index += 1;
      });            
    }
    


    
    if (lib && lib.includes('wavedrom')) {
      var wavePrefix = "language-wave";
      var index = 0;
      var jsonContent = null;
      
      Array.prototype.forEach.call(document.querySelectorAll("[class^=" + wavePrefix + "]"), function (x) {
        x.style.display = 'none'
        x.parentNode.style.backgroundColor = "transparent"
        jsonContent = x.innerText;
        var node0 = document.createElement('div');
        var source = null;
        node0.id = 'WaveDrom_Display_' + index;
        source = JSON.parse(jsonContent);
        x.parentNode.insertBefore(node0, x);
        WaveDrom.RenderWaveForm(index, source, "WaveDrom_Display_");
        index += 1;
      });
    }
    


    
    if (lib && lib.includes('viz')) {
      var vizPrefix = "language-viz-";
      Array.prototype.forEach.call(document.querySelectorAll("[class^=" + vizPrefix + "]"), function (x) {
        x.style.display = 'none'
        x.parentNode.style.backgroundColor = "transparent"
        var engine;
        x.getAttribute("class").split(" ").forEach(function (cls) {
          if (cls.startsWith(vizPrefix)) {
            engine = cls.substr(vizPrefix.length);
          }
        });
        var viz = new Viz();
        viz.renderSVGElement(x.innerText, { engine: engine })
          .then(function (element) {
            element.style.width = "100%";
            x.parentNode.insertBefore(element, x);
          })
      });
    }
    
    
  }
</script>


            
            <footer class="footer">
    
<div class="dropdown">
  <button class="dropdown-trigger" aria-label="Select Theme Button">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path fill="currentColor" d="M12.65 15.67c.14-.36.05-.77-.23-1.05l-2.09-2.06.03-.03c1.74-1.94 2.98-4.17 3.71-6.53h1.94c.54 0 .99-.45.99-.99v-.02c0-.54-.45-.99-.99-.99H10V3c0-.55-.45-1-1-1s-1 .45-1 1v1H1.99c-.54 0-.99.45-.99.99 0 .55.45.99.99.99h10.18C11.5 7.92 10.44 9.75 9 11.35c-.81-.89-1.49-1.86-2.06-2.88-.16-.29-.45-.47-.78-.47-.69 0-1.13.75-.79 1.35.63 1.13 1.4 2.21 2.3 3.21L3.3 16.87c-.4.39-.4 1.03 0 1.42.39.39 1.02.39 1.42 0L9 14l2.02 2.02c.51.51 1.38.32 1.63-.35zM17.5 10c-.6 0-1.14.37-1.35.94l-3.67 9.8c-.24.61.22 1.26.87 1.26.39 0 .74-.24.88-.61l.89-2.39h4.75l.9 2.39c.14.36.49.61.88.61.65 0 1.11-.65.88-1.26l-3.67-9.8c-.22-.57-.76-.94-1.36-.94zm-1.62 7l1.62-4.33L19.12 17h-3.24z"/></svg>
  </button>
  <div class="dropdown-content">
    
    
    
      
      
        
        
          
            
              <a href="https://hoontaeklee.github.io/en/posts/20200516_islr/" data-lang="en" class="dropdown-item is-active">English</a>
            
          
        
      
        
      
    
  </div>
</div>

    
<div class="footer__social">
  <div class="social">
    
            
    
            
    
            
    
      
      <a href="mailto:lht3718@email.com" title="email" aria-label="email">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><path fill="currentColor" d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm-.4 4.25l-7.07 4.42c-.32.2-.74.2-1.06 0L4.4 8.25c-.25-.16-.4-.43-.4-.72 0-.67.73-1.07 1.3-.72L12 11l6.7-4.19c.57-.35 1.3.05 1.3.72 0 .29-.15.56-.4.72z"/></svg>
      </a>
            
    
            
    
            
    
      
      <a href="https://github.com/hoontaeklee" title="github" aria-label="github">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="32" height="32" viewBox="0 0 24 24" version="1.1">
<g id="surface3680">
<path fill="currentColor" d="M 10.898438 2.101562 C 6.300781 2.601562 2.601562 6.300781 2.101562 10.800781 C 1.601562 15.5 4.300781 19.699219 8.398438 21.300781 C 8.699219 21.398438 9 21.199219 9 20.800781 L 9 19.199219 C 9 19.199219 8.601562 19.300781 8.101562 19.300781 C 6.699219 19.300781 6.101562 18.101562 6 17.398438 C 5.898438 17 5.699219 16.699219 5.398438 16.398438 C 5.101562 16.300781 5 16.300781 5 16.199219 C 5 16 5.300781 16 5.398438 16 C 6 16 6.5 16.699219 6.699219 17 C 7.199219 17.800781 7.800781 18 8.101562 18 C 8.5 18 8.800781 17.898438 9 17.800781 C 9.101562 17.101562 9.398438 16.398438 10 16 C 7.699219 15.5 6 14.199219 6 12 C 6 10.898438 6.5 9.800781 7.199219 9 C 7.101562 8.800781 7 8.300781 7 7.601562 C 7 7.199219 7 6.601562 7.300781 6 C 7.300781 6 8.699219 6 10.101562 7.300781 C 10.601562 7.101562 11.300781 7 12 7 C 12.699219 7 13.398438 7.101562 14 7.300781 C 15.300781 6 16.800781 6 16.800781 6 C 17 6.601562 17 7.199219 17 7.601562 C 17 8.398438 16.898438 8.800781 16.800781 9 C 17.5 9.800781 18 10.800781 18 12 C 18 14.199219 16.300781 15.5 14 16 C 14.601562 16.5 15 17.398438 15 18.300781 L 15 20.898438 C 15 21.199219 15.300781 21.5 15.699219 21.398438 C 19.398438 19.898438 22 16.300781 22 12.101562 C 22 6.101562 16.898438 1.398438 10.898438 2.101562 Z M 10.898438 2.101562 "/>
</g>
</svg>

      </a>
            
    
            
    
            
    
      
      <a href="https://scholar.google.co.kr/" title="google-scholar" aria-label="google-scholar">
        <svg fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="32" height="32"><path d="M 25 2 C 12.309534 2 2 12.309534 2 25 C 2 37.690466 12.309534 48 25 48 C 37.690466 48 48 37.690466 48 25 C 48 12.309534 37.690466 2 25 2 z M 25 4 C 36.609534 4 46 13.390466 46 25 C 46 36.609534 36.609534 46 25 46 C 13.390466 46 4 36.609534 4 25 C 4 13.390466 13.390466 4 25 4 z M 21 11 L 11 20 L 17.78125 20 C 17.80125 22.847 19.967531 25.730469 23.769531 25.730469 C 24.129531 25.730469 24.529688 25.690391 24.929688 25.650391 C 24.749688 26.100391 24.560547 26.470078 24.560547 27.080078 C 24.560547 28.230078 25.140391 28.920078 25.650391 29.580078 C 24.020391 29.690078 20.989766 29.879531 18.759766 31.269531 C 16.629766 32.559531 15.980469 34.43 15.980469 35.75 C 15.980469 38.47 18.500469 41 23.730469 41 C 29.930469 41 33.220703 37.510547 33.220703 34.060547 C 33.220703 31.530547 31.779453 30.279922 30.189453 28.919922 L 28.900391 27.890625 C 28.500391 27.570625 27.949219 27.120312 27.949219 26.320312 C 27.949219 25.510313 28.500703 24.989766 28.970703 24.509766 C 30.480703 23.309766 32 21.960234 32 19.240234 C 32 18.197234 31.756203 17.348391 31.408203 16.650391 L 35 13.570312 L 35 17.277344 C 34.405 17.623344 34 18.261 34 19 L 34 25 C 34 26.104 34.896 27 36 27 C 37.104 27 38 26.104 38 25 L 38 19 C 38 18.262 37.595 17.624344 37 17.277344 L 37 12 C 37 11.957 36.980609 11.920906 36.974609 11.878906 L 38 11 L 21 11 z M 24.269531 14.240234 C 27.269531 14.240234 28.820312 18.35 28.820312 21 C 28.820312 21.65 28.739922 22.819922 27.919922 23.669922 C 27.339922 24.259922 26.370938 24.699219 25.460938 24.699219 C 22.370938 24.699219 20.949219 20.620156 20.949219 18.160156 C 20.949219 17.210156 21.14 16.220938 21.75 15.460938 C 22.33 14.710938 23.339531 14.240234 24.269531 14.240234 z M 26.039062 30.609375 C 26.409063 30.609375 26.590859 30.610391 26.880859 30.650391 C 29.620859 32.630391 30.800781 33.620234 30.800781 35.490234 C 30.800781 37.760234 28.97 39.460938 25.5 39.460938 C 21.64 39.460938 19.160156 37.590469 19.160156 34.980469 C 19.160156 32.370469 21.459766 31.499219 22.259766 31.199219 C 23.769766 30.679219 25.719062 30.609375 26.039062 30.609375 z"/></svg>
      </a>
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
      
      <a href="https://stackoverflow.com/users/7578494/hoontaek" title="stack-overflow" aria-label="stack-overflow">
        <svg fill="#000000" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="32" height="32"><path fill="currentColor" d="M 9.914063 0.71875 L 9.085938 1.28125 L 11.894531 5.367188 L 12.71875 4.800781 Z M 7.695313 2.453125 L 7.039063 3.207031 L 10.917969 6.582031 L 11.574219 5.828125 Z M 6.226563 4.804688 L 5.773438 5.695313 L 10.210938 7.953125 L 10.664063 7.0625 Z M 5.363281 7.140625 L 5.136719 8.109375 L 9.976563 9.242188 L 10.203125 8.265625 Z M 3 9 L 3 14 L 12 14 L 12 9 L 11 9 L 11 13 L 4 13 L 4 9 Z M 5.03125 9.25 L 4.96875 10.25 L 9.972656 10.566406 L 10.035156 9.570313 Z M 5 11 L 5 12 L 10 12 L 10 11 Z"/></svg>
      </a>
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
            
    
    
  
  
    
      <a href="https://hoontaeklee.github.io/en/posts//index.xml" type="application/rss+xml" title="RSS" aria-label="RSS Feed Link">
        <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" d="M0 0h24v24H0V0z"/><circle fill="currentColor" cx="6.18" cy="17.82" r="2.18"/><path fill="currentColor" d="M5.59 10.23c-.84-.14-1.59.55-1.59 1.4 0 .71.53 1.28 1.23 1.4 2.92.51 5.22 2.82 5.74 5.74.12.7.69 1.23 1.4 1.23.85 0 1.54-.75 1.41-1.59-.68-4.2-3.99-7.51-8.19-8.18zm-.03-5.71C4.73 4.43 4 5.1 4 5.93c0 .73.55 1.33 1.27 1.4 6.01.6 10.79 5.38 11.39 11.39.07.73.67 1.28 1.4 1.28.84 0 1.5-.73 1.42-1.56-.73-7.34-6.57-13.19-13.92-13.92z"/></svg>
      </a>
    
  

  </div>
</div>

    
<div id="gtt">
  <div class="gtt">
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M8.12 14.71L12 10.83l3.88 3.88c.39.39 1.02.39 1.41 0 .39-.39.39-1.02 0-1.41L12.7 8.71c-.39-.39-1.02-.39-1.41 0L6.7 13.3c-.39.39-.39 1.02 0 1.41.39.38 1.03.39 1.42 0z"/></svg>
  </div>
</div>

    <hr />

    <div class="basicflex">
        
            <a href="" class="footer__link" target="_blank" rel="noreferrer"></a>
        
            <a href="" class="footer__link" target="_blank" rel="noreferrer"></a>
        
    </div>

    <div class="footer__poweredby">
        
                
            <p class="caption">
                
                    ©2021, All Rights Reserved
                
            </p>
        

        
            <p class="caption">Powered by <a href="https://gohugo.io/" target="_blank" rel="noreferrer">Hugo</a> and the <a href="https://github.com/zzossig/hugo-theme-zzo" target="_blank" rel="noreferrer">Zzo theme</a></p>
        
        
    </div> 
</footer>
        </div>
        
<div class="wrapper__right hide" dir="ltr">
  <script>document.querySelector('.wrapper__right').classList.remove('hide')</script>
  
    
      
        <div class="toc__flexbox--outer" data-position="fixed" data-dir="ltr" data-ani="true">
          <h6 class="toc__title toc__title--outer" data-ani="true">What&#39;s on this Page</h6>
          
          <label class="switch" data-ani="true">
            <input id="visible-toc" aria-label="Visible TOC" type="checkbox" checked>
            <span class="slider round"></span>
          </label>
          
        </div>
        <div class="toc toc__outer " data-dir="ltr" data-folding="true" data-ani="true">
          <nav id="TableOfContents">
  <ul>
    <li><a href="#2-statistical-learning">2. Statistical Learning</a>
      <ul>
        <li><a href="#21-what-is-statistical-learning">2.1. What Is Statistical Learning?</a>
          <ul>
            <li><a href="#211-why-estimate-f">2.1.1. Why Estimate f?</a></li>
            <li><a href="#212-how-do-we-estimate-f">2.1.2. How Do We Estimate f?</a></li>
            <li><a href="#213-the-trade-off-between-prediction-accuracy-and-model-interpretability">2.1.3. The Trade-Off Between Prediction Accuracy and Model Interpretability</a></li>
            <li><a href="#214-supervised-versus-unsupervised-learning">2.1.4. Supervised Versus Unsupervised Learning</a></li>
            <li><a href="#215-regression-versus-classification-problems">2.1.5. Regression Versus Classification Problems</a></li>
          </ul>
        </li>
        <li><a href="#22-assessing-model-accuracy">2.2. Assessing Model Accuracy</a>
          <ul>
            <li><a href="#221-measuring-the-quality-of-fit">2.2.1. Measuring the Quality of Fit</a></li>
            <li><a href="#222-the-bias-variance-trade-off">2.2.2. The Bias-Variance Trade-Off</a></li>
            <li><a href="#223-the-classification-setting">2.2.3. The Classification Setting</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#5-resampling-methods">5. Resampling Methods</a>
      <ul>
        <li><a href="#51-cross-validation">5.1. Cross-Validation</a>
          <ul>
            <li><a href="#511-the-validation-set-approach">5.1.1. The Validation Set Approach</a></li>
            <li><a href="#512-leave-one-out-cross-validation">5.1.2. Leave-One-Out Cross-Validation</a></li>
            <li><a href="#513-k-fold-cross-validation">5.1.3. k-Fold Cross-Validation</a></li>
            <li><a href="#514-bias-variance-trade-off-for-k-fold-cross-validation">5.1.4. Bias-Variance Trade-Off for k-Fold Cross-Validation</a></li>
            <li><a href="#515-cross-validation-on-classification-problems">5.1.5. Cross-Validation on Classification Problems</a></li>
          </ul>
        </li>
        <li><a href="#52-the-bootstrap">5.2. The Bootstrap</a></li>
        <li><a href="#53-lab-cross-validation-and-the-bootstrap">5.3. Lab: Cross-Validation and the Bootstrap</a>
          <ul>
            <li><a href="#531-the-validation-set-approach">5.3.1. The Validation Set Approach</a></li>
            <li><a href="#532-leave-one-out-cross-validation">5.3.2. Leave-One-Out Cross-Validation</a></li>
            <li><a href="#533-k-fold-cross-validation">5.3.3. k-Fold Cross-Validation</a></li>
            <li><a href="#534-the-bootstrap">5.3.4. The Bootstrap</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#7-moving-beyond-linearity">7. Moving Beyond Linearity</a>
      <ul>
        <li><a href="#74-regression-splines">7.4. Regression Splines</a>
          <ul>
            <li><a href="#741-piecewise-polynomials">7.4.1. Piecewise Polynomials</a></li>
            <li><a href="#742-constraints-and-splines">7.4.2. Constraints and Splines</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#8-tree-based-methods">8. Tree-Based Methods</a>
      <ul>
        <li><a href="#81-the-basics-of-decision-trees">8.1. The Basics of Decision Trees</a>
          <ul>
            <li><a href="#811-regression-trees">8.1.1. Regression Trees</a>
              <ul>
                <li><a href="#recursive-binary-splitting">Recursive Binary Splitting</a></li>
                <li><a href="#tree-pruning">Tree Pruning</a></li>
              </ul>
            </li>
            <li><a href="#812-classification-trees">8.1.2. Classification Trees</a></li>
            <li><a href="#813-trees-versus-linear-models">8.1.3. Trees Versus Linear Models</a></li>
            <li><a href="#814-advantages-and-disadvantages-of-trees">8.1.4. Advantages and Disadvantages of Trees</a></li>
          </ul>
        </li>
        <li><a href="#82-bagging-random-forests-boosting">8.2. Bagging, Random Forests, Boosting</a>
          <ul>
            <li><a href="#821-bagging">8.2.1. Bagging</a>
              <ul>
                <li><a href="#out-of-bag-error-estimation">Out-of-Bag Error Estimation</a></li>
                <li><a href="#variable-importance-measures">Variable Importance Measures</a></li>
              </ul>
            </li>
            <li><a href="#822-random-forests">8.2.2. Random Forests</a></li>
            <li><a href="#823-boosting">8.2.3. Boosting</a></li>
          </ul>
        </li>
        <li><a href="#83-lab-decision-trees">8.3. Lab: Decision Trees</a>
          <ul>
            <li><a href="#831-fitting-classification-trees">8.3.1. Fitting Classification Trees</a></li>
            <li><a href="#832-fitting-regression-trees">8.3.2. Fitting Regression Trees</a></li>
            <li><a href="#833-bagging-and-random-forests">8.3.3. Bagging and Random Forests</a></li>
            <li><a href="#834-boosting">8.3.4. Boosting</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#9-support-vector-machines">9. Support Vector Machines</a>
      <ul>
        <li><a href="#91-maximal-margin-classifier">9.1. Maximal Margin Classifier</a>
          <ul>
            <li><a href="#911-what-is-a-hyperplane">9.1.1. What Is a Hyperplane?</a></li>
            <li><a href="#912-classification-using-a-separating-hyperplane">9.1.2. Classification Using a Separating Hyperplane</a></li>
            <li><a href="#913-the-maximal-margin-classifier">9.1.3. The Maximal Margin Classifier</a></li>
            <li><a href="#914-construction-of-the-maximal-margin-classifier">9.1.4. Construction of the Maximal Margin Classifier</a></li>
            <li><a href="#915-the-non-separable-case">9.1.5. The Non-separable Case</a></li>
          </ul>
        </li>
        <li><a href="#92-support-vector-classifiers">9.2. Support Vector Classifiers</a>
          <ul>
            <li><a href="#921-overview-of-the-support-vector-classifier">9.2.1. Overview of the Support Vector Classifier</a></li>
            <li><a href="#922-details-of-the-support-vector-classifier">9.2.2. Details of the Support Vector Classifier</a></li>
          </ul>
        </li>
        <li><a href="#93-support-vector-machines">9.3. Support Vector Machines</a>
          <ul>
            <li><a href="#931-classification-with-non-liinear-decision-boundaries">9.3.1. Classification with Non-liinear Decision Boundaries</a></li>
            <li><a href="#932-the-support-vector-machine">9.3.2. The Support Vector Machine</a></li>
            <li><a href="#933-an-application-to-the-heart-disease-data">9.3.3. An Application to the Heart Disease Data</a></li>
          </ul>
        </li>
        <li><a href="#94-svms-with-more-than-two-classes">9.4. SVMs with More than Two Classes</a>
          <ul>
            <li><a href="#941-one-versus-one-classification">9.4.1. One-Versus-One Classification</a></li>
            <li><a href="#942-one-versus-all-classification">9.4.2. One-Versus-All Classification</a></li>
          </ul>
        </li>
        <li><a href="#95-relationship-to-logistic-regression">9.5. Relationship to Logistic Regression</a>
          <ul>
            <li>
              <ul>
                <li><a href="#support-vector-regression-vs-least-squares-regression">Support vector regression vs least squares regression</a></li>
              </ul>
            </li>
          </ul>
        </li>
        <li><a href="#96-lab-support-vector-machines">9.6. Lab: Support Vector Machines</a>
          <ul>
            <li><a href="#961-support-vector-classifier">9.6.1. Support Vector Classifier</a></li>
            <li><a href="#962-support-vector-machine">9.6.2. Support Vector Machine</a></li>
            <li><a href="#963-roc-curves">9.6.3. ROC Curves</a></li>
            <li><a href="#964-svm-with-multiple-classes">9.6.4. SVM with Multiple Classes</a></li>
            <li><a href="#965-application-to-gene-expression-data">9.6.5. Application to Gene Expression Data</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
        </div>
      
    
  
</div>

    </div>
</body>

</html>